--- START OF MozillaUpdateLock-2656FF1E876E9973 ---

--- END OF MozillaUpdateLock-2656FF1E876E9973 ---


--- START OF z/repo-to-prompt/LICENSE ---
                                 Apache License
                           Version 2.0, January 2004
                        http://www.apache.org/licenses/

   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION

   1. Definitions.

      "License" shall mean the terms and conditions for use, reproduction,
      and distribution as defined by Sections 1 through 9 of this document.

      "Licensor" shall mean the copyright owner or entity authorized by
      the copyright owner that is granting the License.

      "Legal Entity" shall mean the union of the acting entity and all
      other entities that control, are controlled by, or are under common
      control with that entity. For the purposes of this definition,
      "control" means (i) the power, direct or indirect, to cause the
      direction or management of such entity, whether by contract or
      otherwise, or (ii) ownership of fifty percent (50%) or more of the
      outstanding shares, or (iii) beneficial ownership of such entity.

      "You" (or "Your") shall mean an individual or Legal Entity
      exercising permissions granted by this License.

      "Source" form shall mean the preferred form for making modifications,
      including but not limited to software source code, documentation
      source, and configuration files.

      "Object" form shall mean any form resulting from mechanical
      transformation or translation of a Source form, including but
      not limited to compiled object code, generated documentation,
      and conversions to other media types.

      "Work" shall mean the work of authorship, whether in Source or
      Object form, made available under the License, as indicated by a
      copyright notice that is included in or attached to the work
      (an example is provided in the Appendix below).

      "Derivative Works" shall mean any work, whether in Source or Object
      form, that is based on (or derived from) the Work and for which the
      editorial revisions, annotations, elaborations, or other modifications
      represent, as a whole, an original work of authorship. For the purposes
      of this License, Derivative Works shall not include works that remain
      separable from, or merely link (or bind by name) to the interfaces of,
      the Work and Derivative Works thereof.

      "Contribution" shall mean any work of authorship, including
      the original version of the Work and any modifications or additions
      to that Work or Derivative Works thereof, that is intentionally
      submitted to Licensor for inclusion in the Work by the copyright owner
      or by an individual or Legal Entity authorized to submit on behalf of
      the copyright owner. For the purposes of this definition, "submitted"
      means any form of electronic, verbal, or written communication sent
      to the Licensor or its representatives, including but not limited to
      communication on electronic mailing lists, source code control systems,
      and issue tracking systems that are managed by, or on behalf of, the
      Licensor for the purpose of discussing and improving the Work, but
      excluding communication that is conspicuously marked or otherwise
      designated in writing by the copyright owner as "Not a Contribution."

      "Contributor" shall mean Licensor and any individual or Legal Entity
      on behalf of whom a Contribution has been received by Licensor and
      subsequently incorporated within the Work.

   2. Grant of Copyright License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      copyright license to reproduce, prepare Derivative Works of,
      publicly display, publicly perform, sublicense, and distribute the
      Work and such Derivative Works in Source or Object form.

   3. Grant of Patent License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      (except as stated in this section) patent license to make, have made,
      use, offer to sell, sell, import, and otherwise transfer the Work,
      where such license applies only to those patent claims licensable
      by such Contributor that are necessarily infringed by their
      Contribution(s) alone or by combination of their Contribution(s)
      with the Work to which such Contribution(s) was submitted. If You
      institute patent litigation against any entity (including a
      cross-claim or counterclaim in a lawsuit) alleging that the Work
      or a Contribution incorporated within the Work constitutes direct
      or contributory patent infringement, then any patent licenses
      granted to You under this License for that Work shall terminate
      as of the date such litigation is filed.

   4. Redistribution. You may reproduce and distribute copies of the
      Work or Derivative Works thereof in any medium, with or without
      modifications, and in Source or Object form, provided that You
      meet the following conditions:

      (a) You must give any other recipients of the Work or
          Derivative Works a copy of this License; and

      (b) You must cause any modified files to carry prominent notices
          stating that You changed the files; and

      (c) You must retain, in the Source form of any Derivative Works
          that You distribute, all copyright, patent, trademark, and
          attribution notices from the Source form of the Work,
          excluding those notices that do not pertain to any part of
          the Derivative Works; and

      (d) If the Work includes a "NOTICE" text file as part of its
          distribution, then any Derivative Works that You distribute must
          include a readable copy of the attribution notices contained
          within such NOTICE file, excluding those notices that do not
          pertain to any part of the Derivative Works, in at least one
          of the following places: within a NOTICE text file distributed
          as part of the Derivative Works; within the Source form or
          documentation, if provided along with the Derivative Works; or,
          within a display generated by the Derivative Works, if and
          wherever such third-party notices normally appear. The contents
          of the NOTICE file are for informational purposes only and
          do not modify the License. You may add Your own attribution
          notices within Derivative Works that You distribute, alongside
          or as an addendum to the NOTICE text from the Work, provided
          that such additional attribution notices cannot be construed
          as modifying the License.

      You may add Your own copyright statement to Your modifications and
      may provide additional or different license terms and conditions
      for use, reproduction, or distribution of Your modifications, or
      for any such Derivative Works as a whole, provided Your use,
      reproduction, and distribution of the Work otherwise complies with
      the conditions stated in this License.

   5. Submission of Contributions. Unless You explicitly state otherwise,
      any Contribution intentionally submitted for inclusion in the Work
      by You to the Licensor shall be under the terms and conditions of
      this License, without any additional terms or conditions.
      Notwithstanding the above, nothing herein shall supersede or modify
      the terms of any separate license agreement you may have executed
      with Licensor regarding such Contributions.

   6. Trademarks. This License does not grant permission to use the trade
      names, trademarks, service marks, or product names of the Licensor,
      except as required for reasonable and customary use in describing the
      origin of the Work and reproducing the content of the NOTICE file.

   7. Disclaimer of Warranty. Unless required by applicable law or
      agreed to in writing, Licensor provides the Work (and each
      Contributor provides its Contributions) on an "AS IS" BASIS,
      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
      implied, including, without limitation, any warranties or conditions
      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
      PARTICULAR PURPOSE. You are solely responsible for determining the
      appropriateness of using or redistributing the Work and assume any
      risks associated with Your exercise of permissions under this License.

   8. Limitation of Liability. In no event and under no legal theory,
      whether in tort (including negligence), contract, or otherwise,
      unless required by applicable law (such as deliberate and grossly
      negligent acts) or agreed to in writing, shall any Contributor be
      liable to You for damages, including any direct, indirect, special,
      incidental, or consequential damages of any character arising as a
      result of this License or out of the use or inability to use the
      Work (including but not limited to damages for loss of goodwill,
      work stoppage, computer failure or malfunction, or any and all
      other commercial damages or losses), even if such Contributor
      has been advised of the possibility of such damages.

   9. Accepting Warranty or Additional Liability. While redistributing
      the Work or Derivative Works thereof, You may choose to offer,
      and charge a fee for, acceptance of support, warranty, indemnity,
      or other liability obligations and/or rights consistent with this
      License. However, in accepting such obligations, You may act only
      on Your own behalf and on Your sole responsibility, not on behalf
      of any other Contributor, and only if You agree to indemnify,
      defend, and hold each Contributor harmless for any liability
      incurred by, or claims asserted against, such Contributor by reason
      of your accepting any such warranty or additional liability.

   END OF TERMS AND CONDITIONS

   APPENDIX: How to apply the Apache License to your work.

      To apply the Apache License to your work, attach the following
      boilerplate notice, with the fields enclosed by brackets "[]"
      replaced with your own identifying information. (Don't include
      the brackets!)  The text should be enclosed in the appropriate
      comment syntax for the file format. We also recommend that a
      file or class name and description of purpose be included on the
      same "printed page" as the copyright notice for easier
      identification within third-party archives.

   Copyright [yyyy] [name of copyright owner]

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.

--- END OF z/repo-to-prompt/LICENSE ---


--- START OF z/repo-to-prompt/requirements.txt ---
tqdm
black
emoji
--- END OF z/repo-to-prompt/requirements.txt ---


--- START OF z/repo-to-prompt/README.md ---
# repo-to-prompt
repo-to-prompt, or R2P, is a powerful tool that can quickly convert an entire Git repository to a prompt that can be fed to any large language model (LLM).

It will automatically ignore all binary files. Additionally, it will respect your **.gitignore**.

## Usage

If you're already in a git repo:
```
r2p -repo .
```

Alternatively, you can pass a git URL to the tool:
```
r2p -repo <repo url>
```

The prompt will be generated in a file called **r2p_output.txt**.

## Output formats

A simple .txt file would be sufficient for most use cases. But the tool also supports the following output formats:

- Markdown
- JSON

## Additional Features

- Can count tokens for most OpenAI models

--- END OF z/repo-to-prompt/README.md ---


--- START OF z/repo-to-prompt/setup.py ---
from setuptools import setup, find_packages

with open('README.md', 'r', encoding='utf-8') as f:
    long_description = f.read()

setup(
    name='repo-to-prompt',
    version='0.1.0',
    author='Ashraff Hathibelagal',
    description='A tool to turn a Git repository into an LLM-friendly prompt',
    long_description=long_description,
    long_description_content_type='text/markdown',
    url='https://github.com/hathibelagal-dev/repo-to-prompt',
    packages=find_packages(where='src'),
    package_dir={'': 'src'},
    python_requires='>=3.6',
    install_requires=[
        'tqdm',
        'emoji'
    ],
    entry_points={
        'console_scripts': [
            'repo-to-prompt=src.main:main',
        ],
    },
    classifiers=[
        'Development Status :: 3 - Alpha',
        'Intended Audience :: Developers',
        'License :: OSI Approved :: Apache Software License'
        'Programming Language :: Python :: 3',
        'Programming Language :: Python :: 3.6',
        'Programming Language :: Python :: 3.7',
        'Programming Language :: Python :: 3.8',
        'Programming Language :: Python :: 3.9',
    ],
    keywords='ai language-models devtools gpt-4 openai llama mistral gemini chatbot',
    project_urls={
        'Source': 'https://github.com/hathibelagal-dev/repo-to-prompt',
        'Tracker': 'https://github.com/hathibelagal-dev/repo-to-prompt/issues',
    },
)
--- END OF z/repo-to-prompt/setup.py ---


--- START OF z/repo-to-prompt/src/file_handler.py ---
class FileHandler:
    def __init__(self, include_binary=False):
        """Initialize with a flag for including binary files."""
        self.include_binary = include_binary

    @staticmethod
    def is_binary(filename):
        """Very basic check if a file might be binary."""
        try:
            with open(filename, "rb") as f:
                test = f.read(1024)
                if b"\0" in test:
                    return True
        except:
            pass
        return False

    def read_file(self, file_path):
        """Read and return file content, handling binary if specified."""
        try:
            with open(file_path, "r", encoding="utf-8") as infile:
                return infile.read()
        except UnicodeDecodeError:
            if self.include_binary:
                with open(file_path, "rb") as infile:
                    return infile.read().hex()
        return None

--- END OF z/repo-to-prompt/src/file_handler.py ---


--- START OF z/repo-to-prompt/src/__init__.py ---

--- END OF z/repo-to-prompt/src/__init__.py ---


--- START OF z/repo-to-prompt/src/ignore_handler.py ---
import os
import pathlib
import pathspec


class IgnoreHandler:
    def __init__(self, repo_path):
        """Initialize with the path to the repository, looking for both .gitignore and .r2pignore."""
        self.repo_path = pathlib.Path(repo_path).resolve()
        self.n_ignored = 0
        self.spec = self._read_ignores()

    def _read_ignores(self):
        """Read both .gitignore and .r2pignore files and return a compiled pathspec."""
        ignore_patterns = []

        for ignore_file in [".gitignore", ".r2pignore"]:
            ignore_file_path = self.repo_path / ignore_file
            if ignore_file_path.exists():
                with open(ignore_file_path, "r", encoding="utf-8") as f:
                    ignore_patterns.extend(f.readlines())

        return pathspec.PathSpec.from_lines("gitwildmatch", ignore_patterns)

    def should_ignore(self, file_path):
        """Check if a file should be ignored based on .gitignore-style rules."""
        relative_path = os.path.relpath(file_path, self.repo_path)
        if self.spec.match_file(relative_path):
            self.n_ignored += 1
            return True
        return False
--- END OF z/repo-to-prompt/src/ignore_handler.py ---


--- START OF z/repo-to-prompt/src/concatenator.py ---
from ignore_handler import IgnoreHandler
from file_handler import FileHandler
from tqdm import tqdm
import os


class FileConcatenator:
    def __init__(self, repo_path, output_file, include_binary=False, encoding="utf-8"):
        """Initialize with paths and binary inclusion flag."""
        self.repo_path = repo_path
        self.output_file = output_file
        self.ignore_handler = IgnoreHandler(repo_path)
        self.file_handler = FileHandler(include_binary)

    def concatenate(self):
        """Concatenate files from the repo path to the output file."""

        total_files = sum(len(files) for _, _, files in os.walk(self.repo_path))
        with tqdm(total=total_files, desc="Concatenating") as pbar:
            with open(self.output_file, "w", encoding="utf-8") as outfile:
                for root, _, files in os.walk(self.repo_path):
                    for file in files:
                        file_path = os.path.join(root, file)
                        if not self.ignore_handler.should_ignore(file_path):
                            content = self.file_handler.read_file(file_path)
                            if content is not None:
                                relative_path = os.path.relpath(
                                    file_path, self.repo_path
                                )
                                outfile.write(f"--- START OF {relative_path} ---\n")
                                outfile.write(content)
                                outfile.write(f"\n--- END OF {relative_path} ---\n")
                                outfile.write("\n\n")
                            pbar.update(1)

        return total_files, self.ignore_handler.n_ignored

--- END OF z/repo-to-prompt/src/concatenator.py ---


--- START OF z/repo-to-prompt/src/main.py ---
import argparse
from concatenator import FileConcatenator
import emoji


def main():
    parser = argparse.ArgumentParser(
        description="Concatenate all files of a Git repo into a single prompt."
    )
    parser.add_argument("repo_path", help="Path to the root of the repository")
    parser.add_argument(
        "--include-binary",
        action="store_true",
        help="Include binary files in concatenation",
    )
    parser.add_argument(
        "--output-file", default="llm_prompt.txt", help="Name of the output file"
    )
    parser.add_argument(
        "--output-encoding", default="utf-8", help="Encoding for output file"
    )

    args = parser.parse_args()

    concatenator = FileConcatenator(
        args.repo_path, args.output_file, args.include_binary, args.output_encoding
    )
    _, n_ignored = concatenator.concatenate()
    print(
        emoji.emojize(
            f":thumbs_up: All valid files have been concatenated into {args.output_file}"
        )
    )
    if n_ignored > 0:
        print(
            emoji.emojize(
                f":thumbs_up: {n_ignored} files were ignored due to .gitignore or .r2pignore rules"
            )
        )


if __name__ == "__main__":
    main()

--- END OF z/repo-to-prompt/src/main.py ---


--- START OF t/f2 ---
Bye

--- END OF t/f2 ---


--- START OF t/f1 ---
Hello

--- END OF t/f1 ---


--- START OF t/q/hid ---
Why

--- END OF t/q/hid ---


--- START OF q/repo-to-prompt/LICENSE ---
                                 Apache License
                           Version 2.0, January 2004
                        http://www.apache.org/licenses/

   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION

   1. Definitions.

      "License" shall mean the terms and conditions for use, reproduction,
      and distribution as defined by Sections 1 through 9 of this document.

      "Licensor" shall mean the copyright owner or entity authorized by
      the copyright owner that is granting the License.

      "Legal Entity" shall mean the union of the acting entity and all
      other entities that control, are controlled by, or are under common
      control with that entity. For the purposes of this definition,
      "control" means (i) the power, direct or indirect, to cause the
      direction or management of such entity, whether by contract or
      otherwise, or (ii) ownership of fifty percent (50%) or more of the
      outstanding shares, or (iii) beneficial ownership of such entity.

      "You" (or "Your") shall mean an individual or Legal Entity
      exercising permissions granted by this License.

      "Source" form shall mean the preferred form for making modifications,
      including but not limited to software source code, documentation
      source, and configuration files.

      "Object" form shall mean any form resulting from mechanical
      transformation or translation of a Source form, including but
      not limited to compiled object code, generated documentation,
      and conversions to other media types.

      "Work" shall mean the work of authorship, whether in Source or
      Object form, made available under the License, as indicated by a
      copyright notice that is included in or attached to the work
      (an example is provided in the Appendix below).

      "Derivative Works" shall mean any work, whether in Source or Object
      form, that is based on (or derived from) the Work and for which the
      editorial revisions, annotations, elaborations, or other modifications
      represent, as a whole, an original work of authorship. For the purposes
      of this License, Derivative Works shall not include works that remain
      separable from, or merely link (or bind by name) to the interfaces of,
      the Work and Derivative Works thereof.

      "Contribution" shall mean any work of authorship, including
      the original version of the Work and any modifications or additions
      to that Work or Derivative Works thereof, that is intentionally
      submitted to Licensor for inclusion in the Work by the copyright owner
      or by an individual or Legal Entity authorized to submit on behalf of
      the copyright owner. For the purposes of this definition, "submitted"
      means any form of electronic, verbal, or written communication sent
      to the Licensor or its representatives, including but not limited to
      communication on electronic mailing lists, source code control systems,
      and issue tracking systems that are managed by, or on behalf of, the
      Licensor for the purpose of discussing and improving the Work, but
      excluding communication that is conspicuously marked or otherwise
      designated in writing by the copyright owner as "Not a Contribution."

      "Contributor" shall mean Licensor and any individual or Legal Entity
      on behalf of whom a Contribution has been received by Licensor and
      subsequently incorporated within the Work.

   2. Grant of Copyright License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      copyright license to reproduce, prepare Derivative Works of,
      publicly display, publicly perform, sublicense, and distribute the
      Work and such Derivative Works in Source or Object form.

   3. Grant of Patent License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      (except as stated in this section) patent license to make, have made,
      use, offer to sell, sell, import, and otherwise transfer the Work,
      where such license applies only to those patent claims licensable
      by such Contributor that are necessarily infringed by their
      Contribution(s) alone or by combination of their Contribution(s)
      with the Work to which such Contribution(s) was submitted. If You
      institute patent litigation against any entity (including a
      cross-claim or counterclaim in a lawsuit) alleging that the Work
      or a Contribution incorporated within the Work constitutes direct
      or contributory patent infringement, then any patent licenses
      granted to You under this License for that Work shall terminate
      as of the date such litigation is filed.

   4. Redistribution. You may reproduce and distribute copies of the
      Work or Derivative Works thereof in any medium, with or without
      modifications, and in Source or Object form, provided that You
      meet the following conditions:

      (a) You must give any other recipients of the Work or
          Derivative Works a copy of this License; and

      (b) You must cause any modified files to carry prominent notices
          stating that You changed the files; and

      (c) You must retain, in the Source form of any Derivative Works
          that You distribute, all copyright, patent, trademark, and
          attribution notices from the Source form of the Work,
          excluding those notices that do not pertain to any part of
          the Derivative Works; and

      (d) If the Work includes a "NOTICE" text file as part of its
          distribution, then any Derivative Works that You distribute must
          include a readable copy of the attribution notices contained
          within such NOTICE file, excluding those notices that do not
          pertain to any part of the Derivative Works, in at least one
          of the following places: within a NOTICE text file distributed
          as part of the Derivative Works; within the Source form or
          documentation, if provided along with the Derivative Works; or,
          within a display generated by the Derivative Works, if and
          wherever such third-party notices normally appear. The contents
          of the NOTICE file are for informational purposes only and
          do not modify the License. You may add Your own attribution
          notices within Derivative Works that You distribute, alongside
          or as an addendum to the NOTICE text from the Work, provided
          that such additional attribution notices cannot be construed
          as modifying the License.

      You may add Your own copyright statement to Your modifications and
      may provide additional or different license terms and conditions
      for use, reproduction, or distribution of Your modifications, or
      for any such Derivative Works as a whole, provided Your use,
      reproduction, and distribution of the Work otherwise complies with
      the conditions stated in this License.

   5. Submission of Contributions. Unless You explicitly state otherwise,
      any Contribution intentionally submitted for inclusion in the Work
      by You to the Licensor shall be under the terms and conditions of
      this License, without any additional terms or conditions.
      Notwithstanding the above, nothing herein shall supersede or modify
      the terms of any separate license agreement you may have executed
      with Licensor regarding such Contributions.

   6. Trademarks. This License does not grant permission to use the trade
      names, trademarks, service marks, or product names of the Licensor,
      except as required for reasonable and customary use in describing the
      origin of the Work and reproducing the content of the NOTICE file.

   7. Disclaimer of Warranty. Unless required by applicable law or
      agreed to in writing, Licensor provides the Work (and each
      Contributor provides its Contributions) on an "AS IS" BASIS,
      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
      implied, including, without limitation, any warranties or conditions
      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
      PARTICULAR PURPOSE. You are solely responsible for determining the
      appropriateness of using or redistributing the Work and assume any
      risks associated with Your exercise of permissions under this License.

   8. Limitation of Liability. In no event and under no legal theory,
      whether in tort (including negligence), contract, or otherwise,
      unless required by applicable law (such as deliberate and grossly
      negligent acts) or agreed to in writing, shall any Contributor be
      liable to You for damages, including any direct, indirect, special,
      incidental, or consequential damages of any character arising as a
      result of this License or out of the use or inability to use the
      Work (including but not limited to damages for loss of goodwill,
      work stoppage, computer failure or malfunction, or any and all
      other commercial damages or losses), even if such Contributor
      has been advised of the possibility of such damages.

   9. Accepting Warranty or Additional Liability. While redistributing
      the Work or Derivative Works thereof, You may choose to offer,
      and charge a fee for, acceptance of support, warranty, indemnity,
      or other liability obligations and/or rights consistent with this
      License. However, in accepting such obligations, You may act only
      on Your own behalf and on Your sole responsibility, not on behalf
      of any other Contributor, and only if You agree to indemnify,
      defend, and hold each Contributor harmless for any liability
      incurred by, or claims asserted against, such Contributor by reason
      of your accepting any such warranty or additional liability.

   END OF TERMS AND CONDITIONS

   APPENDIX: How to apply the Apache License to your work.

      To apply the Apache License to your work, attach the following
      boilerplate notice, with the fields enclosed by brackets "[]"
      replaced with your own identifying information. (Don't include
      the brackets!)  The text should be enclosed in the appropriate
      comment syntax for the file format. We also recommend that a
      file or class name and description of purpose be included on the
      same "printed page" as the copyright notice for easier
      identification within third-party archives.

   Copyright [yyyy] [name of copyright owner]

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.

--- END OF q/repo-to-prompt/LICENSE ---


--- START OF q/repo-to-prompt/requirements.txt ---
tqdm
black
emoji
--- END OF q/repo-to-prompt/requirements.txt ---


--- START OF q/repo-to-prompt/README.md ---
# repo-to-prompt
repo-to-prompt, or R2P, is a powerful tool that can quickly convert an entire Git repository to a prompt that can be fed to any large language model (LLM).

It will automatically ignore all binary files. Additionally, it will respect your **.gitignore**.

## Usage

If you're already in a git repo:
```
r2p -repo .
```

Alternatively, you can pass a git URL to the tool:
```
r2p -repo <repo url>
```

The prompt will be generated in a file called **r2p_output.txt**.

## Output formats

A simple .txt file would be sufficient for most use cases. But the tool also supports the following output formats:

- Markdown
- JSON

## Additional Features

- Can count tokens for most OpenAI models

--- END OF q/repo-to-prompt/README.md ---


--- START OF q/repo-to-prompt/setup.py ---
from setuptools import setup, find_packages

with open('README.md', 'r', encoding='utf-8') as f:
    long_description = f.read()

setup(
    name='repo-to-prompt',
    version='0.1.0',
    author='Ashraff Hathibelagal',
    description='A tool to turn a Git repository into an LLM-friendly prompt',
    long_description=long_description,
    long_description_content_type='text/markdown',
    url='https://github.com/hathibelagal-dev/repo-to-prompt',
    packages=find_packages(where='src'),
    package_dir={'': 'src'},
    python_requires='>=3.6',
    install_requires=[
        'tqdm',
        'emoji'
    ],
    entry_points={
        'console_scripts': [
            'repo-to-prompt=src.main:main',
        ],
    },
    classifiers=[
        'Development Status :: 3 - Alpha',
        'Intended Audience :: Developers',
        'License :: OSI Approved :: Apache Software License'
        'Programming Language :: Python :: 3',
        'Programming Language :: Python :: 3.6',
        'Programming Language :: Python :: 3.7',
        'Programming Language :: Python :: 3.8',
        'Programming Language :: Python :: 3.9',
    ],
    keywords='ai language-models devtools gpt-4 openai llama mistral gemini chatbot',
    project_urls={
        'Source': 'https://github.com/hathibelagal-dev/repo-to-prompt',
        'Tracker': 'https://github.com/hathibelagal-dev/repo-to-prompt/issues',
    },
)
--- END OF q/repo-to-prompt/setup.py ---


--- START OF q/repo-to-prompt/src/file_handler.py ---
class FileHandler:
    def __init__(self, include_binary=False):
        """Initialize with a flag for including binary files."""
        self.include_binary = include_binary

    @staticmethod
    def is_binary(filename):
        """Very basic check if a file might be binary."""
        try:
            with open(filename, "rb") as f:
                test = f.read(1024)
                if b"\0" in test:
                    return True
        except:
            pass
        return False

    def read_file(self, file_path):
        """Read and return file content, handling binary if specified."""
        try:
            with open(file_path, "r", encoding="utf-8") as infile:
                return infile.read()
        except UnicodeDecodeError:
            if self.include_binary:
                with open(file_path, "rb") as infile:
                    return infile.read().hex()
        return None

--- END OF q/repo-to-prompt/src/file_handler.py ---


--- START OF q/repo-to-prompt/src/__init__.py ---

--- END OF q/repo-to-prompt/src/__init__.py ---


--- START OF q/repo-to-prompt/src/ignore_handler.py ---
import os
import pathlib
import pathspec


class IgnoreHandler:
    def __init__(self, repo_path):
        """Initialize with the path to the repository, looking for both .gitignore and .r2pignore."""
        self.repo_path = pathlib.Path(repo_path).resolve()
        self.n_ignored = 0
        self.spec = self._read_ignores()

    def _read_ignores(self):
        """Read both .gitignore and .r2pignore files and return a compiled pathspec."""
        ignore_patterns = []

        for ignore_file in [".gitignore", ".r2pignore"]:
            ignore_file_path = self.repo_path / ignore_file
            if ignore_file_path.exists():
                with open(ignore_file_path, "r", encoding="utf-8") as f:
                    ignore_patterns.extend(f.readlines())

        return pathspec.PathSpec.from_lines("gitwildmatch", ignore_patterns)

    def should_ignore(self, file_path):
        """Check if a file should be ignored based on .gitignore-style rules."""
        relative_path = os.path.relpath(file_path, self.repo_path)
        if self.spec.match_file(relative_path):
            self.n_ignored += 1
            return True
        return False
--- END OF q/repo-to-prompt/src/ignore_handler.py ---


--- START OF q/repo-to-prompt/src/concatenator.py ---
from ignore_handler import IgnoreHandler
from file_handler import FileHandler
from tqdm import tqdm
import os


class FileConcatenator:
    def __init__(self, repo_path, output_file, include_binary=False, encoding="utf-8"):
        """Initialize with paths and binary inclusion flag."""
        self.repo_path = repo_path
        self.output_file = output_file
        self.ignore_handler = IgnoreHandler(repo_path)
        self.file_handler = FileHandler(include_binary)

    def concatenate(self):
        """Concatenate files from the repo path to the output file."""

        total_files = sum(len(files) for _, _, files in os.walk(self.repo_path))
        with tqdm(total=total_files, desc="Concatenating") as pbar:
            with open(self.output_file, "w", encoding="utf-8") as outfile:
                for root, _, files in os.walk(self.repo_path):
                    for file in files:
                        file_path = os.path.join(root, file)
                        if not self.ignore_handler.should_ignore(file_path):
                            content = self.file_handler.read_file(file_path)
                            if content is not None:
                                relative_path = os.path.relpath(
                                    file_path, self.repo_path
                                )
                                outfile.write(f"--- START OF {relative_path} ---\n")
                                outfile.write(content)
                                outfile.write(f"\n--- END OF {relative_path} ---\n")
                                outfile.write("\n\n")
                            pbar.update(1)

        return total_files, self.ignore_handler.n_ignored

--- END OF q/repo-to-prompt/src/concatenator.py ---


--- START OF q/repo-to-prompt/src/main.py ---
import argparse
from concatenator import FileConcatenator
import emoji


def main():
    parser = argparse.ArgumentParser(
        description="Concatenate all files of a Git repo into a single prompt."
    )
    parser.add_argument("repo_path", help="Path to the root of the repository")
    parser.add_argument(
        "--include-binary",
        action="store_true",
        help="Include binary files in concatenation",
    )
    parser.add_argument(
        "--output-file", default="llm_prompt.txt", help="Name of the output file"
    )
    parser.add_argument(
        "--output-encoding", default="utf-8", help="Encoding for output file"
    )

    args = parser.parse_args()

    concatenator = FileConcatenator(
        args.repo_path, args.output_file, args.include_binary, args.output_encoding
    )
    _, n_ignored = concatenator.concatenate()
    print(
        emoji.emojize(
            f":thumbs_up: All valid files have been concatenated into {args.output_file}"
        )
    )
    if n_ignored > 0:
        print(
            emoji.emojize(
                f":thumbs_up: {n_ignored} files were ignored due to .gitignore or .r2pignore rules"
            )
        )


if __name__ == "__main__":
    main()

--- END OF q/repo-to-prompt/src/main.py ---


--- START OF q/repo-to-prompt/src/llm_prompt.txt ---
--- START OF .r2pignore ---
*.json
LICENSE.txt
docs

--- END OF .r2pignore ---


--- START OF pyproject.toml ---
[build-system]
requires = ["setuptools>=65.0.0"]
build-backend = "setuptools.build_meta"

[project]
name = "emoji"
description = "Emoji for Python"
readme = "README.rst"
requires-python = ">=3.7"
authors = [
    { name = "Taehoon Kim", email = "carpedm20@gmail.com" },
    { name = "Kevin Wurster", email = "wursterk@gmail.com" },
]
keywords = ["emoji"]
classifiers = [
    "Development Status :: 5 - Production/Stable",
    "Intended Audience :: Developers",
    "Intended Audience :: Information Technology",
    "License :: OSI Approved :: BSD License",
    "Operating System :: OS Independent",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.7",
    "Programming Language :: Python :: 3.8",
    "Programming Language :: Python :: 3.9",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
    "Programming Language :: Python :: 3.13",
    "Programming Language :: Python :: Implementation :: CPython",
    "Programming Language :: Python :: Implementation :: PyPy",
    "Programming Language :: Python",
    "Topic :: Internet :: WWW/HTTP :: Dynamic Content",
    "Topic :: Multimedia :: Graphics :: Presentation",
    "Topic :: Software Development :: Libraries :: Python Modules",
    "Typing :: Typed",
]
dependencies = ["typing_extensions >= 4.7.0; python_version < '3.9'"]
dynamic = ["version"]

[project.urls]
homepage = "https://github.com/carpedm20/emoji/"
repository = "https://github.com/carpedm20/emoji/"

[project.optional-dependencies]
dev = ["pytest>=7.4.4", "coverage"]

[tool.setuptools.packages.find]
include = ["emoji*"]

[tool.setuptools.package-data]
emoji = ["py.typed", "unicode_codes/emoji.json", "unicode_codes/emoji_*.json"]

[tool.setuptools.dynamic]
version = { attr = "emoji.__version__" }

[tool.pytest.ini_options]
pythonpath = [".", "utils"]
testpaths = ["tests"]

[tool.pyright]
pythonVersion = "3.7"
pythonPlatform = "All"
typeCheckingMode = "strict"
extraPaths = ["utils"]
exclude = [
    "**/__pycache__",
    ".git",
    ".venv",
    "build",
    "utils/gh-pages",
    "utils/generate_emoji.py",
    "utils/generate_emoji_translations.py",
    "utils/generateutils.py",
]

[tool.ruff]
line-length = 88
[tool.ruff.format]
quote-style = "single"
exclude = [
    "utils/generate_emoji.py",
    "utils/generate_emoji_translations.py",
    "utils/generateutils.py",
]

[tool.ruff.lint]
select = ["E4", "E7", "E9", "F", "B", "Q"]
ignore = ["Q000", "Q003"]

[tool.tox]
legacy_tox_ini = """
    [tox]
    minversion = 4.15.0

    [testenv]
    description = Run the tests with pytest
    package = wheel
    wheel_build_env = .pkg
    changedir = tests
    deps =
        pytest>=6
    commands =
        pytest {tty:--color=yes} --basetemp="{envtmpdir}" {posargs}
"""

--- END OF pyproject.toml ---


--- START OF MANIFEST.in ---
include LICENSE.txt
include MANIFEST.in
include README.rst
include CHANGES.md
include utils/testutils.py
recursive-include tests *.py
include emoji/unicode_codes/emoji.json
recursive-include emoji/unicode_codes emoji_*.json

--- END OF MANIFEST.in ---


--- START OF .gitignore ---
# Byte-compiled / optimized / DLL files
__pycache__/
*.py[cod]

# C extensions
*.so

# Distribution / packaging
.Python
env/
venv/
venv2/
build/
develop-eggs/
dist/
downloads/
eggs/
lib/
lib64/
parts/
sdist/
var/
*.egg-info/
.installed.cfg
*.egg
*.DS_Store

# PyInstaller
#  Usually these files are written by a python script from a template
#  before PyInstaller builds the exe, so as to inject date/other infos into it.
*.manifest
*.spec

# Installer logs
pip-log.txt
pip-delete-this-directory.txt

# Unit test / coverage reports
htmlcov/
.tox/
.coverage
.cache
nosetests.xml
coverage.xml

# Translations
*.mo
*.pot

# Django stuff:
*.log

# Sphinx documentation
docs/_build/

# PyBuilder
target/

# JetBrains PyCharm
.idea/
/.pytest_cache/
.vscode/

--- END OF .gitignore ---


--- START OF CHANGES.md ---
emoji
=====

v2.14.1 (2025-01-10)
-----
* Use `importlib.resources` to load json files #311
* Update translations to Unicode release-46-1

v2.14.0 (2024-10-02)
-----
* Update to Unicode 16.0

v2.13.2 (2024-09-23)
-----
* `typing_extensions` dependency not required on Python 3.9 and higher #303

v2.13.1 (2024-09-21)
-----
* Read JSON files in binary mode to avoid UnicodeDecodeError #305

v2.13.0 (2024-09-19)
-----
* Use JSON files to store the database of emoji
* Load a language into emoji.EMOJI_DATA with emoji.config.load_language("zh")

v2.12.1 (2024-05-20)
-----
* `typing-extensions` requires at least version `4.7.0` #297

v2.12.0 (2024-05-19)
-----
* Move type annotations inline
* Use `functools.lru_cache` for looking up emoji by name with `get_emoji_by_name()`
* Move internal functions `get_emoji_unicode_dict()`, `get_aliases_unicode_dict()`, `_EMOJI_UNICODE` and `_ALIASES_UNICODE` to `testutils`
* Add type hints to tests
* Remove obsolete dev dependency `coveralls`

v2.11.1 (2024-04-21)
-----
* Add missing stubs for purely_emoji

v2.11.0 (2024-03-26)
-----
* Update to Unicode v15.1

v2.10.1 (2024-01-31)
-----
* Fix slow import when debugging in Python 3.12 #280

v2.10.0 (2024-01-18)
-----
* Added Arabic and Turkish translations

v2.9.0 (2023-12-05)
-----
* Added Russian translation

v2.8.0 (2023-08-16)
-----
* Update translations to unicode release-43-1
* Include "derived annotations"-translations from unicode CLDR
* Fix translations for emoji that have multiple forms with/out \uFE0F (Fixes Partially missing languages #272 )
* Remove multiple underscore __,  ___, ____ and _-_ from translations

v2.7.0 (2023-07-25)
-----
* Extract aliases from cheat sheet and youtube
* Fix extracting translations from emojiterra
* Update EMOJI_DATA with new aliases and translations

v2.6.0 (2023-06-28)
-----
* Added new function purely_emoji() | Check if a string contains only emojis

v2.5.1 (2023-06-15)
-----
* Fix Malformed zero width joiner (\u200d) causes IndexError

v2.5.0 (2023-06-08)
-----
* Added support for Multi-person skintones
* Removed support for Python 2, 3.4, 3.5
* The logic from demojize() is moved to two separate private function tokenize() and filter_tokens() in a new file emoji/tokenizer.py
* A new public function analyze() is available and that supports the multi-person skintones

v2.4.0 (2023-03-12)
-----
* Added Japanese and Korean

v2.3.0 (2023-02-04)
-----
* Added Indonesian and Simplified Chinese
* Bug fixing

v2.2.0 (2022-10-31)
-----
* Added support for Unicode Version 15
* Added more translations for existing languages: (similar to the Turkish Language)
* Added Readme on how to add a language
* Fix 2.0.0: sphinx warnings reference target not found

v2.1.0 (2022-09-17)
-----
* Added Farsi support
* Added Trove classifiers for Python 3.10 and 3.11

v2.0.0 (2022-06-30)
-----
* Removed the old dicts EMOJI_UNICODE_*, UNICODE_EMOJI_*
* Removed unused language=None parameters
* Removed use_alias parameter
* Removed the get_regexp method
* Removed emoji_lis
* Removed distinct_emoji_lis
* Made the list of languages public: emoji.LANGUAGES = ['en','es','pt','it','fr','de']
* Updated translations to release-41 (no changes compared to release-40)
* Generate documentation for the public functions from the docstrings with Sphinx
* Added some more examples to the README: e.g. how to replace/remove emojis
* Total count of emojis:  4702

v1.7.0 (2022-03-07)
-----
* Added `emoji_list()` and `distinct_emoji_list()`
* Added deprecation warnings for several functions and variables that will be removed in version 2.0.0.
  If you don't want to see these warnings, you can stay with 1.6.x. For example, in pip/requirements.txt you can pin to 1.6.x with `emoji~=1.6.3`.

v1.6.3 (2022-01-15)
-----
* Added support for counting unique emojis

v1.6.2 (2021-12-06)
-----
* Improve performance of demojize()
* Added more tests
* Added warning when someone uses any other language than 'en' with use_aliases=True in emojize()

v1.6.1 (2021-10-13)
-----
* Allow multiple aliases
* Restored aliases from 1.5.0

v1.6.0 (2021-10-04)
-----
* Fix Unicode of some emoji in the language files
* is_emoji function added
* Added dict of dict with emoji data include emoji versions and statuses
* emoji.version(string) method added
* Included 'variant' in the dict of dicts

v1.5.2 (2021-09-25)
-----
* is_emoji function added

v1.5.1 (2021-09-25)
-----
* Fix Unicode of some emoji in the language files

v1.5.0 (2021-09-17)
-----
* Emojis of English version updated to the Emoji Charts v14.0
* Current count of emojis - 3633
* Fix matching of non-ASCII emoji names on Python 2

v1.4.2 (2021-07-30)
-----
* Delimiter for German time naming changed from ":" to "."

v1.4.1 (2021-07-18)
-----
* Fix some French emoji names not being matched
* Drop seemingly accidentally added colons from German emoji names

v1.4.0 (2021-06-22)
-----
* Added support for German naming of emojis

v1.3.0 (2021-06-02)
-----
* Added support for French naming of emojis

v1.2.1 (2021-03-13)
-----
* Added replace_emoji

v1.2.0 (2021-01-27)
-----
* Emojis of English version updated to the Emoji Charts v13.1
* Added all emoji modifiers
* Current count of emojis - 3521

v1.1.1 (2021-01-25)
-----
* Emoji extractor refactored 

v1.1.0 (2021-01-23)
-----
* Added support for Italian naming of emojis
* Added Python 3.8 and 3.9 as supported versions

v1.0.1 (2021-01-23)
-----
* Bug fixing

v1.0.0 (2021-01-22)
-----
* Added support for Spanish naming of emojis
* Added support for Portuguese naming of emojis
* Emoji packs split by language to different modules

v0.3.5
-----
* Use codecs.open() instead of open() when processing readme in setup.py - #2, #5

v0.3.4 (2015-05-19)
-----
* Restored default functionality - #6
* Removed `emoji.decode()` - #10
* Added `use_aliases` to `emoji.emojize()` to enable the GitHub aliases and others - #8

v0.2.0
---
* Added ~400 codes to bring the emoji list up to date
* emojize() regex now matches &.ô’Åéãíç
* Unittests for API and to validate emoji formatting and parsing
* decode() function to lookup emoji by their Unicode code

--- END OF CHANGES.md ---


--- START OF README.rst ---
Emoji
=====

Emoji for Python.  This project was inspired by `kyokomi <https://github.com/kyokomi/emoji>`__.


Example
-------

The entire set of Emoji codes as defined by the `Unicode consortium <https://unicode.org/emoji/charts/full-emoji-list.html>`__
is supported in addition to a bunch of `aliases <https://www.webfx.com/tools/emoji-cheat-sheet/>`__.  By
default, only the official list is enabled but doing ``emoji.emojize(language='alias')`` enables
both the full list and aliases.

.. code-block:: python

    >>> import emoji
    >>> print(emoji.emojize('Python is :thumbs_up:'))
    Python is 👍
    >>> print(emoji.emojize('Python is :thumbsup:', language='alias'))
    Python is 👍
    >>> print(emoji.demojize('Python is 👍'))
    Python is :thumbs_up:
    >>> print(emoji.emojize("Python is fun :red_heart:"))
    Python is fun ❤
    >>> print(emoji.emojize("Python is fun :red_heart:", variant="emoji_type"))
    Python is fun ❤️ #red heart, not black heart
    >>> print(emoji.is_emoji("👍"))
    True

..

By default, the language is English (``language='en'``) but also supported languages are:

* Spanish (``'es'``)
* Portuguese (``'pt'``)
* Italian (``'it'``)
* French (``'fr'``)
* German (``'de'``)
* Farsi/Persian (``'fa'``)
* Indonesian (``'id'``)
* Simplified Chinese (``'zh'``)
* Japanese (``'ja'``)
* Korean (``'ko'``)
* Russian (``'ru'``)
* Arabic (``'ar'``)
* Turkish (``'tr'``)


.. code-block:: python

    >>> print(emoji.emojize('Python es :pulgar_hacia_arriba:', language='es'))
    Python es 👍
    >>> print(emoji.demojize('Python es 👍', language='es'))
    Python es :pulgar_hacia_arriba:
    >>> print(emoji.emojize("Python é :polegar_para_cima:", language='pt'))
    Python é 👍
    >>> print(emoji.demojize("Python é 👍", language='pt'))
    Python é :polegar_para_cima:️

..

Installation
------------

Via pip:

.. code-block:: console

    $ python -m pip install emoji --upgrade

From master branch:

.. code-block:: console

    $ git clone https://github.com/carpedm20/emoji.git
    $ cd emoji
    $ python -m pip install .


Developing
----------

.. code-block:: console

    $ git clone https://github.com/carpedm20/emoji.git
    $ cd emoji
    $ python -m pip install -e .\[dev\]
    $ pytest
    $ coverage run -m pytest
    $ coverage report

The ``utils/generate_emoji.py`` script is used to generate
``unicode_codes/emoji.json``. Generally speaking it scrapes a table on the
`Unicode Consortium's website <https://www.unicode.org/reports/tr51/#emoji_data>`__
with `BeautifulSoup <http://www.crummy.com/software/BeautifulSoup/>`__
For more information take a look in the `utils/README.md <utils/README.md>`__ file.

Check the code style with:

.. code-block:: console

    $ python -m pip install ruff
    $ ruff check emoji

Test the type checks with:

.. code-block:: console

    $ python -m pip install pyright mypy typeguard
    $ pyright emoji
    $ pyright tests
    $ mypy emoji
    $ pytest --typeguard-packages=emoji


Links
-----

**Documentation**

`https://carpedm20.github.io/emoji/docs/ <https://carpedm20.github.io/emoji/docs/>`__

**Overview of all emoji:**

`https://carpedm20.github.io/emoji/ <https://carpedm20.github.io/emoji/>`__

(auto-generated list of the emoji that are supported by the current version of this package)

**For English:**

`Emoji Cheat Sheet <https://www.webfx.com/tools/emoji-cheat-sheet/>`__

`Official Unicode list <http://www.unicode.org/emoji/charts/full-emoji-list.html>`__

**For Spanish:**

`Unicode list <https://emojiterra.com/es/lista-es/>`__

**For Portuguese:**

`Unicode list <https://emojiterra.com/pt/lista/>`__

**For Italian:**

`Unicode list <https://emojiterra.com/it/lista-it/>`__

**For French:**

`Unicode list <https://emojiterra.com/fr/liste-fr/>`__

**For German:**

`Unicode list <https://emojiterra.com/de/liste/>`__


Authors
-------

Taehoon Kim / `@carpedm20 <http://carpedm20.github.io/about/>`__

Kevin Wurster / `@geowurster <http://twitter.com/geowurster/>`__

Maintainer
----------
Tahir Jalilov / `@TahirJalilov <https://github.com/TahirJalilov>`__

--- END OF README.rst ---


--- START OF example/example.py ---
import emoji

print(emoji.emojize('Water! :water_wave:'))
print(
    emoji.demojize(
        ' at runtime expect NOT to see a picture here, but regular text instead -->    🌊'
    )
)
print(emoji.demojize('🌊'))

--- END OF example/example.py ---


--- START OF tests/conftest.py ---
from typing import List
import random
import functools

import pytest


def pytest_sessionstart():
    # Increase cache size to unlimited size to avoid cache misses during tests
    import emoji.unicode_codes

    emoji.unicode_codes.get_emoji_by_name = functools.lru_cache(maxsize=None)(
        emoji.unicode_codes.get_emoji_by_name.__wrapped__
    )


def pytest_addoption(parser: pytest.Parser):
    parser.addoption(
        '--shuffle',
        dest='shuffle',
        action='store_true',
        default=False,
        help='Run tests in random order',
    )


def pytest_collection_modifyitems(session: pytest.Session, items: List[pytest.Item]):
    if session.config.getoption('shuffle'):
        print('')
        print('Shuffling items for a random test order')
        random.shuffle(items)

--- END OF tests/conftest.py ---


--- START OF tests/test_zwj_remove.py ---
"""Tests for emoji that consist of multiple emoji joined with a u200D (ZWJ - zero width joiner)
This file contains tests when the ZWJ is removed by demojize/replace_emoji.
See test_zwj_keep.py for tests when the ZWJ is kept.
"""

from typing import Any, Dict
import emoji


def ascii(s: str) -> str:
    # return escaped Code points \U000AB123
    return s.encode('unicode-escape').decode()


def test_non_rgi_zwj_demojize():
    # These emoji are non-RGI ZWJ sequences. They should be decoded by demojize to their constituents.
    # They cannot be reversed with emojize(demojize(nonRGI)) because the \u200d is stripped by demojize.
    emoji.config.demojize_keep_zwj = False

    assert (
        emoji.demojize(
            '\U0001f468\u200d\U0001f469\U0001f3ff\u200d\U0001f467\U0001f3fb\u200d\U0001f466\U0001f3fe'
        )
        == ':man::woman_dark_skin_tone::girl_light_skin_tone::boy_medium-dark_skin_tone:'
    )

    assert (
        emoji.demojize(
            '\U0001f468\U0001f3ff\u200d\U0001f469\U0001f3ff\u200d\U0001f467\U0001f3fb\u200d\U0001f466\U0001f3fe'
        )
        == ':man_dark_skin_tone::woman_dark_skin_tone::girl_light_skin_tone::boy_medium-dark_skin_tone:'
    )

    assert (
        emoji.demojize(
            '\U0001f468\U0001f3ff\u200d\U0001f469\u200d\U0001f467\U0001f3fb\u200d\U0001f466'
        )
        == ':man_dark_skin_tone::family_woman_girl::light_skin_tone::boy:'
    )

    # https://www.unicode.org/Public/15.0.0/ucd/auxiliary/GraphemeBreakTest-15.0.0d1.html#s19
    assert (
        emoji.demojize('\U0001f3ff\U0001f476\u200d\U0001f6d1')
        == ':dark_skin_tone::baby::stop_sign:'
    )

    # https://www.unicode.org/Public/15.0.0/ucd/auxiliary/GraphemeBreakTest-15.0.0d1.html#s20
    # Check that \u200d is kept, if it not part of a valid ZWJ emoji
    assert (
        emoji.demojize('\U0001f476\U0001f3ff\u0308\u200d\U0001f476\U0001f3ff')
        == ':baby_dark_skin_tone:\u0308\u200d:baby_dark_skin_tone:'
    )


def test_malformed_zwj_demojize():
    # These sequences are malformed in the sense that they are neither RGI nor non-RGI ZWJ sequences
    # Check that still all the emoji are decoded
    emoji.config.demojize_keep_zwj = False

    result = emoji.demojize(
        '\U0001f468\u200d\U0001f3ff\u200d\U0001f467\U0001f3fb\u200d\U0001f466\U0001f3fe'
    )
    assert '\U0001f468' not in result
    assert '\U0001f3ff' not in result
    assert '\U0001f467\U0001f3fb' not in result
    assert '\U0001f466\U0001f3fe' not in result

    result = emoji.demojize(
        '\U0001f3ff\u200d\U0001f468\u200d\U0001f467\U0001f3fb\u200d\U0001f466\U0001f3fe'
    )
    assert '\U0001f468' not in result
    assert '\U0001f3ff' not in result
    assert '\U0001f467\U0001f3fb' not in result
    assert '\U0001f466\U0001f3fe' not in result

    # Mix of emoji and other characters
    # Check that still all the emoji are decoded

    result = emoji.demojize(
        '\U0001f468\U0001f3ff\u200dabcd\u200d\U0001f467\U0001f3fb\u200d\U0001f466\U0001f3fe'
    )
    assert '\U0001f468\U0001f3ff' not in result
    assert '\U0001f467\U0001f3fb' not in result
    assert '\U0001f466\U0001f3fe' not in result
    assert ':man_dark_skin_tone:' in result
    assert 'abcd' in result
    assert ':girl_light_skin_tone:' in result
    assert ':boy_medium-dark_skin_tone:' in result

    result = emoji.demojize(
        'W\u200d\U0001f469\U0001f3ff\u200d\U0001f467\U0001f3fb\u200d\U0001f466\U0001f3fe'
    )
    assert '\U0001f469\U0001f3ff' not in result
    assert '\U0001f467\U0001f3fb' not in result
    assert '\U0001f466\U0001f3fe' not in result
    assert result.startswith('W')
    assert ':woman_dark_skin_tone:' in result
    assert ':girl_light_skin_tone:' in result
    assert ':boy_medium-dark_skin_tone:' in result

    result = emoji.demojize('\U0001f9d1\U0001f3fe\u200d\u200d\U0001f393')
    assert '\U0001f9d1\U0001f3fe' not in result
    assert '\U0001f393' not in result
    assert ':person_medium-dark_skin_tone:' in result
    assert ':graduation_cap:' in result


def test_non_rgi_zwj_replace():
    emoji.config.replace_emoji_keep_zwj = False

    assert (
        emoji.replace_emoji(
            '\U0001f468\u200d\U0001f469\U0001f3ff\u200d\U0001f467\U0001f3fb\u200d\U0001f466\U0001f3fe',
            '',
        )
        == ''
    )
    assert (
        emoji.replace_emoji(
            '\U0001f468\u200d\U0001f469\U0001f3ff\u200d\U0001f467\U0001f3fb\u200d\U0001f466\U0001f3fe',
            'X',
        )
        == 'XXXX'
    )

    assert (
        emoji.replace_emoji(
            '\U0001f468\U0001f3ff\u200d\U0001f469\U0001f3ff\u200d\U0001f467\U0001f3fb\u200d\U0001f466\U0001f3fe',
            '',
        )
        == ''
    )
    assert (
        emoji.replace_emoji(
            '\U0001f468\U0001f3ff\u200d\U0001f469\U0001f3ff\u200d\U0001f467\U0001f3fb\u200d\U0001f466\U0001f3fe',
            'X',
        )
        == 'XXXX'
    )

    assert (
        emoji.replace_emoji(
            '\U0001f468\U0001f3ff\u200d\U0001f469\u200d\U0001f467\U0001f3fb\u200d\U0001f466',
            '',
        )
        == ''
    )
    assert (
        emoji.replace_emoji(
            '\U0001f468\U0001f3ff\u200d\U0001f469\u200d\U0001f467\U0001f3fb\u200d\U0001f466',
            'X',
        )
        == 'XXXX'
    )

    # https://www.unicode.org/Public/15.0.0/ucd/auxiliary/GraphemeBreakTest-15.0.0d1.html#s19
    assert (
        emoji.replace_emoji('\U0001f3ff\U0001f476\u200d\U0001f6d1', 'Test8')
        == 'Test8Test8Test8'
    )

    # https://www.unicode.org/Public/15.0.0/ucd/auxiliary/GraphemeBreakTest-15.0.0d1.html#s20
    # Check that \u200d is kept, if it not part of a valid ZWJ emoji
    assert (
        emoji.replace_emoji(
            '\U0001f476\U0001f3ff\u0308\u200d\U0001f476\U0001f3ff', 'Test9'
        )
        == 'Test9\u0308\u200dTest9'
    )

    # Replace with different length
    index = [0]

    def replace_f(e: str, emoji_data: Dict[str, Any]) -> str:
        index[0] += 1
        if index[0] % 2 == 0:
            return 'X'
        else:
            return 'yyy'

    assert (
        emoji.replace_emoji(
            '\U0001f468\u200d\U0001f469\U0001f3ff\u200d\U0001f467\U0001f3fb\u200d\U0001f466\U0001f3fe',
            replace_f,
        )
        == 'yyyXyyyX'
    )

--- END OF tests/test_zwj_remove.py ---


--- START OF tests/test_unicode_codes.py ---
"""Unittests for emoji.unicode_codes."""

from typing import Set
import emoji.unicode_codes
from testutils import (
    get_language_packs,
    get_aliases_unicode_dict,
    get_emoji_unicode_dict,
)


def test_emoji_english_names():
    for language, group in get_language_packs('en', 'alias'):
        for name, ucode in group.items():
            assert name.startswith(':') and name.endswith(':') and len(name) >= 3
            emj = emoji.emojize(name, language=language)
            assert emj == ucode, '"%s" == "%s"' % (emj, ucode)


def test_compare_normal_and_aliases():
    # There should always be more aliases than normal codes
    # since the aliases contain the normal codes

    english_pack = get_emoji_unicode_dict('en')
    alias_pack = get_aliases_unicode_dict()

    assert len(english_pack) < len(alias_pack)


def test_no_alias_duplicates():
    # There should not be two emoji with the same alias
    # (aliases still can be the same as another 'en'-name)
    all_aliases: Set[str] = set()
    for data in emoji.EMOJI_DATA.values():
        if data['status'] <= emoji.STATUS['fully_qualified'] and 'alias' in data:
            for alias in data['alias']:
                assert alias not in all_aliases
                all_aliases.add(alias)


def test_get_emoji_by_alias():
    # Compare get_emoji_by_name() to get_aliases_unicode_dict()
    for alias, emj in get_aliases_unicode_dict().items():
        assert emoji.unicode_codes.get_emoji_by_name(alias, 'alias') == emj


def test_get_emoji_by_name():
    # Compare get_emoji_by_name() to get_emoji_unicode_dict()
    for lang in emoji.LANGUAGES:
        for name, emj in get_emoji_unicode_dict(lang).items():
            assert emoji.unicode_codes.get_emoji_by_name(name, lang) == emj

--- END OF tests/test_unicode_codes.py ---


--- START OF tests/test_zwj_keep.py ---
"""Tests for emoji that consist of multiple emoji joined with a u200D (ZWJ - zero width joiner)
This file contains tests when the ZWJ is kept in place by demojize/replace_emoji.
See test_zwj_remove.py for tests when the ZWJ is removed.
"""

from typing import Any, Dict
import emoji


def ascii(s: str) -> str:
    # return escaped Code points \U000AB123
    return s.encode('unicode-escape').decode()


def test_non_rgi_zwj_demojize():
    # These emoji are non-RGI ZWJ sequences. They should be decoded by demojize to their constituents.
    emoji.config.demojize_keep_zwj = True

    assert (
        emoji.demojize(
            '\U0001f468\u200d\U0001f469\U0001f3ff\u200d\U0001f467\U0001f3fb\u200d\U0001f466\U0001f3fe'
        )
        == ':man:\u200d:woman_dark_skin_tone:\u200d:girl_light_skin_tone:\u200d:boy_medium-dark_skin_tone:'
    )

    assert (
        emoji.demojize(
            '\U0001f468\U0001f3ff\u200d\U0001f469\U0001f3ff\u200d\U0001f467\U0001f3fb\u200d\U0001f466\U0001f3fe'
        )
        == ':man_dark_skin_tone:\u200d:woman_dark_skin_tone:\u200d:girl_light_skin_tone:\u200d:boy_medium-dark_skin_tone:'
    )

    assert (
        emoji.demojize(
            '\U0001f468\U0001f3ff\u200d\U0001f469\u200d\U0001f467\U0001f3fb\u200d\U0001f466'
        )
        == ':man_dark_skin_tone:\u200d:family_woman_girl::light_skin_tone:\u200d:boy:'
    )

    # https://www.unicode.org/Public/15.0.0/ucd/auxiliary/GraphemeBreakTest-15.0.0d1.html#s19
    assert (
        emoji.demojize('\U0001f3ff\U0001f476\u200d\U0001f6d1')
        == ':dark_skin_tone::baby:\u200d:stop_sign:'
    )

    # https://www.unicode.org/Public/15.0.0/ucd/auxiliary/GraphemeBreakTest-15.0.0d1.html#s20
    # Check that \u200d is kept, if it not part of a valid ZWJ emoji
    assert (
        emoji.demojize('\U0001f476\U0001f3ff\u0308\u200d\U0001f476\U0001f3ff')
        == ':baby_dark_skin_tone:\u0308\u200d:baby_dark_skin_tone:'
    )


def test_malformed_zwj_demojize():
    # These sequences are malformed in the sense that they are neither RGI nor non-RGI ZWJ sequences
    # Check that still all the emoji are decoded
    emoji.config.demojize_keep_zwj = True

    result = emoji.demojize(
        '\U0001f468\u200d\U0001f3ff\u200d\U0001f467\U0001f3fb\u200d\U0001f466\U0001f3fe'
    )
    assert '\U0001f468' not in result
    assert '\U0001f3ff' not in result
    assert '\U0001f467\U0001f3fb' not in result
    assert '\U0001f466\U0001f3fe' not in result

    result = emoji.demojize(
        '\U0001f3ff\u200d\U0001f468\u200d\U0001f467\U0001f3fb\u200d\U0001f466\U0001f3fe'
    )
    assert '\U0001f468' not in result
    assert '\U0001f3ff' not in result
    assert '\U0001f467\U0001f3fb' not in result
    assert '\U0001f466\U0001f3fe' not in result

    # Mix of emoji and other characters
    # Check that still all the emoji are decoded
    result = emoji.demojize(
        '\U0001f468\U0001f3ff\u200dabcd\u200d\U0001f467\U0001f3fb\u200d\U0001f466\U0001f3fe'
    )
    assert '\U0001f468\U0001f3ff' not in result
    assert '\U0001f467\U0001f3fb' not in result
    assert '\U0001f466\U0001f3fe' not in result
    assert result.count('\u200d') == 3
    assert ':man_dark_skin_tone:' in result
    assert 'abcd' in result
    assert ':girl_light_skin_tone:' in result
    assert ':boy_medium-dark_skin_tone:' in result

    result = emoji.demojize(
        'W\u200d\U0001f469\U0001f3ff\u200d\U0001f467\U0001f3fb\u200d\U0001f466\U0001f3fe'
    )
    assert '\U0001f469\U0001f3ff' not in result
    assert '\U0001f467\U0001f3fb' not in result
    assert '\U0001f466\U0001f3fe' not in result
    assert result.count('\u200d') == 3
    assert result.startswith('W')
    assert ':woman_dark_skin_tone:' in result
    assert ':girl_light_skin_tone:' in result
    assert ':boy_medium-dark_skin_tone:' in result

    result = emoji.demojize('\U0001f9d1\U0001f3fe\u200d\u200d\U0001f393')
    assert '\U0001f9d1\U0001f3fe' not in result
    assert '\U0001f393' not in result
    assert result.count('\u200d') == 2
    assert ':person_medium-dark_skin_tone:' in result
    assert ':graduation_cap:' in result


def test_non_rgi_zwj_replace():
    emoji.config.replace_emoji_keep_zwj = True

    assert (
        emoji.replace_emoji(
            '\U0001f468\u200d\U0001f469\U0001f3ff\u200d\U0001f467\U0001f3fb\u200d\U0001f466\U0001f3fe',
            '',
        )
        == ''
    )
    assert (
        emoji.replace_emoji(
            '\U0001f468\u200d\U0001f469\U0001f3ff\u200d\U0001f467\U0001f3fb\u200d\U0001f466\U0001f3fe',
            'X',
        )
        == 'X'
    )

    assert (
        emoji.replace_emoji(
            '\U0001f468\U0001f3ff\u200d\U0001f469\U0001f3ff\u200d\U0001f467\U0001f3fb\u200d\U0001f466\U0001f3fe',
            '',
        )
        == ''
    )
    assert (
        emoji.replace_emoji(
            '\U0001f468\U0001f3ff\u200d\U0001f469\U0001f3ff\u200d\U0001f467\U0001f3fb\u200d\U0001f466\U0001f3fe',
            'X',
        )
        == 'X'
    )

    assert (
        emoji.replace_emoji(
            '\U0001f468\U0001f3ff\u200d\U0001f469\u200d\U0001f467\U0001f3fb\u200d\U0001f466',
            '',
        )
        == ''
    )
    assert (
        emoji.replace_emoji(
            '\U0001f468\U0001f3ff\u200d\U0001f469\u200d\U0001f467\U0001f3fb\u200d\U0001f466',
            'X',
        )
        == 'XX'
    )

    assert emoji.replace_emoji('\U0001f3ff\U0001f476\u200d\U0001f6d1', 'X') == 'XX'

    assert (
        emoji.replace_emoji('\U0001f476\U0001f3ff\u0308\u200d\U0001f476\U0001f3ff', 'X')
        == 'X\u0308\u200dX'
    )

    # Replace with different length
    index = [0]

    def replace_f(e: str, emoji_data: Dict[str, Any]) -> str:
        index[0] += 1
        if index[0] % 2 == 0:
            return 'X'
        else:
            return 'yyy'

    assert (
        emoji.replace_emoji(
            'A\U0001f468\u200d\U0001f469\U0001f3ff\u200d\U0001f467\U0001f3fb\u200d\U0001f466\U0001f3fe\U0001f468\U0001f3fb\u200d\U0001f469\U0001f3fc\u200d\U0001f467\U0001f3fe\U0001f469\U0001f3feB',
            replace_f,
        )
        == 'AyyyXyyyB'
    )


def test_non_rgi_zwj_reversible():
    emoji.config.demojize_keep_zwj = True
    for emj in [
        '\U0001f468\u200d\U0001f469\U0001f3ff\u200d\U0001f467\U0001f3fb\u200d\U0001f466\U0001f3fe',
        '\U0001f468\U0001f3ff\u200d\U0001f469\U0001f3ff\u200d\U0001f467\U0001f3fb\u200d\U0001f466\U0001f3fe',
        '\U0001f468\U0001f3ff\u200d\U0001f469\U0001f3fe\u200d\U0001f466\U0001f3fd\u200d\U0001f467\U0001f3fb',
        'Test \U0001f468\u200d\U0001f469\U0001f3ff\u200d\U0001f467\U0001f3fb\u200d\U0001f466\U0001f3fe abc',
        '\U0001f468\U0000200d\U00002708\U0000fe0f\U0001f468\U0001f3ff\u200d\U0001f469\U0001f3ff\u200d\U0001f467\U0001f3fb\u200d\U0001f466\U0001f3fe',
        '\U0001f468\U0001f3ff\u200d\U0001f469\U0001f3fe\u200d\U0001f466\U0001f3fd\u200d\U0001f467\U0001f3fb\U0001f64e\U0001f3fd\U0000200d\U00002642\U0000fe0f',
        '\U0001f468\u200d\U0001f469\U0001f3ff\u200d\U0001f467\U0001f3fb\u200d\U0001f466\U0001f3fe\U0001f468\u200d\U0001f469\U0001f3ff\u200d\U0001f467\U0001f3fb\u200d\U0001f466\U0001f3fe',
        '\U0001f3ff\U0001f476\u200d\U0001f6d1',
    ]:
        assert emoji.emojize(emoji.demojize(emj)) == emj

--- END OF tests/test_zwj_keep.py ---


--- START OF tests/test_core.py ---
"""Unittests for emoji.core"""

import random
import re
import sys

from typing import Any, Callable, Dict, List, Tuple, Union
if sys.version_info < (3, 9):
    from typing_extensions import Literal  # type: ignore
else:
    from typing import Literal
import pytest
import emoji.unicode_codes
from testutils import (
    ascii,
    normalize,
    all_language_packs,
    all_language_and_alias_packs,
    get_emoji_unicode_dict,
    load_all_languages as load_all_languages,
)

try:
    from typeguard import suppress_type_checks  # type:ignore
except ImportError:
    from contextlib import nullcontext as suppress_type_checks  # type:ignore


def test_emojize_name_only(load_all_languages):  # type:ignore
    # Check that the regular expression emoji.core._EMOJI_NAME_PATTERN contains all the necesseary characters
    from emoji.core import _EMOJI_NAME_PATTERN  # pyright: ignore [reportPrivateUsage]

    pattern = re.compile('[^%s]' % (_EMOJI_NAME_PATTERN,))

    for lang_code, emoji_pack in all_language_and_alias_packs():
        for name_in_db in emoji_pack.keys():
            pairs = [
                ('Form from EMOJI_DATA', name_in_db),
                ('NFKC', normalize('NFKC', name_in_db)),
                ('NFKD', normalize('NFKD', name_in_db)),
                ('NFD', normalize('NFD', name_in_db)),
                ('NFC', normalize('NFC', name_in_db)),
            ]
            for form, name in pairs:
                actual = emoji.emojize(name, language=lang_code)
                expected = emoji_pack[name_in_db]

                if expected != actual:
                    print('Regular expression is missing a character:')
                    print('Emoji name %r in form %r contains:' % (name, form))
                    print(
                        '\n'.join(
                            [
                                '%r (%r) is not in the regular expression'
                                % (x, x.encode('unicode-escape').decode())
                                for x in pattern.findall(name[1:-1])
                            ]
                        )
                    )

                assert expected == actual, '%s != %s' % (expected, actual)
                assert pattern.search(name[1:-1]) is None


def test_regular_expression_minimal(load_all_languages):  # type:ignore
    # Check that the regular expression emoji.core._EMOJI_NAME_PATTERN only contains the necesseary characters
    from emoji.core import _EMOJI_NAME_PATTERN  # pyright: ignore [reportPrivateUsage]

    pattern_str = '[^%s]' % (_EMOJI_NAME_PATTERN,)
    i = 2
    while i < len(pattern_str) - 1:
        c = pattern_str[i]
        if c == '\\':
            i += 2
            continue
        pattern = re.compile(pattern_str.replace(c, ''))
        failed = False
        for _, emoji_pack in all_language_and_alias_packs():
            for name_in_db in emoji_pack.keys():
                name_in_db = name_in_db[1:-1]
                names = [
                    name_in_db,
                    normalize('NFKC', name_in_db),
                    normalize('NFKD', name_in_db),
                    normalize('NFD', name_in_db),
                    normalize('NFC', name_in_db),
                ]
                for str in names:
                    if pattern.search(str):
                        failed = True
                        break
            if failed:
                break
        if not failed:
            assert failed, 'char: %r is not necessary in regular expression' % (c,)

        i += 1


def test_emojize_complicated_string():
    # A bunch of emoji's with UTF-8 strings to make sure the regex expression is functioning
    name_code = {
        ':flag_for_Ceuta_&_Melilla:': '\U0001f1ea\U0001f1e6',
        ':flag_for_St._Barthélemy:': '\U0001f1e7\U0001f1f1',
        ':flag_for_Côte_d’Ivoire:': '\U0001f1e8\U0001f1ee',
        ':flag_for_Åland_Islands:': '\U0001f1e6\U0001f1fd',
        ':flag_for_São_Tomé_&_Príncipe:': '\U0001f1f8\U0001f1f9',
        ':flag_for_Curaçao:': '\U0001f1e8\U0001f1fc',
    }
    string = ' complicated! '.join(list(name_code.keys()))
    actual = emoji.emojize(string)
    expected = string
    for name, code in name_code.items():
        expected = expected.replace(name, code)
    expected = emoji.emojize(actual)
    assert expected == actual, '%s != %s' % (expected, actual)


def test_emojize_languages(load_all_languages):  # type:ignore
    for lang_code, emoji_pack in all_language_packs():
        for name, emj in emoji_pack.items():
            assert emoji.emojize(name, language=lang_code) == emj


def test_demojize_languages(load_all_languages):  # type:ignore
    for lang_code, emoji_pack in all_language_packs():
        for name, emj in emoji_pack.items():
            assert emoji.demojize(emj, language=lang_code) == name


def test_emojize_variant():
    def remove_variant(s: str) -> str:
        return re.sub('[\ufe0e\ufe0f]$', '', s)

    english_pack = get_emoji_unicode_dict('en')

    assert emoji.emojize(':Taurus:', variant=None) == english_pack[':Taurus:']
    assert emoji.emojize(':Taurus:', variant=None) == emoji.emojize(':Taurus:')
    assert (
        emoji.emojize(':Taurus:', variant='text_type')
        == remove_variant(english_pack[':Taurus:']) + '\ufe0e'
    )
    assert (
        emoji.emojize(':Taurus:', variant='emoji_type')
        == remove_variant(english_pack[':Taurus:']) + '\ufe0f'
    )

    assert (
        emoji.emojize(':admission_tickets:', variant=None)
        == english_pack[':admission_tickets:']
    )
    assert emoji.emojize(':admission_tickets:', variant=None) == emoji.emojize(
        ':admission_tickets:'
    )
    assert (
        emoji.emojize(':admission_tickets:', variant='text_type')
        == remove_variant(english_pack[':admission_tickets:']) + '\ufe0e'
    )
    assert (
        emoji.emojize(':admission_tickets:', variant='emoji_type')
        == remove_variant(english_pack[':admission_tickets:']) + '\ufe0f'
    )

    with suppress_type_checks():  # type:ignore
        with pytest.raises(ValueError):
            emoji.emojize(':admission_tickets:', variant=False)  # type: ignore[arg-type]

        with pytest.raises(ValueError):
            emoji.emojize(':admission_tickets:', variant=True)  # type: ignore[arg-type]

        with pytest.raises(ValueError):
            emoji.emojize(':admission_tickets:', variant='wrong')  # type: ignore[arg-type]

    assert emoji.emojize(':football:') == ':football:'
    assert emoji.emojize(':football:', variant='text_type') == ':football:'
    assert emoji.emojize(':football:', language='alias') == '\U0001f3c8'
    assert (
        emoji.emojize(':football:', variant='emoji_type', language='alias')
        == '\U0001f3c8'
    )


def test_demojize_removes_variant():
    # demojize should remove all variant indicators \ufe0e and \ufe0f from the string
    text = ''.join(
        [
            emoji.emojize(':Taurus:', variant='text_type'),
            emoji.emojize(':Taurus:', variant='emoji_type'),
            emoji.emojize(':admission_tickets:', variant='text_type'),
            emoji.emojize(':admission_tickets:', variant='emoji_type'),
            emoji.emojize(':alien:', variant='text_type'),
            emoji.emojize(':alien:', variant='emoji_type'),
            emoji.emojize(':atom_symbol:', variant='text_type'),
            emoji.emojize(':atom_symbol:', variant='emoji_type'),
        ]
    )

    for lang_code in emoji.LANGUAGES:
        result = emoji.demojize(text, language=lang_code)
        assert '\ufe0e' not in result
        assert '\ufe0f' not in result


def test_emojize_invalid_emoji():
    string = '__---___--Invalid__--__-Name'
    assert emoji.emojize(string) == string

    string = ':: baby:: :_: : : :  : :-: :+:'
    assert emoji.emojize(string) == string


def test_emojize_version(load_all_languages):  # type:ignore
    assert (
        emoji.emojize('Flags like :Belgium: are in version 2.0', version=1.0)
        == 'Flags like  are in version 2.0'
    )
    assert (
        emoji.emojize('Flags like :Belgium: are in version 2.0', version=1.9)
        == 'Flags like  are in version 2.0'
    )
    assert (
        emoji.emojize('Flags like :Belgium: are in version 2.0', version=2.0)
        == 'Flags like 🇧🇪 are in version 2.0'
    )
    assert (
        emoji.emojize('Flags like :Belgium: are in version 2.0', version=3.0)
        == 'Flags like 🇧🇪 are in version 2.0'
    )
    assert (
        emoji.emojize('Boxing gloves :boxing_glove: are in version 3.0', version=0)
        == 'Boxing gloves  are in version 3.0'
    )
    assert (
        emoji.emojize('Boxing gloves :boxing_glove: are in version 3.0', version=1)
        == 'Boxing gloves  are in version 3.0'
    )
    assert (
        emoji.emojize('Boxing gloves :boxing_glove: are in version 3.0', version=2)
        == 'Boxing gloves  are in version 3.0'
    )
    assert (
        emoji.emojize('Boxing gloves :boxing_glove: are in version 3.0', version=3)
        == 'Boxing gloves 🥊 are in version 3.0'
    )
    assert (
        emoji.emojize('Boxing gloves :boxing_glove: are in version 3.0', version=4)
        == 'Boxing gloves 🥊 are in version 3.0'
    )

    assert (
        emoji.emojize(
            'Biking :man_biking: is in 4.0', version=3.0, handle_version='<emoji>'
        )
        == 'Biking <emoji> is in 4.0'
    )
    assert (
        emoji.emojize(
            'Biking :man_biking: is in 4.0',
            version=3.0,
            handle_version=lambda e, data: '<emoji>',
        )
        == 'Biking <emoji> is in 4.0'
    )
    assert (
        emoji.emojize(
            'Biking :man_biking: is in 4.0',
            version=3.0,
            handle_version=lambda e, data: data['fr'],
        )
        == 'Biking :cycliste_homme: is in 4.0'
    )

    def f(emj: str, data: Dict[str, str]) -> str:
        assert data['E'] == 5
        return ''

    assert emoji.emojize(':bowl_with_spoon:', version=-1, handle_version=f) == ''
    assert emoji.emojize(':bowl_with_spoon:') == '\U0001f963'
    assert emoji.emojize(':bowl_with_spoon:', version=4) == ''
    assert emoji.emojize(':bowl_with_spoon:', version=4.9) == ''
    assert emoji.emojize(':bowl_with_spoon:', version=5) == '\U0001f963'
    assert emoji.emojize(':bowl_with_spoon:', version=5.1) == '\U0001f963'
    assert emoji.emojize(':bowl_with_spoon:', version=6) == '\U0001f963'
    assert emoji.emojize(':bowl_with_spoon:', version=4, handle_version='abc') == 'abc'
    assert emoji.emojize(':bowl_with_spoon:', version=4, handle_version=None) == ''
    assert emoji.emojize(':bowl_with_spoon:', version=4, handle_version='') == ''
    assert (
        emoji.emojize(
            ':bowl_with_spoon:', version=4, handle_version=lambda e, d: str(d['E'])
        )
        == '5'
    )


def test_demojize_version():
    assert (
        emoji.emojize('A :T-Rex: is eating a :croissant:', version=3.0)
        == 'A  is eating a 🥐'
    )

    assert (
        emoji.emojize(
            'A :T-Rex: is eating a :croissant:',
            version=3.0,
            handle_version='[Unsupported emoji]',
        )
        == 'A [Unsupported emoji] is eating a 🥐'
    )

    assert (
        emoji.demojize('A 🦖 is eating a 🥐', version=3.0)
        == 'A  is eating a :croissant:'
    )

    assert (
        emoji.demojize('A 🦖 is eating a 🥐', handle_version='X', version=3.0)
        == 'A X is eating a :croissant:'
    )

    assert (
        emoji.demojize('A 🦖 is eating a 🥐', handle_version='X', version=5.0)
        == 'A :T-Rex: is eating a :croissant:'
    )


def test_alias():
    # When lanugage != "alias" aliases should be passed through untouched
    assert emoji.emojize(':soccer:') == ':soccer:'
    assert emoji.emojize(':soccer:', language='alias') == '\U000026bd'
    assert emoji.emojize(':football:') == ':football:'
    assert emoji.emojize(':football:', language='alias') == '\U0001f3c8'
    # Multiple aliases for one emoji:
    assert emoji.emojize(':thumbsup:', language='alias') == emoji.emojize(
        ':+1:', language='alias'
    )
    assert emoji.emojize(':thumbsup:', language='alias') == emoji.emojize(
        ':thumbs_up:', language='alias'
    )
    assert emoji.emojize(':thumbsup:', language='alias') == '\U0001f44d'

    thumbsup = '\U0001f44d'
    assert emoji.demojize(thumbsup, language='alias') != thumbsup
    assert emoji.demojize(thumbsup, language='alias') != ':thumbs_up:'
    assert emoji.demojize(thumbsup, language='alias') != emoji.demojize(thumbsup)

    thailand = '🇹🇭'
    assert emoji.demojize(thailand, language='alias') != thailand
    assert emoji.demojize(thailand, language='alias') != ':Thailand:'
    assert emoji.demojize(thailand, language='alias') != emoji.demojize(thailand)
    assert emoji.demojize(thailand, language='alias', version=1.0) != emoji.demojize(
        thailand, language='alias'
    )

    # No alias
    for emj, emoji_data in emoji.EMOJI_DATA.items():
        if emoji_data['status'] != emoji.STATUS['fully_qualified']:
            continue
        if 'alias' not in emoji_data:
            assert emoji.emojize(emoji_data['en'], language='alias') != emoji_data['en']
            assert emoji.demojize(emj, language='alias') == emoji_data['en']


def test_invalid_alias():
    # Invalid aliases should be passed through untouched
    assert emoji.emojize(':tester:', language='alias') == ':tester:'
    assert emoji.emojize(':footbal:', language='alias') == ':footbal:'
    assert emoji.emojize(':socer:', language='alias') == ':socer:'
    assert emoji.emojize(':socer:', language='alias', variant='text_type') == ':socer:'


def test_demojize_name_only(load_all_languages):  # type:ignore
    for emj, item in emoji.EMOJI_DATA.items():
        if item['status'] != emoji.STATUS['fully_qualified']:
            continue
        for lang_code in emoji.LANGUAGES:
            if lang_code not in item:
                continue
            name = item[lang_code]
            oneway = emoji.emojize(name, language=lang_code)
            assert oneway == emj
            roundtrip = emoji.demojize(oneway, language=lang_code)
            assert name == roundtrip, '%s != %s' % (name, roundtrip)


def test_demojize_complicated_string():
    constructed = 'testing :baby::emoji_modifier_fitzpatrick_type-3: with :eyes: :eyes::eyes: modifiers :baby::emoji_modifier_fitzpatrick_type-5: to symbols ヒㇿ'
    emojid = emoji.emojize(constructed)
    destructed = emoji.demojize(emojid)
    assert constructed == destructed, '%s != %s' % (constructed, destructed)


def test_demojize_delimiters():
    for e in ['\U000026bd', '\U0001f44d', '\U0001f3c8']:
        for d in [
            (':', ':'),
            ('}', '}'),
            ('!$', '!!$'),
            ('[123', '456]'),
            ('😁', '👌'),
            ('[', ']'),
        ]:
            s = emoji.demojize(e, delimiters=d)
            assert s.startswith(d[0])
            assert s.endswith(d[1])

    text = 'Example with an emoji%sin a sentence and %s %s %s %s multiple emoji %s%s%s%s%s in a row'
    for e in ['\U000026bd', '\U0001f44d', '\U0001f3c8']:
        for d in [
            (':', ':'),
            ('{', '}'),
            ('!$', '$!'),
            (':', '::'),
            ('::', '::'),
            ('😁', '👌'),
            ('[', ']'),
        ]:
            print('delimiter: %s' % (d,))
            text_with_unicode = text % ((e,) * 10)
            demojized_text = emoji.demojize(text_with_unicode, delimiters=d)
            assert text_with_unicode != demojized_text, (
                text_with_unicode,
                demojized_text,
            )
            assert e not in demojized_text
            assert emoji.emojize(demojized_text, delimiters=d) == text_with_unicode
            de = emoji.demojize(e, delimiters=d)
            text_with_emoji = text % ((de,) * 10)
            assert demojized_text == text_with_emoji
            assert emoji.emojize(text_with_emoji, delimiters=d) == text_with_unicode


def test_emoji_list():
    assert emoji.emoji_list('Hi, I am 👌 test')[0]['match_start'] == 9
    assert emoji.emoji_list('Hi') == []
    if (
        len('Hello 🇫🇷👌') < 10
    ):  # skip these tests on python with UCS-2 as the string length/positions are different
        assert emoji.emoji_list('Hi, I am fine. 😁') == [
            {'match_start': 15, 'match_end': 16, 'emoji': '😁'}
        ]
        assert emoji.emoji_list('Hello 🇫🇷👌') == [
            {'emoji': '🇫🇷', 'match_start': 6, 'match_end': 8},
            {'emoji': '👌', 'match_start': 8, 'match_end': 9},
        ]


def test_distinct_emoji_list():
    assert emoji.distinct_emoji_list('Hi, I am fine. 😁') == ['😁']
    assert emoji.distinct_emoji_list('Hi') == []
    assert set(emoji.distinct_emoji_list('Hello 🇫🇷👌')) == {'🇫🇷', '👌'}
    assert emoji.distinct_emoji_list('Hi, I am fine. 😁😁😁😁') == ['😁']


def test_emoji_count():
    assert emoji.emoji_count('Hi, I am fine. 😁') == 1
    assert emoji.emoji_count('Hi') == 0
    assert emoji.emoji_count('Hello 🇫🇷👌') == 2
    assert emoji.emoji_count('Hello 🇵🇱🍺🇵🇱', unique=True) == 2


def test_replace_emoji():
    assert emoji.replace_emoji('Hi, I am fine. 😁') == 'Hi, I am fine. '
    assert emoji.replace_emoji('Hi') == 'Hi'
    assert emoji.replace_emoji('Hello 🇫🇷👌') == 'Hello '
    assert emoji.replace_emoji('Hello 🇫🇷👌', 'x') == 'Hello xx'

    def replace(emj: str, data: Dict[str, str]) -> str:
        assert emj in ['🇫🇷', '👌']
        return 'x'

    assert emoji.replace_emoji('Hello 🇫🇷👌', replace) == 'Hello xx'


def test_is_emoji():
    assert emoji.is_emoji('😁')
    assert not emoji.is_emoji('H')
    assert emoji.is_emoji('🇫🇷')
    assert not emoji.is_emoji('🇫🇷🇫🇷')
    assert not emoji.is_emoji('\ufe0f')  # variation selector


def test_long_emoji():
    assert (
        emoji.demojize('This is \U0001f9d1\U0001f3fc\U0000200d\U0001f37c example text')
        == 'This is :person_feeding_baby_medium-light_skin_tone: example text'
    )
    assert (
        emoji.demojize(
            'This is \U0001f468\U0001f3ff\u200d\u2764\ufe0f\u200d\U0001f468\U0001f3ff example text \U0001f469\U0001f3fb\U0000200d\U0001f91d\U0000200d\U0001f468\U0001f3ff'
        )
        == 'This is :couple_with_heart_man_man_dark_skin_tone: example text :woman_and_man_holding_hands_light_skin_tone_dark_skin_tone:'
    )
    assert (
        emoji.demojize(
            'This is \U0001f468\U0001f3ff\u200d\u2764\ufe0f\u200d\U0001f468\U0001f3ff\U0001f468\U0001f3ff\u200d\u2764\ufe0f\u200d\U0001f48b\u200d\U0001f468\U0001f3ff example text \U0001f469\U0001f3fb\U0000200d\U0001f91d\U0000200d\U0001f468\U0001f3ff'
        )
        == 'This is :couple_with_heart_man_man_dark_skin_tone::kiss_man_man_dark_skin_tone: example text :woman_and_man_holding_hands_light_skin_tone_dark_skin_tone:'
    )
    assert (
        emoji.demojize(
            '\U0001f46b\U0001f3fb This is \U0001f468\U0001f3ff\U0001f468\U0001f3ff\u200d\u2764\ufe0f\u200d\U0001f468\U0001f3ff\U0001f468\U0001f3ff\u200d\u2764\ufe0f\u200d\U0001f48b\u200d\U0001f468\U0001f3ff example text \U0001f469\U0001f3fb\U0000200d\U0001f91d\U0000200d\U0001f468\U0001f3ff'
        )
        == ':woman_and_man_holding_hands_light_skin_tone: This is :man_dark_skin_tone::couple_with_heart_man_man_dark_skin_tone::kiss_man_man_dark_skin_tone: example text :woman_and_man_holding_hands_light_skin_tone_dark_skin_tone:'
    )
    assert (
        emoji.demojize(
            '\U0001f46b\U0001f3fb\U0001f46b\U0001f3fb\U0001f469\U0001f3fb\U0000200d\U0001f91d\U0000200d\U0001f468\U0001f3ff\U0001faf1\U0001f3fd\U0001faf1\U0001f3fd\U0000200d\U0001faf2\U0001f3ff'
        )
        == ':woman_and_man_holding_hands_light_skin_tone::woman_and_man_holding_hands_light_skin_tone::woman_and_man_holding_hands_light_skin_tone_dark_skin_tone::rightwards_hand_medium_skin_tone::handshake_medium_skin_tone_dark_skin_tone:'
    )
    s = ':crossed_fingers_medium-light_skin_tone::crossed_fingers::crossed_fingers_dark_skin_tone:'
    assert emoji.demojize(emoji.demojize(s)) == s


def test_untranslated(load_all_languages):  # type:ignore
    for item in emoji.EMOJI_DATA.values():
        if item['status'] != emoji.STATUS['fully_qualified']:
            continue
        if 'es' not in item:
            # untranslated
            value = emoji.emojize(item['en'], language='en')
            roundtrip = emoji.demojize(value, language='es')
            assert roundtrip == value, '%s != %s (from %s)' % (
                ascii(roundtrip),
                ascii(value),
                item['en'],
            )
        else:
            # translated
            value = emoji.emojize(item['en'], language='en')
            roundtrip = emoji.demojize(value, language='es')
            assert roundtrip == item['es'], '%s != %s' % (roundtrip, item['es'])


def test_text(load_all_languages):  # type:ignore
    emoji.config.demojize_keep_zwj = True  # Restore default config value
    emoji.config.replace_emoji_keep_zwj = False  # Restore default config value

    UCS2 = len('Hello 🇫🇷👌') > 9  # don't break up characters on python with UCS-2

    text = """Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.
Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.
Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur.
Excepteur sint occaecat in reprehenderit in cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.
Stróż pchnął kość w quiz gędźb vel fax myjń.
Høj bly gom vandt fræk sexquiz på wc.
Съешь же ещё этих мягких французских булок, да выпей чаю.
За миг бях в чужд плюшен скърцащ фотьойл.
هلا سكنت بذي ضغثٍ فقد زعموا — شخصت تطلب ظبياً راح مجتازا
שפן אכל קצת גזר בטעם חסה, ודי
ऋषियों को सताने वाले दुष्ट राक्षसों के राजा रावण का सर्वनाश करने वाले विष्णुवतार भगवान श्रीराम, अयोध्या के महाराज दशरथ के बड़े सपुत्र थे।
とりなくこゑす ゆめさませ みよあけわたる ひんかしを そらいろはえて おきつへに ほふねむれゐぬ もやのうち
視野無限廣，窗外有藍天
Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur.
Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.
"""

    def default_select(emj_data: Dict[str, Any]) -> str:
        return emj_data['en']

    def add_random_emoji(
        text: str,
        lst: List[Tuple[str, Dict[str, Any]]],
        select: Callable[[Dict[str, Any]], Union[str, Literal[False]]] = default_select,
    ) -> Tuple[str, str, List[str]]:
        emoji_list: List[str] = []
        text_with_unicode = ''
        text_with_placeholder = ''
        for i in range(0, len(text), 10):
            while True:
                emj, emj_data = random.choice(lst)
                placeholder = select(emj_data)
                if placeholder:
                    break

            if UCS2:
                j = text.find(' ', i, i + 10)
                if j == -1:
                    continue
            else:
                j = random.randint(i, i + 10)

            text_with_unicode += text[i:j]
            text_with_unicode += emj
            text_with_unicode += text[j : i + 10]

            text_with_placeholder += text[i:j]
            text_with_placeholder += placeholder
            text_with_placeholder += text[j : i + 10]

            emoji_list.append(emj)

        return text_with_unicode, text_with_placeholder, emoji_list

    def clean(s: str) -> str:
        return s.replace('\u200d', '').replace('\ufe0f', '')

    qualified_emoji_list = [
        (emj, item)
        for emj, item in emoji.EMOJI_DATA.items()
        if item['status'] == emoji.STATUS['fully_qualified']
    ]

    all_emoji_list_except_component = [
        (emj, item)
        for emj, item in emoji.EMOJI_DATA.items()
        if item['status'] >= emoji.STATUS['fully_qualified']
    ]

    # qualified emoji
    text_with_unicode, text_with_placeholder, emoji_list = add_random_emoji(
        text, qualified_emoji_list
    )
    assert emoji.demojize(text_with_unicode) == text_with_placeholder
    assert emoji.emojize(text_with_placeholder) == text_with_unicode
    if not UCS2:
        assert emoji.replace_emoji(text_with_unicode, '') == text
    assert set(emoji.distinct_emoji_list(text_with_unicode)) == set(emoji_list)
    for i, lis in enumerate(emoji.emoji_list(text_with_unicode)):
        assert lis['emoji'] == emoji_list[i]

    # qualified emoji from "es"
    def select_es(emj_data: Dict[str, Any]) -> Union[str, Literal[False]]:
        return emj_data['es'] if 'es' in emj_data else False

    text_with_unicode, text_with_placeholder, emoji_list = add_random_emoji(
        text, qualified_emoji_list, select=select_es
    )
    assert emoji.demojize(text_with_unicode, language='es') == text_with_placeholder
    assert emoji.emojize(text_with_placeholder, language='es') == text_with_unicode
    if not UCS2:
        assert emoji.replace_emoji(text_with_unicode, '') == text
    assert set(emoji.distinct_emoji_list(text_with_unicode)) == set(emoji_list)
    for i, lis in enumerate(emoji.emoji_list(text_with_unicode)):
        assert lis['emoji'] == emoji_list[i]

    # qualified emoji from "alias"
    def select_alias(emj_data: Dict[str, Any]) -> Union[str, Literal[False]]:
        return emj_data['alias'][0] if 'alias' in emj_data else False

    text_with_unicode, text_with_placeholder, emoji_list = add_random_emoji(
        text, qualified_emoji_list, select=select_alias
    )
    assert emoji.demojize(text_with_unicode, language='alias') == text_with_placeholder
    assert emoji.emojize(text_with_placeholder, language='alias') == text_with_unicode
    if not UCS2:
        assert emoji.replace_emoji(text_with_unicode, '') == text
    assert set(emoji.distinct_emoji_list(text_with_unicode)) == set(emoji_list)
    for i, lis in enumerate(emoji.emoji_list(text_with_unicode)):
        assert lis['emoji'] == emoji_list[i]

    # all emoji (except components)
    text_with_unicode, text_with_placeholder, emoji_list = add_random_emoji(
        text, all_emoji_list_except_component
    )
    assert emoji.demojize(text_with_unicode) == text_with_placeholder
    assert clean(emoji.emojize(text_with_placeholder)) == clean(text_with_unicode)
    if not UCS2:
        assert emoji.replace_emoji(text_with_unicode, '') == text
    assert set(emoji.distinct_emoji_list(text_with_unicode)) == set(emoji_list)
    for i, lis in enumerate(emoji.emoji_list(text_with_unicode)):
        assert lis['emoji'] == emoji_list[i]


def test_text_multiple_times(load_all_languages: Any):
    # Run test_text() multiple times because it relies on a random text
    for _ in range(100):
        test_text(load_all_languages)


def test_invalid_chars():
    invalidchar = '\U0001f20f'
    assert emoji.demojize(invalidchar) == invalidchar, '%r != %r' % (
        ascii(emoji.demojize(invalidchar)),
        ascii(invalidchar),
    )
    assert emoji.demojize(invalidchar) == invalidchar, '%r != %r' % (
        ascii(emoji.demojize(invalidchar)),
        ascii(invalidchar),
    )

    invalidchar = 'u\2302 ⌂'
    assert emoji.demojize(invalidchar) == invalidchar, '%r != %r' % (
        ascii(emoji.demojize(invalidchar)),
        ascii(invalidchar),
    )
    assert emoji.demojize(invalidchar) == invalidchar, '%r != %r' % (
        ascii(emoji.demojize(invalidchar)),
        ascii(invalidchar),
    )


def test_combine_with_component():
    text = 'Example of a combined emoji%sin a sentence'

    combined = emoji.emojize(text % ':woman_dark_skin_tone:')
    separated = emoji.emojize(text % ':woman::dark_skin_tone:')
    assert combined == separated, '%r != %r' % (ascii(combined), ascii(separated))

    combined = emoji.emojize(text % ':woman_dark_skin_tone_white_hair:')
    separated = emoji.emojize(text % ':woman::dark_skin_tone:\u200d:white_hair:')
    assert combined == separated, '%r != %r' % (ascii(combined), ascii(separated))


purely_emoji_testdata = [
    ('\U0001f600\ufe0f', True),
    ('\U0001f600', True),
    ('\U0001f600\U0001f600\U0001f600', True),
    ('abc', False),
    ('abc\U0001f600', False),
    ('\U0001f600c', False),
    ('\u270a\U0001f3fe', True),
]


@pytest.mark.parametrize('string,expected', purely_emoji_testdata)
def test_purely_emoji(string: str, expected: bool):
    assert emoji.purely_emoji(string) == expected

--- END OF tests/test_core.py ---


--- START OF tests/test_nfkc.py ---
"""Unittests for canonically equivalent Unicode sequences"""

import emoji
from testutils import is_normalized


def test_database_normalized():
    # Test if all names in EMOJI_DATA are in NFKC form
    for e, emoji_data in emoji.EMOJI_DATA.items():
        if 'alias' in emoji_data:
            for alias in emoji_data['alias']:
                assert is_normalized('NFKC', alias), 'Alias %r of %r is not NFKC' % (
                    alias,
                    e,
                )
        for lang in emoji.LANGUAGES:
            if lang in emoji_data:
                name = emoji_data[lang]
                assert is_normalized('NFKC', name), 'Name lang=%s of %r is not NFKC' % (
                    lang,
                    e,
                )


def test_normalized_and_not_normalized():
    pairs = [
        ['en', ':Cura\xe7ao:', ':Curac\u0327ao:'],
        ['en', ':Co\u0302te_d\u2019Ivoire:', ':Co\u0302te_d\u2019Ivoire:'],
        ['alias', ':flag_for_\xc5land_Islands:', ':flag_for_A\u030aland_Islands:'],
        ['de', ':flagge_d\xe4nemark:', ':flagge_da\u0308nemark:'],
        [
            'fr',
            ':drapeau_r\xe9publique_dominicaine:',
            ':drapeau_re\u0301publique_dominicaine:',
        ],
        ['fr', ':fl\xe8che_fin:', ':fle\u0300che_fin:'],
        ['es', ':bandera_etiop\xeda:', ':bandera_etiopi\u0301a:'],
        ['pt', ':bot\xe3o_free:', ':bota\u0303o_free:'],
        ['de', ':alter_schl\xfcssel:', ':alter_schlu\u0308ssel:'],
        [
            'fr',
            ':homme_\xe2g\xe9_peau_l\xe9g\xe8rement_mate:',
            ':homme_a\u0302ge\u0301_peau_le\u0301ge\u0300rement_mate:',
        ],
        ['pt', ':cora\xe7\xe3o_vermelho:', ':corac\u0327a\u0303o_vermelho:'],
        ['en', ':Cayman_Islands:', ':Cayman_\u2160slands:'],
        ['fr', ':c\u0153ur_rouge:', ':c\ua7f9ur_rouge:'],
    ]

    for language, normalized, other_form in pairs:
        emoji_from_normalized = emoji.emojize(normalized, language=language)
        emoji_from_other_form = emoji.emojize(other_form, language=language)
        assert emoji_from_normalized == emoji_from_other_form
        assert not emoji_from_normalized.startswith(':')

--- END OF tests/test_nfkc.py ---


--- START OF tests/test_versions.py ---
"""Unittests for versions in EMOJI_DATA"""

from typing import Any, Dict, List
import pytest
import emoji.unicode_codes
from testutils import all_language_packs


def test_emoji_versions_complete_emojize():
    # Check that every emoji has a valid version
    replacement = '<3'
    for lang_code, emoji_pack in all_language_packs():
        for name in emoji_pack.keys():
            version: List[float] = []

            def f(e: str, d: Dict[str, Any]) -> str:
                v = d['E']
                n = d[lang_code]
                assert n == name
                assert isinstance(v, (int, float))
                assert v >= 0.6
                version.append(v)
                return replacement

            r = emoji.emojize(name, language=lang_code, version=0.0, handle_version=f)
            assert len(version) == 1
            assert r == replacement


def test_emoji_versions_complete_demojize():
    # Check that every emoji has a valid version
    for lang_code, emoji_pack in all_language_packs():
        for name in emoji_pack.keys():
            version: List[float] = []

            def f(e: str, d: Dict[str, Any]) -> str:
                v = d['E']
                assert isinstance(v, (int, float))
                assert v >= 0.6
                version.append(v)
                return ''

            emoji.demojize(
                emoji.emojize(name, language=lang_code),
                language=lang_code,
                version=0.0,
                handle_version=f,
            )
            if len(version) != 1:
                print(name)
                print(
                    emoji.emojize(name, language=lang_code)
                    .encode('unicode-escape')
                    .decode('utf-8')
                )
                print(
                    emoji.demojize(
                        emoji.emojize(name, language=lang_code), language=lang_code
                    )
                    .encode('unicode-escape')
                    .decode('utf-8')
                )
            assert len(version) == 1


def test_method_version():
    # Test method "emoji.version()"

    assert emoji.version(':snake:') == 0.6
    assert emoji.version('\U0001f40d') == 0.6

    assert emoji.version(':brain:') == 5
    assert emoji.version('\U0001f9e0') == 5
    assert emoji.version(':cerebro:') == 5

    assert emoji.version('prefix :people_hugging: suffix') == 13
    assert emoji.version('prefix \U0001fac2 suffix') == 13

    assert emoji.version('\U0001f611') == 1
    assert emoji.version(':expressionless_face:') == 1
    assert emoji.version(':expressionless:') == 1

    assert emoji.version("':pouring_liquid::people_hugging:") == 14
    assert emoji.version('\U0001fad7\U0001fac2') == 14

    assert emoji.emojize(':123:', version=5, variant='text_type') == ':123:'

    with pytest.raises(ValueError):
        emoji.version('test')

    with pytest.raises(ValueError):
        emoji.version("':snak:")


def test_method_replace_version():
    # Test method "emoji.replace_emoji(string, version=X.Y)"

    assert (
        emoji.replace_emoji(
            '\U0001f40d\U0001f9e0\U0001fac2\U0001fad7\U0001fac2', version=6
        )
        == '\U0001f40d\U0001f9e0'
    )

    assert emoji.replace_emoji('Hi, I am fine. 😁', version=0) == 'Hi, I am fine. '
    assert emoji.replace_emoji('Hi', version=0) == 'Hi'
    assert emoji.replace_emoji('Hello 🇫🇷👌', version=0) == 'Hello '
    assert (
        emoji.replace_emoji(
            'Hello 🇫🇷👌',
            'x',
            version=0,
        )
        == 'Hello xx'
    )
    assert (
        emoji.replace_emoji(
            'Hello 🇫🇷👌',
            'x',
            version=1,
        )
        == 'Hello 🇫🇷👌'
    )

    def replace(emj: str, data: Dict[str, Any]) -> str:
        assert emj in ['🇫🇷', '👌']
        return 'x'

    assert emoji.replace_emoji('Hello 🇫🇷👌', replace, version=0.1) == 'Hello xx'

    assert (
        emoji.replace_emoji('A 🦖 is eating a 🥐', replace='', version=5.0)
        == 'A 🦖 is eating a 🥐'
    )

--- END OF tests/test_versions.py ---


--- START OF tests/test_json.py ---
import sys
import functools

import pytest

import emoji


@pytest.fixture
def clean_module():
    """Ensures a fresh import and init of the emoji module.
    Unloads all emoji.* modules, then loads the emoji module,
    runs the test function, then deletes all the emoji.* modules
    """
    global emoji
    for name in [
        name
        for name in sys.modules
        if name.startswith('emoji') or name.startswith('test')
    ]:
        del sys.modules[name]
    import emoji

    # Increase cache size to avoid cache misses during tests
    emoji.unicode_codes.get_emoji_by_name = functools.lru_cache(maxsize=None)(  # type:ignore
        emoji.unicode_codes.get_emoji_by_name.__wrapped__  # type:ignore
    )

    yield
    for name in [
        name
        for name in sys.modules
        if name.startswith('emoji') or name.startswith('test')
    ]:
        del sys.modules[name]

    # Increase cache size to avoid cache misses during tests
    emoji.unicode_codes.get_emoji_by_name = functools.lru_cache(maxsize=None)(  # type:ignore
        emoji.unicode_codes.get_emoji_by_name.__wrapped__  # type:ignore
    )


def test_language_loaded_after_emojize(clean_module):  # type:ignore
    emoji.emojize('string', language='es')
    assert 'es' in emoji.EMOJI_DATA[emoji.emojize(':lion:')]


def test_language_loaded_after_demojize(clean_module):  # type:ignore
    emoji.demojize('string', language='es')
    assert 'es' in emoji.EMOJI_DATA[emoji.emojize(':lion:')]


def test_language_not_auto_loaded(clean_module):  # type:ignore
    assert 'es' not in emoji.EMOJI_DATA[emoji.emojize(':lion:')]


def test_key_access_load_language(clean_module):  # type:ignore
    assert 'es' not in emoji.EMOJI_DATA[emoji.emojize(':lion:')]
    with pytest.deprecated_call():
        assert emoji.EMOJI_DATA[emoji.emojize(':lion:')]['es']
    assert 'es' in emoji.EMOJI_DATA[emoji.emojize(':lion:')]
    assert 'es' in emoji.EMOJI_DATA[emoji.emojize(':zebra:')]

    with pytest.raises(KeyError):
        emoji.EMOJI_DATA[emoji.emojize(':lion:')]['xyz']


def test_explicit_load_language(clean_module):  # type:ignore
    assert 'fr' not in emoji.EMOJI_DATA[emoji.emojize(':lion:')]
    emoji.config.load_language('fr')
    assert 'fr' in emoji.EMOJI_DATA[emoji.emojize(':lion:')]
    assert emoji.EMOJI_DATA[emoji.emojize(':lion:')]['fr'] == ':tête_de_lion:'

    assert 'es' not in emoji.EMOJI_DATA[emoji.emojize(':lion:')]
    emoji.config.load_language('es')
    assert 'es' in emoji.EMOJI_DATA[emoji.emojize(':lion:')]


def test_explict_load_all_languages(clean_module):  # type:ignore
    assert 'fr' not in emoji.EMOJI_DATA[emoji.emojize(':lion:')]
    assert 'es' not in emoji.EMOJI_DATA[emoji.emojize(':lion:')]
    emoji.config.load_language()
    assert 'es' in emoji.EMOJI_DATA[emoji.emojize(':lion:')]
    assert 'fr' in emoji.EMOJI_DATA[emoji.emojize(':lion:')]
    assert emoji.EMOJI_DATA[emoji.emojize(':lion:')]['fr'] == ':tête_de_lion:'


def test_load_language_multiple_times(clean_module):  # type:ignore
    assert 'fr' not in emoji.EMOJI_DATA[emoji.emojize(':lion:')]
    for _ in range(10000):
        emoji.config.load_language('fr')
    assert 'fr' in emoji.EMOJI_DATA[emoji.emojize(':lion:')]
    assert emoji.EMOJI_DATA[emoji.emojize(':lion:')]['fr'] == ':tête_de_lion:'


unsupported_languages = ['', ' ', '1', 'e', 'z', 'zz', 'ZZ', 'EN', 'ES', 'xyz', 'eses']


@pytest.mark.parametrize('lang', unsupported_languages)
def test_load_unsupported_language(lang: str):
    with pytest.raises(NotImplementedError):
        emoji.config.load_language(lang)


@pytest.mark.parametrize('lang', unsupported_languages)
def test_access_unsupported_language(lang: str):
    with pytest.raises(KeyError):
        emoji.EMOJI_DATA[emoji.emojize(':lion:')][lang]


@pytest.mark.parametrize('lang', unsupported_languages)
def test_emojize_unsupported_language(lang: str):
    with pytest.raises(NotImplementedError):
        emoji.emojize(':lion:', language=lang)

    with pytest.raises(NotImplementedError):
        emoji.demojize(':lion:', language=lang)

--- END OF tests/test_json.py ---


--- START OF tests/test_analyze.py ---
"""Unittests for emoji.analyze()"""

import emoji


def test_analyze():
    assert list(emoji.analyze('')) == []

    assert list(emoji.analyze('', non_emoji=True)) == []

    assert list(emoji.analyze('abc')) == []

    assert list(emoji.analyze('abc', non_emoji=True)) == [
        ('a', 'a'),
        ('b', 'b'),
        ('c', 'c'),
    ]

    result = list(emoji.analyze('abc\U0001f472'))
    assert len(result) == 1
    assert not isinstance(result[0].value, str)
    assert result[0].value.emoji == '\U0001f472'

    result = list(emoji.analyze('abc\U0001f472', non_emoji=True))
    assert result[0].value == 'a'
    assert not isinstance(result[3].value, str)
    assert result[3].value.emoji == '\U0001f472'

    result = list(emoji.analyze('\U0001f477\U0001f3fb\U0000200d\U00002640'))
    assert len(result) == 1
    assert not isinstance(result[0].value, str)
    assert result[0].value.emoji == '\U0001f477\U0001f3fb\U0000200d\U00002640'

    result = list(
        emoji.analyze('\U0001f477\U0001f3fc\U0001f477\U0001f3fb\U0000200d\U00002640')
    )
    assert len(result) == 2
    assert not isinstance(result[0].value, str)
    assert result[0].value.emoji == '\U0001f477\U0001f3fc'
    assert not isinstance(result[1].value, str)
    assert result[1].value.emoji == '\U0001f477\U0001f3fb\U0000200d\U00002640'


def test_analyze_non_rgi_zwj():
    result = list(
        emoji.analyze(
            '\U0001f468\U0001f3ff\U0000200d\U0001f469\U0001f3fb\U0000200d\U0001f467\U0001f3fd'
        )
    )
    assert len(result) == 1
    assert not isinstance(result[0].value, str)
    assert (
        result[0].value.emoji
        == '\U0001f468\U0001f3ff\U0000200d\U0001f469\U0001f3fb\U0000200d\U0001f467\U0001f3fd'
    )

    result = list(
        emoji.analyze(
            '\U0001f468\U0001f3ff\U0000200d\U0001f469\U0001f3fb\U0000200d\U0001f467\U0001f3fd',
            join_emoji=False,
        )
    )
    assert len(result) == 3
    assert not isinstance(result[0].value, str)
    assert result[0].value.emoji == '\U0001f468\U0001f3ff'
    assert not isinstance(result[1].value, str)
    assert result[1].value.emoji == '\U0001f469\U0001f3fb'
    assert not isinstance(result[2].value, str)
    assert result[2].value.emoji == '\U0001f467\U0001f3fd'

    result = list(
        emoji.analyze(
            '\U0001f468\U0001f3ff\U0000200d\U0001f469\U0001f3fb\U0000200d\U0001f467\U0001f3fdx',
            join_emoji=False,
            non_emoji=True,
        )
    )
    assert len(result) == 6
    assert not isinstance(result[0].value, str)
    assert result[0].value.emoji == '\U0001f468\U0001f3ff'
    assert result[1].value == '\U0000200d'
    assert not isinstance(result[2].value, str)
    assert result[2].value.emoji == '\U0001f469\U0001f3fb'
    assert result[3].value == '\U0000200d'
    assert not isinstance(result[4].value, str)
    assert result[4].value.emoji == '\U0001f467\U0001f3fd'
    assert result[5].value == 'x'

    result = list(
        emoji.analyze(
            '\U0001f468\U0001f3ff\U0000200d\U0001f469\U0001f3fb\U0000200d\U0001f467\U0001f3fdx',
            join_emoji=True,
            non_emoji=True,
        )
    )
    assert len(result) == 2
    assert not isinstance(result[0].value, str)
    assert (
        result[0].value.emoji
        == '\U0001f468\U0001f3ff\U0000200d\U0001f469\U0001f3fb\U0000200d\U0001f467\U0001f3fd'
    )
    assert result[1].value == 'x'

    result = list(emoji.analyze('\u200d🦷\u200d🦷'))
    assert len(result) == 1
    assert isinstance(result[0].value, emoji.EmojiMatchZWJNonRGI)

    result = list(emoji.analyze('\u200d🦷\u200d🦷', join_emoji=False))
    assert len(result) == 2
    assert all(isinstance(token.value, emoji.EmojiMatch) for token in result)

    result = list(emoji.analyze('\u200d🦷\u200d🦷', join_emoji=False, non_emoji=True))
    assert len(result) == 4
    assert result[0].value == '\u200d'
    assert isinstance(result[1].value, emoji.EmojiMatch)
    assert result[2].value == '\u200d'
    assert isinstance(result[3].value, emoji.EmojiMatch)


def test_emoji_match():
    s = 'a\U0001f309b'
    token = next(emoji.analyze(s))
    assert isinstance(token, emoji.Token)

    assert token.chars == s[1:-1]

    match = token.value

    assert isinstance(match, emoji.EmojiMatch)
    assert match.emoji == s[1:-1]
    assert match.start == 1
    assert match.end == 2
    assert not match.is_zwj()
    assert match.split() == match
    assert str(match).startswith('EmojiMatch(')

    s = 'a\U0001f468\U0000200d\U0001f467b'
    token = next(emoji.analyze(s))
    assert isinstance(token, emoji.Token)

    assert token.chars == s[1:-1]

    match = token.value

    assert isinstance(match, emoji.EmojiMatch)
    assert match.emoji == s[1:-1]
    assert match.start == 1
    assert match.end == 4
    assert match.is_zwj()
    assert str(match).startswith('EmojiMatch(')

    splitted = match.split()
    assert isinstance(splitted, emoji.EmojiMatchZWJ)
    assert splitted.emoji == s[1:-1]
    assert splitted.start == 1
    assert splitted.end == 4
    assert splitted.is_zwj()
    assert splitted.join() == s[1:-1]
    assert splitted.split() == splitted
    assert str(splitted).startswith('EmojiMatchZWJ(')
    assert len(splitted.emojis) == 2

    man, woman = splitted.emojis

    assert isinstance(man, emoji.EmojiMatch)
    assert man.start == 1
    assert man.end == 2

    assert isinstance(woman, emoji.EmojiMatch)
    assert woman.start == 3
    assert woman.end == 4

--- END OF tests/test_analyze.py ---


--- START OF tests/test_dict.py ---
"""Unittests for the big dict of dicts containing all emoji"""

from typing import Set, Dict
import re
import emoji

from testutils import load_all_languages as load_all_languages


def test_all_languages_list(load_all_languages):  # type:ignore
    """Compare all language keys in EMOJI_DATA with the emoji.LANGUAGES list"""

    langs: Set[str] = set()
    for item in emoji.EMOJI_DATA.values():
        langs.update(item.keys())
    all_languages = {lang for lang in langs if len(lang) == 2 and lang.lower() == lang}

    assert set(emoji.LANGUAGES) == all_languages


def test_emoji_versions():
    """Check that every emoji has a valid version"""
    for item in emoji.EMOJI_DATA.values():
        assert 'E' in item
        v = item['E']
        assert isinstance(v, (int, float))
        assert v >= 0.6


def check_duplicate_names(lang: str):
    """Check that there are no duplicate names in the fully_qualified except for different variants"""
    seen: Dict[str, int] = {}
    for item in emoji.EMOJI_DATA.values():
        if item['status'] > emoji.STATUS['fully_qualified']:
            continue

        if lang not in item:
            continue

        name = item[lang]
        if name in seen and 'variant' in item:
            seen[name] += 1
        else:
            assert name not in seen
            seen[name] = 0


def test_duplicate_names(load_all_languages):  # type:ignore
    """Check that there are no duplicate names in the fully_qualified except for different variants"""
    for lang in emoji.LANGUAGES:
        check_duplicate_names(lang)


def test_name_valid(load_all_languages):  # type:ignore
    """Check that every name starts with colons and does not contain other colons or whitespace"""

    pattern = re.compile(r':[^:\s]+:')
    for item in emoji.EMOJI_DATA.values():
        for lang in emoji.LANGUAGES:
            if lang in item:
                name = item[lang]
                assert pattern.match(name)

--- END OF tests/test_dict.py ---


--- START OF tests/test_zwj_common.py ---
"""Tests for emoji that consist of multiple emoji joined with a u200D (ZWJ - zero width joiner)
This file contains tests that are irrespective of keeping/removing the ZWJ.
See test_zwj_remove.py for tests when the ZWJ is removed.
See test_zwj_keep.py for tests when the ZWJ is kept.
"""

import emoji


def test_non_rgi_zwj_emoji_list():
    matches = emoji.emoji_list(
        '\U0001f468\u200d\U0001f469\U0001f3ff\u200d\U0001f467\U0001f3fb\u200d\U0001f466\U0001f3fe'
    )

    assert matches[0]['match_start'] == 0
    assert matches[0]['match_end'] == 1
    assert matches[0]['emoji'] == '\U0001f468'

    assert matches[1]['match_start'] == 2
    assert matches[1]['match_end'] == 4
    assert matches[1]['emoji'] == '\U0001f469\U0001f3ff'

    assert matches[2]['match_start'] == 5
    assert matches[2]['match_end'] == 7
    assert matches[2]['emoji'] == '\U0001f467\U0001f3fb'

    assert matches[3]['match_start'] == 8
    assert matches[3]['match_end'] == 10
    assert matches[3]['emoji'] == '\U0001f466\U0001f3fe'

    matches = emoji.emoji_list(
        'abc\U0001f468\u200d\U0001f469\U0001f3ff\u200d\U0001f467\U0001f3fb\u200d\U0001f466\U0001f3feyxz'
    )

    assert matches[0]['match_start'] == 3
    assert matches[0]['match_end'] == 4
    assert matches[0]['emoji'] == '\U0001f468'

    assert matches[1]['match_start'] == 5
    assert matches[1]['match_end'] == 7
    assert matches[1]['emoji'] == '\U0001f469\U0001f3ff'

    assert matches[2]['match_start'] == 8
    assert matches[2]['match_end'] == 10
    assert matches[2]['emoji'] == '\U0001f467\U0001f3fb'

    assert matches[3]['match_start'] == 11
    assert matches[3]['match_end'] == 13
    assert matches[3]['emoji'] == '\U0001f466\U0001f3fe'

    matches = emoji.emoji_list(
        '\U0001f9d1\U0000200d\U0001f9b3abcyxz\U0001fac5\U0001f468\U0001f3fd\u200d\U0001f467\U0001f3fc\u200d\U0001f467\U0001f3fe'
    )

    assert matches[0]['match_start'] == 0
    assert matches[0]['match_end'] == 3
    assert matches[0]['emoji'] == '\U0001f9d1\U0000200d\U0001f9b3'

    assert matches[1]['match_start'] == 9
    assert matches[1]['match_end'] == 10
    assert matches[1]['emoji'] == '\U0001fac5'

    assert matches[2]['match_start'] == 10
    assert matches[2]['match_end'] == 12
    assert matches[2]['emoji'] == '\U0001f468\U0001f3fd'

    assert matches[3]['match_start'] == 13
    assert matches[3]['match_end'] == 15
    assert matches[3]['emoji'] == '\U0001f467\U0001f3fc'

    assert matches[4]['match_start'] == 16
    assert matches[4]['match_end'] == 18
    assert matches[4]['emoji'] == '\U0001f467\U0001f3fe'


def test_non_rgi_zwj_demojize():
    result = emoji.demojize(
        '\U0001f9d1\U0001f3fc\U0000200d\U0001f3a8\U0001f468\u200d\U0001f469\U0001f3ff\u200d\U0001f467\U0001f3fb\u200d\U0001f466\U0001f3fe'
    )
    assert '\U0001f9d1\U0001f3fc\U0000200d\U0001f3a8' not in result
    assert (
        '\U0001f468\u200d\U0001f469\U0001f3ff\u200d\U0001f467\U0001f3fb\u200d\U0001f466\U0001f3fe'
        not in result
    )
    assert ':artist_medium-light_skin_tone:' in result

    result = emoji.demojize(
        'Test \U0001f6b5\U0001f3ff\U0000200d\U00002642\U0000fe0f abc \U0001f468\U0001f3ff\u200d\U0001f469\U0001f3fe\u200d\U0001f466\U0001f3fd\u200d\U0001f467\U0001f3fb'
    )
    assert '\U0001f6b5\U0001f3ff\U0000200d\U00002642\U0000fe0f' not in result
    assert (
        '\U0001f468\U0001f3ff\u200d\U0001f469\U0001f3fe\u200d\U0001f466\U0001f3fd\u200d\U0001f467\U0001f3fb'
        not in result
    )
    assert ':man_mountain_biking_dark_skin_tone:' in result


def test_malformed_zwj_no_emoji():
    s = '\u200d'
    assert emoji.replace_emoji(s) == s

    s = '\u200d\u200d'
    assert emoji.replace_emoji(s) == s

    s = '\u200d\u200d\u200d'
    assert emoji.replace_emoji(s) == s

    s = 'Has\u200din the middle'
    assert emoji.replace_emoji(s) == s

    s = '\u200dStarts With'
    assert emoji.replace_emoji(s) == s

    s = 'Ends With\u200d'
    assert emoji.replace_emoji(s) == s

    s = 'Multiple\u200d\u200d\u200din the middle'
    assert emoji.replace_emoji(s) == s

    s = '\u200d\u200dStarts With two'
    assert emoji.replace_emoji(s) == s

    s = '\u200d\u200d\u200dStarts With three'
    assert emoji.replace_emoji(s) == s

    s = 'Ends With two\u200d\u200d'
    assert emoji.replace_emoji(s) == s

    s = 'Ends With three\u200d\u200d\u200d'
    assert emoji.replace_emoji(s) == s


def test_malformed_zwj_mixed_with_emoji():
    emoji.config.demojize_keep_zwj = True  # Restore default config value

    i = 'Has🦷\u200din the middle'
    o = 'Has:tooth:\u200din the middle'
    assert emoji.demojize(i) == o, f'{i!r} != {o!r}'

    i = 'Has\u200d🦷in the middle'
    o = 'Has\u200d:tooth:in the middle'
    assert emoji.demojize(i) == o, f'{i!r} != {o!r}'

    i = '\u200d🦷Starts with'
    o = '\u200d:tooth:Starts with'
    assert emoji.demojize(i) == o, f'{i!r} != {o!r}'

    i = '🦷\u200dStarts with'
    o = ':tooth:\u200dStarts with'
    assert emoji.demojize(i) == o, f'{i!r} != {o!r}'

    i = 'Ends with \u200d🦷'
    o = 'Ends with \u200d:tooth:'
    assert emoji.demojize(i) == o, f'{i!r} != {o!r}'

    i = 'Ends with 🦷\u200d'
    o = 'Ends with :tooth:\u200d'
    assert emoji.demojize(i) == o, f'{i!r} != {o!r}'

    i = 'Multiple 🦷\u200d🦷\u200d in the middle'
    o = 'Multiple :tooth:\u200d:tooth:\u200d in the middle'
    assert emoji.demojize(i) == o, f'{i!r} != {o!r}'

    i = 'Multiple 🦷🦷\u200d\u200d in the middle'
    o = 'Multiple :tooth::tooth:\u200d\u200d in the middle'
    assert emoji.demojize(i) == o, f'{i!r} != {o!r}'

    i = 'Multiple \u200d\u200d🦷🦷 in the middle'
    o = 'Multiple \u200d\u200d:tooth::tooth: in the middle'
    assert emoji.demojize(i) == o, f'{i!r} != {o!r}'

    i = '\u200d\u200d🦷Starts with two'
    o = '\u200d\u200d:tooth:Starts with two'
    assert emoji.demojize(i) == o, f'{i!r} != {o!r}'

    i = '\u200d\u200d\u200d🦷Starts with three'
    o = '\u200d\u200d\u200d:tooth:Starts with three'
    assert emoji.demojize(i) == o, f'{i!r} != {o!r}'

    i = 'Ends with two \u200d\u200d🦷'
    o = 'Ends with two \u200d\u200d:tooth:'
    assert emoji.demojize(i) == o, f'{i!r} != {o!r}'

    i = 'Ends with two 🦷\u200d\u200d'
    o = 'Ends with two :tooth:\u200d\u200d'
    assert emoji.demojize(i) == o, f'{i!r} != {o!r}'

    i = 'Ends with three \u200d\u200d\u200d🦷'
    o = 'Ends with three \u200d\u200d\u200d:tooth:'
    assert emoji.demojize(i) == o, f'{i!r} != {o!r}'

    i = 'Ends with three 🦷\u200d\u200d\u200d'
    o = 'Ends with three :tooth:\u200d\u200d\u200d'
    assert emoji.demojize(i) == o, f'{i!r} != {o!r}'

    i = '🦷\u200d'
    o = ':tooth:\u200d'
    assert emoji.demojize(i) == o, f'{i!r} != {o!r}'

    i = '\u200d🦷'
    o = '\u200d:tooth:'
    assert emoji.demojize(i) == o, f'{i!r} != {o!r}'

    i = '\u200d\u200d🦷'
    o = '\u200d\u200d:tooth:'
    assert emoji.demojize(i) == o, f'{i!r} != {o!r}'

    i = '🦷\u200d\u200d'
    o = ':tooth:\u200d\u200d'
    assert emoji.demojize(i) == o, f'{i!r} != {o!r}'

    i = '\u200d🦷\u200d'
    o = '\u200d:tooth:\u200d'
    assert emoji.demojize(i) == o, f'{i!r} != {o!r}'

    i = '\u200d\u200d🦷\u200d\u200d'
    o = '\u200d\u200d:tooth:\u200d\u200d'
    assert emoji.demojize(i) == o, f'{i!r} != {o!r}'

    i = '\u200d\u200d\u200d🦷\u200d\u200d'
    o = '\u200d\u200d\u200d:tooth:\u200d\u200d'
    assert emoji.demojize(i) == o, f'{i!r} != {o!r}'

    i = '\u200d\u200d🦷\u200d\u200d\u200d'
    o = '\u200d\u200d:tooth:\u200d\u200d\u200d'
    assert emoji.demojize(i) == o, f'{i!r} != {o!r}'

    i = '🦷\u200d\u200d🦷\u200d\u200d\u200d'
    o = ':tooth:\u200d\u200d:tooth:\u200d\u200d\u200d'
    assert emoji.demojize(i) == o, f'{i!r} != {o!r}'

    i = '\u200d\u200d🦷🦷\u200d\u200d\u200d🦷'
    o = '\u200d\u200d:tooth::tooth:\u200d\u200d\u200d:tooth:'
    assert emoji.demojize(i) == o, f'{i!r} != {o!r}'

    i = '\u200d\u200d🦷\u200d\u200d\u200d🦷'
    o = '\u200d\u200d:tooth:\u200d\u200d\u200d:tooth:'
    assert emoji.demojize(i) == o, f'{i!r} != {o!r}'

--- END OF tests/test_zwj_common.py ---


--- START OF emoji/__init__.py ---
__all__ = [
    # emoji.core
    'emojize',
    'demojize',
    'analyze',
    'config',
    'emoji_list',
    'distinct_emoji_list',
    'emoji_count',
    'replace_emoji',
    'is_emoji',
    'purely_emoji',
    'version',
    'Token',
    'EmojiMatch',
    'EmojiMatchZWJ',
    'EmojiMatchZWJNonRGI',
    # emoji.unicode_codes
    'EMOJI_DATA',
    'STATUS',
    'LANGUAGES',
]

__version__ = '2.14.1'
__author__ = 'Taehoon Kim, Kevin Wurster'
__email__ = 'carpedm20@gmail.com'
# and wursterk@gmail.com, tahir.jalilov@gmail.com
__source__ = 'https://github.com/carpedm20/emoji/'
__license__ = """
New BSD License

Copyright (c) 2014-2025, Taehoon Kim, Kevin Wurster
All rights reserved.

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions are met:

* Redistributions of source code must retain the above copyright notice, this
  list of conditions and the following disclaimer.

* Redistributions in binary form must reproduce the above copyright notice,
  this list of conditions and the following disclaimer in the documentation
  and/or other materials provided with the distribution.

* The names of its contributors may not be used to endorse or promote products
  derived from this software without specific prior written permission.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
"""

from emoji.core import *
from emoji.unicode_codes import *

--- END OF emoji/__init__.py ---


--- START OF emoji/core.py ---
"""
emoji.core
~~~~~~~~~~

Core components for emoji.

"""

import re
import unicodedata
import sys
from typing import Any, Callable, Dict, Iterator, List, Optional, Tuple, Union

if sys.version_info < (3, 9):
    from typing_extensions import Literal, Match, TypedDict  # type: ignore
else:
    from typing import Literal, Match, TypedDict

from emoji import unicode_codes
from emoji.tokenizer import (
    Token,
    EmojiMatch,
    EmojiMatchZWJ,
    EmojiMatchZWJNonRGI,
    tokenize,
    filter_tokens,
)

__all__ = [
    'emojize',
    'demojize',
    'analyze',
    'config',
    'emoji_list',
    'distinct_emoji_list',
    'emoji_count',
    'replace_emoji',
    'is_emoji',
    'purely_emoji',
    'version',
    'Token',
    'EmojiMatch',
    'EmojiMatchZWJ',
    'EmojiMatchZWJNonRGI',
]

_DEFAULT_DELIMITER = ':'
# In Arabic language, the unicode character "\u0655" should be kept so we add it to the pattern below
_EMOJI_NAME_PATTERN = '\\w\\-&.’”“()!#*+,/«»\u0300\u0301\u0302\u0303\u0306\u0308\u030a\u0327\u064b\u064e\u064f\u0650\u0653\u0654\u3099\u30fb\u309a\u0655'


class _EmojiListReturn(TypedDict):
    emoji: str
    match_start: int
    match_end: int


class config:
    """Module-wide configuration"""

    demojize_keep_zwj = True
    """Change the behavior of :func:`emoji.demojize()` regarding
    zero-width-joiners (ZWJ/``\\u200D``) in emoji that are not
    "recommended for general interchange" (non-RGI).
    It has no effect on RGI emoji.

    For example this family emoji with different skin tones "👨‍👩🏿‍👧🏻‍👦🏾" contains four
    person emoji that are joined together by three ZWJ characters:
    ``👨\\u200D👩🏿\\u200D👧🏻\\u200D👦🏾``

    If ``True``, the zero-width-joiners will be kept and :func:`emoji.emojize()` can
    reverse the :func:`emoji.demojize()` operation:
    ``emoji.emojize(emoji.demojize(s)) == s``

    The example emoji would be converted to
    ``:man:\\u200d:woman_dark_skin_tone:\\u200d:girl_light_skin_tone:\\u200d:boy_medium-dark_skin_tone:``

    If ``False``, the zero-width-joiners will be removed and :func:`emoji.emojize()`
    can only reverse the individual emoji: ``emoji.emojize(emoji.demojize(s)) != s``

    The example emoji would be converted to
    ``:man::woman_dark_skin_tone::girl_light_skin_tone::boy_medium-dark_skin_tone:``
    """

    replace_emoji_keep_zwj = False
    """Change the behavior of :func:`emoji.replace_emoji()` regarding
    zero-width-joiners (ZWJ/``\\u200D``) in emoji that are not
    "recommended for general interchange" (non-RGI).
    It has no effect on RGI emoji.

    See :attr:`config.demojize_keep_zwj` for more information.
    """

    @staticmethod
    def load_language(language: Union[List[str], str, None] = None):
        """Load one or multiple languages into memory.
        If no language is specified, all languages will be loaded.

        This makes language data accessible in the :data:`EMOJI_DATA` dict.
        For example to access a French emoji name, first load French with

         ``emoji.config.load_language('fr')``

        and then access it with

         ``emoji.EMOJI_DATA['🏄']['fr']``

        Available languages are listed in :data:`LANGUAGES`"""

        languages = (
            [language]
            if isinstance(language, str)
            else language
            if language
            else unicode_codes.LANGUAGES
        )

        for lang in languages:
            unicode_codes.load_from_json(lang)


def emojize(
    string: str,
    delimiters: Tuple[str, str] = (_DEFAULT_DELIMITER, _DEFAULT_DELIMITER),
    variant: Optional[Literal['text_type', 'emoji_type']] = None,
    language: str = 'en',
    version: Optional[float] = None,
    handle_version: Optional[Union[str, Callable[[str, Dict[str, str]], str]]] = None,
) -> str:
    """
    Replace emoji names in a string with Unicode codes.
        >>> import emoji
        >>> print(emoji.emojize("Python is fun :thumbsup:", language='alias'))
        Python is fun 👍
        >>> print(emoji.emojize("Python is fun :thumbs_up:"))
        Python is fun 👍
        >>> print(emoji.emojize("Python is fun {thumbs_up}", delimiters = ("{", "}")))
        Python is fun 👍
        >>> print(emoji.emojize("Python is fun :red_heart:", variant="text_type"))
        Python is fun ❤
        >>> print(emoji.emojize("Python is fun :red_heart:", variant="emoji_type"))
        Python is fun ❤️ # red heart, not black heart

    :param string: String contains emoji names.
    :param delimiters: (optional) Use delimiters other than _DEFAULT_DELIMITER. Each delimiter
        should contain at least one character that is not part of a-zA-Z0-9 and ``_-&.()!?#*+,``.
        See ``emoji.core._EMOJI_NAME_PATTERN`` for the regular expression of unsafe characters.
    :param variant: (optional) Choose variation selector between "base"(None), VS-15 ("text_type") and VS-16 ("emoji_type")
    :param language: Choose language of emoji name: language code 'es', 'de', etc. or 'alias'
        to use English aliases
    :param version: (optional) Max version. If set to an Emoji Version,
        all emoji above this version will be ignored.
    :param handle_version: (optional) Replace the emoji above ``version``
        instead of ignoring it. handle_version can be either a string or a
        callable; If it is a callable, it's passed the Unicode emoji and the
        data dict from :data:`EMOJI_DATA` and must return a replacement string
        to be used::

            handle_version('\\U0001F6EB', {
                'en' : ':airplane_departure:',
                'status' : fully_qualified,
                'E' : 1,
                'alias' : [':flight_departure:'],
                'de': ':abflug:',
                'es': ':avión_despegando:',
                ...
            })

    :raises ValueError: if ``variant`` is neither None, 'text_type' or 'emoji_type'

    """

    unicode_codes.load_from_json(language)

    pattern = re.compile(
        '(%s[%s]+%s)'
        % (re.escape(delimiters[0]), _EMOJI_NAME_PATTERN, re.escape(delimiters[1]))
    )

    def replace(match: Match[str]) -> str:
        name = match.group(1)[len(delimiters[0]) : -len(delimiters[1])]
        emj = unicode_codes.get_emoji_by_name(
            _DEFAULT_DELIMITER
            + unicodedata.normalize('NFKC', name)
            + _DEFAULT_DELIMITER,
            language,
        )

        if emj is None:
            return match.group(1)

        if version is not None and unicode_codes.EMOJI_DATA[emj]['E'] > version:
            if callable(handle_version):
                emj_data = unicode_codes.EMOJI_DATA[emj].copy()
                emj_data['match_start'] = match.start()
                emj_data['match_end'] = match.end()
                return handle_version(emj, emj_data)

            elif handle_version is not None:
                return str(handle_version)
            else:
                return ''

        if variant is None or 'variant' not in unicode_codes.EMOJI_DATA[emj]:
            return emj

        if emj[-1] == '\ufe0e' or emj[-1] == '\ufe0f':
            # Remove an existing variant
            emj = emj[0:-1]
        if variant == 'text_type':
            return emj + '\ufe0e'
        elif variant == 'emoji_type':
            return emj + '\ufe0f'
        else:
            raise ValueError(
                "Parameter 'variant' must be either None, 'text_type' or 'emoji_type'"
            )

    return pattern.sub(replace, string)


def analyze(
    string: str, non_emoji: bool = False, join_emoji: bool = True
) -> Iterator[Token]:
    """
    Find unicode emoji in a string. Yield each emoji as a named tuple
    :class:`Token` ``(chars, EmojiMatch)`` or :class:`Token` ``(chars, EmojiMatchZWJNonRGI)``.
    If ``non_emoji`` is True, also yield all other characters as
    :class:`Token` ``(char, char)`` .

    :param string: String to analyze
    :param non_emoji: If True also yield all non-emoji characters as Token(char, char)
    :param join_emoji: If True, multiple EmojiMatch are merged into a single
        EmojiMatchZWJNonRGI if they are separated only by a ZWJ.
    """

    return filter_tokens(
        tokenize(string, keep_zwj=True), emoji_only=not non_emoji, join_emoji=join_emoji
    )


def demojize(
    string: str,
    delimiters: Tuple[str, str] = (_DEFAULT_DELIMITER, _DEFAULT_DELIMITER),
    language: str = 'en',
    version: Optional[float] = None,
    handle_version: Optional[Union[str, Callable[[str, Dict[str, str]], str]]] = None,
) -> str:
    """
    Replace Unicode emoji in a string with emoji shortcodes. Useful for storage.
        >>> import emoji
        >>> print(emoji.emojize("Python is fun :thumbs_up:"))
        Python is fun 👍
        >>> print(emoji.demojize("Python is fun 👍"))
        Python is fun :thumbs_up:
        >>> print(emoji.demojize("icode is tricky 😯", delimiters=("__", "__")))
        Unicode is tricky __hushed_face__

    :param string: String contains Unicode characters. MUST BE UNICODE.
    :param delimiters: (optional) User delimiters other than ``_DEFAULT_DELIMITER``
    :param language: Choose language of emoji name: language code 'es', 'de', etc. or 'alias'
        to use English aliases
    :param version: (optional) Max version. If set to an Emoji Version,
        all emoji above this version will be removed.
    :param handle_version: (optional) Replace the emoji above ``version``
        instead of removing it. handle_version can be either a string or a
        callable ``handle_version(emj: str, data: dict) -> str``; If it is
        a callable, it's passed the Unicode emoji and the data dict from
        :data:`EMOJI_DATA` and must return a replacement string  to be used.
        The passed data is in the form of::

            handle_version('\\U0001F6EB', {
                'en' : ':airplane_departure:',
                'status' : fully_qualified,
                'E' : 1,
                'alias' : [':flight_departure:'],
                'de': ':abflug:',
                'es': ':avión_despegando:',
                ...
            })

    """

    if language == 'alias':
        language = 'en'
        _use_aliases = True
    else:
        _use_aliases = False

    unicode_codes.load_from_json(language)

    def handle(emoji_match: EmojiMatch) -> str:
        assert emoji_match.data is not None
        if version is not None and emoji_match.data['E'] > version:
            if callable(handle_version):
                return handle_version(emoji_match.emoji, emoji_match.data_copy())
            elif handle_version is not None:
                return handle_version
            else:
                return ''
        elif language in emoji_match.data:
            if _use_aliases and 'alias' in emoji_match.data:
                return (
                    delimiters[0] + emoji_match.data['alias'][0][1:-1] + delimiters[1]
                )
            else:
                return delimiters[0] + emoji_match.data[language][1:-1] + delimiters[1]
        else:
            # The emoji exists, but it is not translated, so we keep the emoji
            return emoji_match.emoji

    matches = tokenize(string, keep_zwj=config.demojize_keep_zwj)
    return ''.join(
        str(handle(token.value)) if isinstance(token.value, EmojiMatch) else token.value
        for token in matches
    )


def replace_emoji(
    string: str,
    replace: Union[str, Callable[[str, Dict[str, str]], str]] = '',
    version: float = -1,
) -> str:
    """
    Replace Unicode emoji in a customizable string.

    :param string: String contains Unicode characters. MUST BE UNICODE.
    :param replace: (optional) replace can be either a string or a callable;
        If it is a callable, it's passed the Unicode emoji and the data dict from
        :data:`EMOJI_DATA` and must return a replacement string to be used.
        replace(str, dict) -> str
    :param version: (optional) Max version. If set to an Emoji Version,
        only emoji above this version will be replaced.
    """

    def handle(emoji_match: EmojiMatch) -> str:
        if version > -1:
            assert emoji_match.data is not None
            if emoji_match.data['E'] > version:
                if callable(replace):
                    return replace(emoji_match.emoji, emoji_match.data_copy())
                else:
                    return str(replace)
        elif callable(replace):
            return replace(emoji_match.emoji, emoji_match.data_copy())
        elif replace is not None:  # type: ignore
            return replace
        return emoji_match.emoji

    matches = tokenize(string, keep_zwj=config.replace_emoji_keep_zwj)
    if config.replace_emoji_keep_zwj:
        matches = filter_tokens(matches, emoji_only=False, join_emoji=True)
    return ''.join(
        str(handle(m.value)) if isinstance(m.value, EmojiMatch) else m.value
        for m in matches
    )


def emoji_list(string: str) -> List[_EmojiListReturn]:
    """
    Returns the location and emoji in list of dict format.
        >>> emoji.emoji_list("Hi, I am fine. 😁")
        [{'match_start': 15, 'match_end': 16, 'emoji': '😁'}]
    """

    return [
        {
            'match_start': m.value.start,
            'match_end': m.value.end,
            'emoji': m.value.emoji,
        }
        for m in tokenize(string, keep_zwj=False)
        if isinstance(m.value, EmojiMatch)
    ]


def distinct_emoji_list(string: str) -> List[str]:
    """Returns distinct list of emojis from the string."""
    distinct_list = list({e['emoji'] for e in emoji_list(string)})
    return distinct_list


def emoji_count(string: str, unique: bool = False) -> int:
    """
    Returns the count of emojis in a string.

    :param unique: (optional) True if count only unique emojis
    """
    if unique:
        return len(distinct_emoji_list(string))
    return len(emoji_list(string))


def is_emoji(string: str) -> bool:
    """
    Returns True if the string is a single emoji, and it is "recommended for
    general interchange" by Unicode.org.
    """
    return string in unicode_codes.EMOJI_DATA


def purely_emoji(string: str) -> bool:
    """
    Returns True if the string contains only emojis.
    This might not imply that `is_emoji` for all the characters, for example,
    if the string contains variation selectors.
    """
    return all(isinstance(m.value, EmojiMatch) for m in analyze(string, non_emoji=True))


def version(string: str) -> float:
    """
    Returns the Emoji Version of the emoji.

    See https://www.unicode.org/reports/tr51/#Versioning for more information.
        >>> emoji.version("😁")
        0.6
        >>> emoji.version(":butterfly:")
        3

    :param string: An emoji or a text containing an emoji
    :raises ValueError: if ``string`` does not contain an emoji
    """
    # Try dictionary lookup
    if string in unicode_codes.EMOJI_DATA:
        return unicode_codes.EMOJI_DATA[string]['E']

    # Try name lookup
    emj_code = unicode_codes.get_emoji_by_name(string, 'en')
    if emj_code and emj_code in unicode_codes.EMOJI_DATA:
        return unicode_codes.EMOJI_DATA[emj_code]['E']

    # Try to find first emoji in string
    version: List[float] = []

    def f(e: str, emoji_data: Dict[str, Any]) -> str:
        version.append(emoji_data['E'])
        return ''

    replace_emoji(string, replace=f, version=-1)
    if version:
        return version[0]
    emojize(string, language='alias', version=-1, handle_version=f)
    if version:
        return version[0]
    for lang_code in unicode_codes.LANGUAGES:
        emojize(string, language=lang_code, version=-1, handle_version=f)
        if version:
            return version[0]

    raise ValueError('No emoji found in string')

--- END OF emoji/core.py ---


--- START OF emoji/tokenizer.py ---
"""
emoji.tokenizer
~~~~~~~~~~~~~~~

Components for detecting and tokenizing emoji in strings.

"""

from typing import List, NamedTuple, Dict, Union, Iterator, Any
from emoji import unicode_codes


__all__ = [
    'EmojiMatch',
    'EmojiMatchZWJ',
    'EmojiMatchZWJNonRGI',
    'Token',
    'tokenize',
    'filter_tokens',
]

_ZWJ = '\u200d'
_SEARCH_TREE: Dict[str, Any] = {}


class EmojiMatch:
    """
    Represents a match of a "recommended for general interchange" (RGI)
    emoji in a string.
    """

    __slots__ = ('emoji', 'start', 'end', 'data')

    def __init__(
        self, emoji: str, start: int, end: int, data: Union[Dict[str, Any], None]
    ):
        self.emoji = emoji
        """The emoji substring"""

        self.start = start
        """The start index of the match in the string"""

        self.end = end
        """The end index of the match in the string"""

        self.data = data
        """The entry from :data:`EMOJI_DATA` for this emoji or ``None`` if the emoji is non-RGI"""

    def data_copy(self) -> Dict[str, Any]:
        """
        Returns a copy of the data from :data:`EMOJI_DATA` for this match
        with the additional keys ``match_start`` and ``match_end``.
        """
        if self.data:
            emj_data = self.data.copy()
            emj_data['match_start'] = self.start
            emj_data['match_end'] = self.end
            return emj_data
        else:
            return {'match_start': self.start, 'match_end': self.end}

    def is_zwj(self) -> bool:
        """
        Checks if this is a ZWJ-emoji.

        :returns: True if this is a ZWJ-emoji, False otherwise
        """

        return _ZWJ in self.emoji

    def split(self) -> Union['EmojiMatchZWJ', 'EmojiMatch']:
        """
        Splits a ZWJ-emoji into its constituents.

        :returns: An :class:`EmojiMatchZWJ` containing the "sub-emoji" if this is a ZWJ-emoji, otherwise self
        """

        if self.is_zwj():
            return EmojiMatchZWJ(self)
        else:
            return self

    def __repr__(self) -> str:
        return f'{self.__class__.__name__}({self.emoji}, {self.start}:{self.end})'


class EmojiMatchZWJ(EmojiMatch):
    """
    Represents a match of multiple emoji in a string that were joined by
    zero-width-joiners (ZWJ/``\\u200D``)."""

    __slots__ = ('emojis',)

    def __init__(self, match: EmojiMatch):
        super().__init__(match.emoji, match.start, match.end, match.data)

        self.emojis: List[EmojiMatch] = []
        """List of sub emoji as EmojiMatch objects"""

        i = match.start
        for e in match.emoji.split(_ZWJ):
            m = EmojiMatch(e, i, i + len(e), unicode_codes.EMOJI_DATA.get(e, None))
            self.emojis.append(m)
            i += len(e) + 1

    def join(self) -> str:
        """
        Joins a ZWJ-emoji into a string
        """

        return _ZWJ.join(e.emoji for e in self.emojis)

    def is_zwj(self) -> bool:
        return True

    def split(self) -> 'EmojiMatchZWJ':
        return self

    def __repr__(self) -> str:
        return f'{self.__class__.__name__}({self.join()}, {self.start}:{self.end})'


class EmojiMatchZWJNonRGI(EmojiMatchZWJ):
    """
    Represents a match of multiple emoji in a string that were joined by
    zero-width-joiners (ZWJ/``\\u200D``). This class is only used for emoji
    that are not "recommended for general interchange" (non-RGI) by Unicode.org.
    The data property of this class is always None.
    """

    def __init__(self, first_emoji_match: EmojiMatch, second_emoji_match: EmojiMatch):
        self.emojis = [first_emoji_match, second_emoji_match]
        """List of sub emoji as EmojiMatch objects"""

        self._update()

    def _update(self):
        self.emoji = _ZWJ.join(e.emoji for e in self.emojis)
        self.start = self.emojis[0].start
        self.end = self.emojis[-1].end
        self.data = None

    def _add(self, next_emoji_match: EmojiMatch):
        self.emojis.append(next_emoji_match)
        self._update()


class Token(NamedTuple):
    """
    A named tuple containing the matched string and its :class:`EmojiMatch` object if it is an emoji
    or a single character that is not a unicode emoji.
    """

    chars: str
    value: Union[str, EmojiMatch]


def tokenize(string: str, keep_zwj: bool) -> Iterator[Token]:
    """
    Finds unicode emoji in a string. Yields all normal characters as a named
    tuple :class:`Token` ``(char, char)`` and all emoji as :class:`Token` ``(chars, EmojiMatch)``.

    :param string: String contains unicode characters. MUST BE UNICODE.
    :param keep_zwj: Should ZWJ-characters (``\\u200D``) that join non-RGI emoji be
        skipped or should be yielded as normal characters
    :return: An iterable of tuples :class:`Token` ``(char, char)`` or :class:`Token` ``(chars, EmojiMatch)``
    """

    tree = get_search_tree()
    EMOJI_DATA = unicode_codes.EMOJI_DATA
    # result: [ Token(oldsubstring0, EmojiMatch), Token(char1, char1), ... ]
    result: List[Token] = []
    i = 0
    length = len(string)
    ignore: List[
        int
    ] = []  # index of chars in string that are skipped, i.e. the ZWJ-char in non-RGI-ZWJ-sequences
    while i < length:
        consumed = False
        char = string[i]
        if i in ignore:
            i += 1
            if char == _ZWJ and keep_zwj:
                result.append(Token(char, char))
            continue

        elif char in tree:
            j = i + 1
            sub_tree = tree[char]
            while j < length and string[j] in sub_tree:
                if j in ignore:
                    break
                sub_tree = sub_tree[string[j]]
                j += 1
            if 'data' in sub_tree:
                emj_data = sub_tree['data']
                code_points = string[i:j]

                # We cannot yield the result here, we need to defer
                # the call until we are sure that the emoji is finished
                # i.e. we're not inside an ongoing ZWJ-sequence
                match_obj = EmojiMatch(code_points, i, j, emj_data)

                i = j - 1
                consumed = True
                result.append(Token(code_points, match_obj))

        elif (
            char == _ZWJ
            and result
            and result[-1].chars in EMOJI_DATA
            and i > 0
            and string[i - 1] in tree
        ):
            # the current char is ZWJ and the last match was an emoji
            ignore.append(i)
            if (
                EMOJI_DATA[result[-1].chars]['status']
                == unicode_codes.STATUS['component']
            ):
                # last match was a component, it could be ZWJ+EMOJI+COMPONENT
                # or ZWJ+COMPONENT
                i = i - sum(len(t.chars) for t in result[-2:])
                if string[i] == _ZWJ:
                    # It's ZWJ+COMPONENT, move one back
                    i += 1
                    del result[-1]
                else:
                    # It's ZWJ+EMOJI+COMPONENT, move two back
                    del result[-2:]
            else:
                # last match result[-1] was a normal emoji, move cursor
                # before the emoji
                i = i - len(result[-1].chars)
                del result[-1]
            continue

        elif result:
            yield from result
            result = []

        if not consumed and char != '\ufe0e' and char != '\ufe0f':
            result.append(Token(char, char))
        i += 1

    yield from result


def filter_tokens(
    matches: Iterator[Token], emoji_only: bool, join_emoji: bool
) -> Iterator[Token]:
    """
    Filters the output of `tokenize()`

    :param matches: An iterable of tuples of the form ``(match_str, result)``
        where ``result`` is either an EmojiMatch or a string.
    :param emoji_only: If True, only EmojiMatch are returned in the output.
        If False all characters are returned
    :param join_emoji: If True, multiple EmojiMatch are merged into
        a single :class:`EmojiMatchZWJNonRGI` if they are separated only by a ZWJ.

    :return: An iterable of tuples :class:`Token` ``(char, char)``,
        :class:`Token` ``(chars, EmojiMatch)`` or :class:`Token` ``(chars, EmojiMatchZWJNonRGI)``
    """

    if not join_emoji and not emoji_only:
        yield from matches
        return

    if not join_emoji:
        for token in matches:
            if token.chars != _ZWJ:
                yield token
        return

    # Combine multiple EmojiMatch that are separated by ZWJs into
    # a single EmojiMatchZWJNonRGI
    previous_is_emoji = False
    previous_is_zwj = False
    pre_previous_is_emoji = False
    accumulator: List[Token] = []
    for token in matches:
        pre_previous_is_emoji = previous_is_emoji
        if previous_is_emoji and token.value == _ZWJ:
            previous_is_zwj = True
        elif isinstance(token.value, EmojiMatch):
            if pre_previous_is_emoji and previous_is_zwj:
                if isinstance(accumulator[-1].value, EmojiMatchZWJNonRGI):
                    accumulator[-1].value._add(token.value)  # pyright: ignore [reportPrivateUsage]
                    accumulator[-1] = Token(
                        accumulator[-1].chars + _ZWJ + token.chars,
                        accumulator[-1].value,
                    )
                else:
                    prev = accumulator.pop()
                    assert isinstance(prev.value, EmojiMatch)
                    accumulator.append(
                        Token(
                            prev.chars + _ZWJ + token.chars,
                            EmojiMatchZWJNonRGI(prev.value, token.value),
                        )
                    )
            else:
                accumulator.append(token)
            previous_is_emoji = True
            previous_is_zwj = False
        else:
            # Other character, not an emoji
            previous_is_emoji = False
            previous_is_zwj = False
            yield from accumulator
            if not emoji_only:
                yield token
            accumulator = []
    yield from accumulator


def get_search_tree() -> Dict[str, Any]:
    """
    Generate a search tree for demojize().
    Example of a search tree::

        EMOJI_DATA =
        {'a': {'en': ':Apple:'},
        'b': {'en': ':Bus:'},
        'ba': {'en': ':Bat:'},
        'band': {'en': ':Beatles:'},
        'bandit': {'en': ':Outlaw:'},
        'bank': {'en': ':BankOfEngland:'},
        'bb': {'en': ':BB-gun:'},
        'c': {'en': ':Car:'}}

        _SEARCH_TREE =
        {'a': {'data': {'en': ':Apple:'}},
        'b': {'a': {'data': {'en': ':Bat:'},
                    'n': {'d': {'data': {'en': ':Beatles:'},
                                'i': {'t': {'data': {'en': ':Outlaw:'}}}},
                        'k': {'data': {'en': ':BankOfEngland:'}}}},
            'b': {'data': {'en': ':BB-gun:'}},
            'data': {'en': ':Bus:'}},
        'c': {'data': {'en': ':Car:'}}}

                   _SEARCH_TREE
                 /     |        ⧵
               /       |          ⧵
            a          b             c
            |        / |  ⧵          |
            |       /  |    ⧵        |
        :Apple:   ba  :Bus:  bb     :Car:
                 /  ⧵         |
                /    ⧵        |
              :Bat:    ban     :BB-gun:
                     /     ⧵
                    /       ⧵
                 band       bank
                /   ⧵         |
               /     ⧵        |
            bandi :Beatles:  :BankOfEngland:
               |
            bandit
               |
           :Outlaw:


    """
    if not _SEARCH_TREE:
        for emj in unicode_codes.EMOJI_DATA:
            sub_tree = _SEARCH_TREE
            lastidx = len(emj) - 1
            for i, char in enumerate(emj):
                if char not in sub_tree:
                    sub_tree[char] = {}
                sub_tree = sub_tree[char]
                if i == lastidx:
                    sub_tree['data'] = unicode_codes.EMOJI_DATA[emj]
    return _SEARCH_TREE

--- END OF emoji/tokenizer.py ---


--- START OF emoji/py.typed ---

--- END OF emoji/py.typed ---


--- START OF emoji/unicode_codes/__init__.py ---
import sys
import importlib.resources
import json
from functools import lru_cache
from warnings import warn

from typing import Any, BinaryIO, Dict, List, Optional

from emoji.unicode_codes.data_dict import STATUS, LANGUAGES

__all__ = [
    'get_emoji_by_name',
    'load_from_json',
    'EMOJI_DATA',
    'STATUS',
    'LANGUAGES',
]

_DEFAULT_KEYS = ('en', 'alias', 'E', 'status')  # The keys in emoji.json

_loaded_keys: List[str] = list(
    _DEFAULT_KEYS
)  # Keep track of keys already loaded from json files to avoid loading them twice


@lru_cache(maxsize=4000)
def get_emoji_by_name(name: str, language: str) -> Optional[str]:
    """
    Find emoji by short-name in a specific language.
    Returns None if not found

    :param name: emoji short code e.g. ":banana:"
    :param language: language-code e.g. 'es', 'de', etc. or 'alias'
    """

    fully_qualified = STATUS['fully_qualified']

    if language == 'alias':
        for emj, data in EMOJI_DATA.items():
            if name in data.get('alias', []) and data['status'] <= fully_qualified:
                return emj
        language = 'en'

    for emj, data in EMOJI_DATA.items():
        if data.get(language) == name and data['status'] <= fully_qualified:
            return emj

    return None


class EmojiDataDict(Dict[str, Any]):
    """Replaces built-in-dict in the values of the EMOJI_DATA dict.
    Auto loads language data when accessing language data via
    key-access without prior loading of the language:
    e.g. EMOJI_DATA['👌']['fr'] will auto load French language and not throw
    a KeyError.
    Shows a deprecation warning explainging that `emoji.config.load_language()`
    should be used."""

    def __missing__(self, key: str) -> str:
        """Auto load language `key`, raises KeyError if language is no supported."""
        if key in LANGUAGES and key not in _loaded_keys:
            load_from_json(key)
            if key in self:
                warn(
                    f"""Use emoji.config.load_language('{key}') before accesing EMOJI_DATA[emj]['{key}'].
Accessing EMOJI_DATA[emj]['{key}'] without loading the language is deprecated.""",
                    DeprecationWarning,
                    stacklevel=3,
                )
                return self[key]  # type: ignore

        raise KeyError(key)


EMOJI_DATA: Dict[str, Dict[str, Any]]


def _open_file(name: str) -> BinaryIO:
    if sys.version_info >= (3, 9):
        return importlib.resources.files('emoji.unicode_codes').joinpath(name).open('rb')
    else:
        return importlib.resources.open_binary('emoji.unicode_codes', name)


def _load_default_from_json():
    global EMOJI_DATA
    global _loaded_keys

    with _open_file('emoji.json') as f:
        EMOJI_DATA = dict(json.load(f, object_pairs_hook=EmojiDataDict))  # type: ignore
    _loaded_keys = list(_DEFAULT_KEYS)


def load_from_json(key: str):
    """Load values from the file 'emoji_{key}.json' into EMOJI_DATA"""

    if key in _loaded_keys:
        return

    if key not in LANGUAGES:
        raise NotImplementedError('Language not supported', key)

    with _open_file(f'emoji_{key}.json') as f:
        for emj, value in json.load(f).items():
            EMOJI_DATA[emj][key] = value  # type: ignore

    _loaded_keys.append(key)


_load_default_from_json()

--- END OF emoji/unicode_codes/__init__.py ---


--- START OF emoji/unicode_codes/data_dict.py ---
"""Data containing all current emoji
Extracted from https://unicode.org/Public/emoji/latest/emoji-test.txt
and https://www.unicode.org/Public/UCD/latest/ucd/emoji/emoji-variation-sequences.txt
See utils/generate_emoji.py

+----------------+-------------+------------------+-------------------+
| Emoji Version  |    Date     | Unicode Version  | Data File Comment |
+----------------+-------------+------------------+-------------------+
| N/A            | 2010-10-11  | Unicode 6.0      | E0.6              |
| N/A            | 2014-06-16  | Unicode 7.0      | E0.7              |
| Emoji 1.0      | 2015-06-09  | Unicode 8.0      | E1.0              |
| Emoji 2.0      | 2015-11-12  | Unicode 8.0      | E2.0              |
| Emoji 3.0      | 2016-06-03  | Unicode 9.0      | E3.0              |
| Emoji 4.0      | 2016-11-22  | Unicode 9.0      | E4.0              |
| Emoji 5.0      | 2017-06-20  | Unicode 10.0     | E5.0              |
| Emoji 11.0     | 2018-05-21  | Unicode 11.0     | E11.0             |
| Emoji 12.0     | 2019-03-05  | Unicode 12.0     | E12.0             |
| Emoji 12.1     | 2019-10-21  | Unicode 12.1     | E12.1             |
| Emoji 13.0     | 2020-03-10  | Unicode 13.0     | E13.0             |
| Emoji 13.1     | 2020-09-15  | Unicode 13.0     | E13.1             |
| Emoji 14.0     | 2021-09-14  | Unicode 14.0     | E14.0             |
| Emoji 15.0     | 2022-09-13  | Unicode 15.0     | E15.0             |
| Emoji 15.1     | 2023-09-12  | Unicode 15.1     | E15.1             |
| Emoji 16.0     | 2024-09-10  | Unicode 16.0     | E16.0             |

               http://www.unicode.org/reports/tr51/#Versioning

"""

__all__ = ['STATUS', 'LANGUAGES']

from typing import Any, Dict, List


component = 1
fully_qualified = 2
minimally_qualified = 3
unqualified = 4

STATUS: Dict[str, int] = {
    'component': component,
    'fully_qualified': fully_qualified,
    'minimally_qualified': minimally_qualified,
    'unqualified': unqualified,
}

LANGUAGES: List[str] = [
    'en',
    'es',
    'ja',
    'ko',
    'pt',
    'it',
    'fr',
    'de',
    'fa',
    'id',
    'zh',
    'ru',
    'tr',
    'ar',
]


# The following is only an example of how the EMOJI_DATA dict is structured.
# The real data is loaded from the json files at runtime, see unicode_codes/__init__.py
EMOJI_DATA: Dict[str, Dict[str, Any]] = {
    '\U0001f947': {  # 🥇
        'en': ':1st_place_medal:',
        'status': fully_qualified,
        'E': 3,
        'de': ':goldmedaille:',
        'es': ':medalla_de_oro:',
        'fr': ':médaille_d’or:',
        'ja': ':金メダル:',
        'ko': ':금메달:',
        'pt': ':medalha_de_ouro:',
        'it': ':medaglia_d’oro:',
        'fa': ':مدال_طلا:',
        'id': ':medali_emas:',
        'zh': ':金牌:',
        'ru': ':золотая_медаль:',
        'tr': ':birincilik_madalyası:',
        'ar': ':ميدالية_مركز_أول:',
    },
    '\U0001f948': {  # 🥈
        'en': ':2nd_place_medal:',
        'status': fully_qualified,
        'E': 3,
        'de': ':silbermedaille:',
        'es': ':medalla_de_plata:',
        'fr': ':médaille_d’argent:',
        'ja': ':銀メダル:',
        'ko': ':은메달:',
        'pt': ':medalha_de_prata:',
        'it': ':medaglia_d’argento:',
        'fa': ':مدال_نقره:',
        'id': ':medali_perak:',
        'zh': ':银牌:',
        'ru': ':серебряная_медаль:',
        'tr': ':ikincilik_madalyası:',
        'ar': ':ميدالية_مركز_ثان:',
    },
    '\U0001f949': {  # 🥉
        'en': ':3rd_place_medal:',
        'status': fully_qualified,
        'E': 3,
        'de': ':bronzemedaille:',
        'es': ':medalla_de_bronce:',
        'fr': ':médaille_de_bronze:',
        'ja': ':銅メダル:',
        'ko': ':동메달:',
        'pt': ':medalha_de_bronze:',
        'it': ':medaglia_di_bronzo:',
        'fa': ':مدال_برنز:',
        'id': ':medali_perunggu:',
        'zh': ':铜牌:',
        'ru': ':бронзовая_медаль:',
        'tr': ':üçüncülük_madalyası:',
        'ar': ':ميدالية_مركز_ثالث:',
    },
    '\U0001f18e': {  # 🆎
        'en': ':AB_button_(blood_type):',
        'status': fully_qualified,
        'E': 0.6,
        'alias': [':ab:', ':ab_button_blood_type:'],
        'de': ':großbuchstaben_ab_in_rotem_quadrat:',
        'es': ':grupo_sanguíneo_ab:',
        'fr': ':groupe_sanguin_ab:',
        'ja': ':血液型ab型:',
        'ko': ':에이비형:',
        'pt': ':botão_ab_(tipo_sanguíneo):',
        'it': ':gruppo_sanguigno_ab:',
        'fa': ':دکمه_آ_ب_(گروه_خونی):',
        'id': ':tombol_ab_(golongan_darah):',
        'zh': ':AB型血:',
        'ru': ':IV_группа_крови:',
        'tr': ':ab_düğmesi_(kan_grubu):',
        'ar': ':زر_ab_(فئة_الدم):',
    },
    '\U0001f3e7': {  # 🏧
        'en': ':ATM_sign:',
        'status': fully_qualified,
        'E': 0.6,
        'alias': [':atm:', ':atm_sign:'],
        'de': ':symbol_geldautomat:',
        'es': ':señal_de_cajero_automático:',
        'fr': ':distributeur_de_billets:',
        'ja': ':atm:',
        'ko': ':에이티엠:',
        'pt': ':símbolo_de_caixa_automático:',
        'it': ':simbolo_dello_sportello_bancomat:',
        'fa': ':نشان_عابربانک:',
        'id': ':tanda_atm:',
        'zh': ':取款机:',
        'ru': ':значок_банкомата:',
        'tr': ':atm_işareti:',
        'ar': ':علامة_ماكينة_صرف_آلي:',
    },
    '\U0001f170\U0000fe0f': {  # 🅰️
        'en': ':A_button_(blood_type):',
        'status': fully_qualified,
        'E': 0.6,
        'alias': [':a:', ':a_button_blood_type:'],
        'variant': True,
        'de': ':großbuchstabe_a_in_rotem_quadrat:',
        'es': ':grupo_sanguíneo_a:',
        'fr': ':groupe_sanguin_a:',
        'ja': ':血液型a型:',
        'ko': ':에이형:',
        'pt': ':botão_a_(tipo_sanguíneo):',
        'it': ':gruppo_sanguigno_a:',
        'fa': ':دکمه_آ_(گروه_خونی):',
        'id': ':tombol_a_(golongan_darah):',
        'zh': ':A型血:',
        'ru': ':ii_группа_крови:',
        'tr': ':a_düğmesi_(kan_grubu):',
        'ar': ':زر_a:',
    },
    '\U0001f170': {  # 🅰
        'en': ':A_button_(blood_type):',
        'status': unqualified,
        'E': 0.6,
        'alias': [':a:', ':a_button_blood_type:'],
        'variant': True,
        'de': ':großbuchstabe_a_in_rotem_quadrat:',
        'es': ':grupo_sanguíneo_a:',
        'fr': ':groupe_sanguin_a:',
        'ja': ':血液型a型:',
        'ko': ':에이형:',
        'pt': ':botão_a_(tipo_sanguíneo):',
        'it': ':gruppo_sanguigno_a:',
        'fa': ':دکمه_آ_(گروه_خونی):',
        'id': ':tombol_a_(golongan_darah):',
        'zh': ':A型血:',
        'ru': ':II_группа_крови:',
        'tr': ':a_düğmesi_(kan_grubu):',
        'ar': ':زر_a:',
    },
    '\U0001f1e6\U0001f1eb': {  # 🇦🇫
        'en': ':Afghanistan:',
        'status': fully_qualified,
        'E': 2,
        'alias': [':flag_for_Afghanistan:', ':afghanistan:'],
        'de': ':flagge_afghanistan:',
        'es': ':bandera_afganistán:',
        'fr': ':drapeau_afghanistan:',
        'ja': ':旗_アフガニスタン:',
        'ko': ':깃발_아프가니스탄:',
        'pt': ':bandeira_afeganistão:',
        'it': ':bandiera_afghanistan:',
        'fa': ':پرچم_افغانستان:',
        'id': ':bendera_afganistan:',
        'zh': ':阿富汗:',
        'ru': ':флаг_Афганистан:',
        'tr': ':bayrak_afganistan:',
        'ar': ':علم_أفغانستان:',
    },
    '\U0001f1e6\U0001f1f1': {  # 🇦🇱
        'en': ':Albania:',
        'status': fully_qualified,
        'E': 2,
        'alias': [':flag_for_Albania:', ':albania:'],
        'de': ':flagge_albanien:',
        'es': ':bandera_albania:',
        'fr': ':drapeau_albanie:',
        'ja': ':旗_アルバニア:',
        'ko': ':깃발_알바니아:',
        'pt': ':bandeira_albânia:',
        'it': ':bandiera_albania:',
        'fa': ':پرچم_آلبانی:',
        'id': ':bendera_albania:',
        'zh': ':阿尔巴尼亚:',
        'ru': ':флаг_Албания:',
        'tr': ':bayrak_arnavutluk:',
        'ar': ':علم_ألبانيا:',
    },
    '\U0001f1e9\U0001f1ff': {  # 🇩🇿
        'en': ':Algeria:',
        'status': fully_qualified,
        'E': 2,
        'alias': [':flag_for_Algeria:', ':algeria:'],
        'de': ':flagge_algerien:',
        'es': ':bandera_argelia:',
        'fr': ':drapeau_algérie:',
        'ja': ':旗_アルジェリア:',
        'ko': ':깃발_알제리:',
        'pt': ':bandeira_argélia:',
        'it': ':bandiera_algeria:',
        'fa': ':پرچم_الجزایر:',
        'id': ':bendera_aljazair:',
        'zh': ':阿尔及利亚:',
        'ru': ':флаг_Алжир:',
        'tr': ':bayrak_cezayir:',
        'ar': ':علم_الجزائر:',
    },
    '\U0001f1e6\U0001f1f8': {  # 🇦🇸
        'en': ':American_Samoa:',
        'status': fully_qualified,
        'E': 2,
        'alias': [':flag_for_American_Samoa:', ':american_samoa:'],
        'de': ':flagge_amerikanisch-samoa:',
        'es': ':bandera_samoa_americana:',
        'fr': ':drapeau_samoa_américaines:',
        'ja': ':旗_米領サモア:',
        'ko': ':깃발_아메리칸_사모아:',
        'pt': ':bandeira_samoa_americana:',
        'it': ':bandiera_samoa_americane:',
        'fa': ':پرچم_ساموآی_امریکا:',
        'id': ':bendera_samoa_amerika:',
        'zh': ':美属萨摩亚:',
        'ru': ':флаг_Американское_Самоа:',
        'tr': ':bayrak_amerikan_samoası:',
        'ar': ':علم_ساموا_الأمريكية:',
    },
}

--- END OF emoji/unicode_codes/data_dict.py ---


--- START OF utils/generateutils.py ---
import re
from typing import Optional
import unicodedata

import requests


__scraper: Optional[requests.Session] = None


def to_ascii(s: str) -> str:
    """return escaped Code points \U000ab123"""
    return s.encode('unicode-escape').decode()


def get_text_from_url(url: str) -> str:
    """Get text from url"""

    html = ''
    if __scraper is None:
        html = requests.get(url).text
    if __scraper is not None or 'you have been blocked' in html.lower():
        html = get_text_from_cloudflare_url(url)

    return html


def get_text_from_cloudflare_url(url: str) -> str:
    """Get text from url that is protected by cloudflare"""
    global __scraper
    if __scraper is None:
        import cloudscraper  # type: ignore

        __scraper = cloudscraper.create_scraper()  # type: ignore
    return __scraper.get(url).text


def adapt_emoji_name(text: str, lang: str, emj: str) -> str:
    # Use NFKC-form (single character instead of character + diacritic)
    # Unicode.org files should be formatted like this anyway, but emojiterra is not consistent
    text = unicodedata.normalize('NFKC', text)

    # Fix German clock times "12:30 Uhr" -> "12.30 Uhr"
    text = re.sub(r'(\d+):(\d+)', r'\1.\2', text)
    text = text.replace('Ziffernblatt ', '')

    # Remove white space
    text = '_'.join(text.split(' '))

    emoji_name = (
        ':'
        + (
            text.lower()
            .removeprefix('flag:_')
            .replace(':', '')
            .replace(',', '')
            .replace('"', '')
            .replace('\u201e', '')
            .replace('\u201f', '')
            .replace('\u202f', '')
            .replace('\u229b', '')
            .replace('\u2013', '-')
            .replace(',_', ',')
            .strip()
            .replace(' ', '_')
            .replace('_-_', '-')
        )
        + ':'
    )

    if lang == 'de':
        emoji_name = emoji_name.replace('\u201c', '').replace('\u201d', '')
        emoji_name = re.sub(r'(hautfarbe)_und_([a-z]+_hautfarbe)', r'\1,\2', emoji_name)

    if lang == 'fa':
        emoji_name = emoji_name.replace('\u200c', '_')
        emoji_name = emoji_name.replace('\u200f', '_')
        emoji_name = emoji_name.replace('\u060c', '_')
        emoji_name = re.sub('_+', '_', emoji_name)

    if lang == 'tr':
        emoji_name = emoji_name.replace('\u0307', '')

    if lang == 'ar':
        # Removal of Arabic comma
        emoji_name = emoji_name.replace('\u060c', '')
        # Removal of supplementary Arabic diacritics "tashkīl"
        diacritics = '[\u0651\u0652\u064c\u064b\u064d\u0640\ufc62]'
        emoji_name = re.sub(diacritics, '', emoji_name)
        # Renaming duplicates
        duplicates = {
            '\U0001f9db\U0001f3ff': ':مصاص_دماء_رجل_بشرة_بلون_غامق:',  # 🧛🏿‍♂️
            '\U0001f9db\U0001f3fb': ':مصاص_دماء_رجل_بشرة_بلون_فاتح:',  # 🧛🏻
            '\U0001f9db\U0001f3fe': ':مصاص_دماء_رجل_بشرة_بلون_معتدل_مائل_للغامق:',  # 🧛🏾
            '\U0001f9db\U0001f3fc': ':مصاص_دماء_رجل_بشرة_بلون_فاتح_ومعتدل:',  # 🧛🏼
            '\U0001f9db\U0001f3fd': ':مصاص_دماء_رجل_بشرة_بلون_معتدل:',  # 🧛🏽
            '\U0001f9db\U0000200d\U00002642\U0000fe0f': ':مصاص_دماء_رجل:',  # 🧛‍♂️
            '\U0001f9a2': ':إوَزة:',  # 🦢
        }

        for e in duplicates:
            if e == emj:
                emoji_name = duplicates[emj]

    if lang == 'zh':
        emoji_name = (
            ':'
            + (
                text.replace(':', '')
                .replace(',', '')
                .replace('-', '')
                .replace('\u201e', '')
                .replace('\u201f', '')
                .replace('\u202f', '')
                .replace('\u229b', '')
                .replace(',_', ',')
                .strip()
                .replace(' ', '_')
            )
            + ':'
        )

        if '日文' in emoji_name:
            # Japanese buttons
            emoji_name = (
                emoji_name.replace('日文的', '')
                .replace('按钮', '')
                .replace('“', '')
                .replace('”', '')
            )

        if '箭头' in emoji_name:
            # Arrows
            emoji_name = emoji_name.replace('_', '').replace('!', '')

        if '按钮' in emoji_name:
            # English buttons
            emoji_name = emoji_name.replace('_', '')

        if '型血' in emoji_name:
            emoji_name = emoji_name.replace('_', '')

        if '中等-' in emoji_name:
            emoji_name = emoji_name.replace('中等-', '中等')

        if emoji_name.startswith(':旗_'):
            # Countries
            emoji_name = emoji_name.replace(':旗_', ':')

        hardcoded = {
            '\U0001f1ed\U0001f1f0': ':香港:',  # 🇭🇰
            '\U0001f1ee\U0001f1e9': ':印度尼西亞:',  # 🇮🇩
            '\U0001f1f0\U0001f1ff': ':哈薩克:',  # 🇰🇿
            '\U0001f1f2\U0001f1f4': ':澳門:',  # 🇲🇴
            '\U0001f1e8\U0001f1ec': ':刚果_布:',  # 🇨🇬
            '\U0001f1e8\U0001f1e9': ':刚果_金:',  # 🇨🇩
            '\U0001f193': ':FREE按钮:',  # 🆓
            '\U0001f238': ':申:',  # 🈸
            '\U0001f250': ':得:',  # 🉐
            '\U0001f22f': ':指:',  # 🈯
            '\U0001f232': ':禁:',  # 🈲
            '\u3297\ufe0f': ':祝:',  # ㊗️
            '\u3297': ':祝:',  # ㊗
            '\U0001f239': ':割:',  # 🈹
            '\U0001f21a': ':无:',  # 🈚
            '\U0001f237\ufe0f': ':月:',  # 🈷️
            '\U0001f237': ':月:',  # 🈷
            '\U0001f235': ':满:',  # 🈵
            '\U0001f236': ':有:',  # 🈶
            '\U0001f234': ':合:',  # 🈴
            '\u3299\ufe0f': ':秘:',  # ㊙️
            '\u3299': ':秘:',  # ㊙
            '\U0001f233': ':空:',  # 🈳
            '\U0001f251': ':可:',  # 🉑
            '\U0001f23a': ':营:',  # 🈺
            '\U0001f202\ufe0f': ':服务:',  # 🈂️
            '\U0001f202': ':服务:',  # 🈂
        }

        if emj in hardcoded:
            emoji_name = hardcoded[emj]

    if lang == 'ru':
        emoji_name = (
            ':'
            + (
                text.replace(':', '')
                .replace(',', '')
                .replace('-', ' ')
                .replace('—', '')
                .replace(',_', ',')
                .strip()
                .replace(' ', '_')
            )
            + ':'
        )

    emoji_name = (
        emoji_name.replace('____', '_')
        .replace('___', '_')
        .replace('__', '_')
        .replace('--', '-')
    )

    return emoji_name

--- END OF utils/generateutils.py ---


--- START OF utils/generate_emoji.py ---
"""
Extract the full list of emoji and names from the Unicode emoji data files
https://unicode.org/Public/emoji/{v}/emoji-test.txt and
https://www.unicode.org/Public/{v}/ucd/emoji/emoji-variation-sequences.txt
and the aliases from various sources.
and combine it with the existing emoji data from the emoji package.
"""

import sys
import os
from pathlib import Path
from typing import Any, Dict, List, Optional, Set
import re
import logging
import json

import requests
import bs4

from generateutils import get_text_from_url, to_ascii

logging.basicConfig(stream=sys.stderr, level=logging.DEBUG)

include = os.path.relpath(os.path.join(os.path.dirname(__file__), '..'))
sys.path.insert(0, include)
import emoji as emoji_pkg  # noqa: E402


def get_emoji_from_url(version: float) -> List[str]:
    """Get splitlines of emojis list from unicode.org"""

    url = f'https://unicode.org/Public/emoji/{version}/emoji-test.txt'
    return get_text_from_url(url).splitlines()


def get_emoji_variation_sequence_from_url(version: str) -> List[str]:
    """Get splitlines of emoji variation sequences from unicode.org"""

    url = f'https://www.unicode.org/Public/{version}/ucd/emoji/emoji-variation-sequences.txt'
    return get_text_from_url(url).splitlines()


def get_cheat_sheet(url: str) -> Dict[str, str]:
    """
    Returns a dict of emoji to short-names:
    E.g. {'👴': ':old_man:', '👵': ':old_woman:', ... }
    """

    html = get_text_from_url(url)

    soup = bs4.BeautifulSoup(html, 'html.parser')
    emojis: Dict[str, str] = {}

    ecs_list = soup.find(class_='ecs-list')
    assert isinstance(ecs_list, bs4.element.Tag), "Couldn't find the ecs-list class in the cheat-sheet"
    items = ecs_list.find_all(class_='_item')
    assert items, "Couldn't find any items in the cheat-sheet"

    pattern = re.compile(r'U\+([0-9A-F]+)')

    for i in items:
        unicode_text = i.find(class_='unicode').text

        code_points = pattern.findall(unicode_text)
        code = ''.join(chr(int(x, 16)) for x in code_points)

        emojis[code] = i.find(class_='shortcode').text

    # Remove some unwanted and some weird entries from the cheat sheet
    filtered: Dict[str, str] = {}
    for emj, short_code in emojis.items():
        if short_code.startswith(':flag_'):
            # Skip flags from cheat-sheet, because we already have very similar aliases for the flags
            continue

        if '⊛' in short_code:
            # Strange emoji with ⊛ in the short-code
            continue

        if emj == '\U0001f93e\U0000200d\U00002640\U0000fe0f':
            # The short-code for this emoji is wrong
            continue

        if emj == '\U0001f468\U0000200d\U0001f468\U0000200d\U0001f467':
            # The short-code for this emoji is wrong
            continue

        if short_code.startswith('::'):
            # Do not allow short-codes to have double :: at the start
            short_code = short_code[1:]

        if short_code.endswith('::'):
            # Do not allow short-codes to have double :: at the end
            short_code = short_code[:-1]

        filtered[emj] = short_code

    assert (
        len(filtered) > 100
    ), f'emoji-cheat-sheet data from {url} has only {len(filtered)} entries'

    return filtered


def get_emoji_from_youtube(url: str) -> Dict[str, List[str]]:
    """Get emoji alias from Youtube
    Returns a dict of emoji to list of short-names:
    E.g. {'💁': [':person_tipping_hand:', ':information_desk_person:'], '😉': [':winking_face:', ':wink:']}
    """

    data = requests.get(url).json()

    output: Dict[str, List[str]] = {}
    for obj in data:
        if 'shortcuts' not in obj or 'emojiId' not in obj:
            continue

        shortcuts = [
            x for x in obj['shortcuts'] if x.startswith(':') and x.endswith(':')
        ]

        if shortcuts:
            output[obj['emojiId']] = shortcuts

    assert len(output) > 100, f'youtube data from {url} has only {len(output)} entries'

    return output


def extract_emojis(
    emojis_lines: List[str], sequences_lines: List[str]
) -> Dict[str, Dict[str, Any]]:
    """Extract emojis line by line to dict"""

    output: Dict[str, Dict[str, Any]] = {}
    for line in emojis_lines:
        if not line == '' and not line.startswith('#'):
            emoji_status = line.split(';')[1].strip().split(' ')[0]

            codes = line.split(';')[0].strip().split(' ')
            separated_line = line.split(' # ')[-1].strip().split(' ')
            separated_name = separated_line[2:]
            version_str = separated_line[1]

            emoji_name: str = (
                '_'.join(separated_name)
                .removeprefix('flag:_')
                .replace(':', '')
                .replace(',', '')
                .replace('\u201c', '')
                .replace('\u201d', '')
                .replace('\u229b', '')
                .strip()
                .replace(' ', '_')
                .replace('_-_', '-')
            )

            assert isinstance(
                emoji_name, str
            ), f'emoji_name is not a string: {emoji_name}'

            emoji_code = ''.join(
                [
                    '\\U0000' + code if len(code) == 4 else '\\U000' + code
                    for code in codes
                ]
            )

            version = float(version_str.replace('E', '').strip())

            if emoji_code in output:
                raise Exception(f'Duplicate emoji: {emoji_name} {emoji_code}')

            output[emoji_code] = {
                'en': emoji_name,
                'status': emoji_status.replace('-', '_'),
                'version': version,
            }

    # Walk through the emoji-variation-sequences.txt
    for line in sequences_lines:
        if not line == '' and not line.startswith('#'):
            # No variant
            normal_codes = line.split(';')[0].strip().split(' ')
            normal_code = ''.join(
                [
                    '\\U0000' + code if len(code) == 4 else '\\U000' + code
                    for code in normal_codes
                ]
            )
            if normal_code in output:
                output[normal_code]['variant'] = True

            # Text variant U+FE0E
            text_codes = (
                re.sub(r'\s*FE0E\s*$', '', line.split(';')[0]).strip().split(' ')
            )
            text_code = ''.join(
                [
                    '\\U0000' + code if len(code) == 4 else '\\U000' + code
                    for code in text_codes
                ]
            )
            if text_code in output:
                output[text_code]['variant'] = True

            # Emoji variant U+FE0F
            emoji_codes = (
                re.sub(r'\s*FE0F\s*$', '', line.split(';')[0]).strip().split(' ')
            )
            emoji_code = ''.join(
                [
                    '\\U0000' + code if len(code) == 4 else '\\U000' + code
                    for code in emoji_codes
                ]
            )
            if emoji_code in output:
                output[emoji_code]['variant'] = True

    return output




def get_emoji_from_github_api(url: str) -> Dict[str, str]:
    """Get emoji alias from GitHub API"""

    data = requests.get(url).json()
    pattern = re.compile(r'unicode/([0-9a-fA-F-]+)\.[a-z]+')

    output: Dict[str, str] = {}
    for name, img in data.items():
        m = pattern.search(img)
        if m:
            emj = ''.join(chr(int(h, 16)) for h in m.group(1).split('-'))
            output[name] = emj
        else:
            pass  # Special GitHub emoji that is not part of Unicode

    assert len(output) > 100, f'data from github API has only {len(output)} entries'

    return output


GITHUB_REMOVED_CHARS = re.compile('\u200d|\ufe0f|\ufe0e', re.IGNORECASE)


def find_github_aliases(
    emj: str,
    github_dict: Dict[str, str],
    v: Dict[str, Any],
    emj_no_variant: Optional[str] = None,
) -> Set[str]:
    aliases: Set[str] = set()

    # Strip ZWJ \u200D, text_type \uFE0E and emoji_type \uFE0F
    # because the GitHub API does not include these
    emj_clean = GITHUB_REMOVED_CHARS.sub('', emj)

    for gh_alias in github_dict:
        if emj == github_dict[gh_alias]:
            aliases.add(gh_alias)
        elif 'variant' in v and emj_no_variant == github_dict[gh_alias]:
            aliases.add(gh_alias)
        elif emj_clean == github_dict[gh_alias]:
            aliases.add(gh_alias)

    return aliases



if __name__ == '__main__':
    out_file = (
        Path(emoji_pkg.__file__).parent.joinpath('unicode_codes/emoji.json').resolve()
    )
    logging.info(f'  Outfile: {out_file}')

    logging.info('  Downloading...\n')

    # Find the latest version at https://www.unicode.org/reports/tr51/#emoji_data
    emoji_source = get_emoji_from_url(16.0)
    emoji_sequences_source = get_emoji_variation_sequence_from_url('16.0.0')
    emojis = extract_emojis(emoji_source, emoji_sequences_source)

    github_alias_dict = get_emoji_from_github_api('https://api.github.com/emojis')
    cheat_sheet_dict = get_cheat_sheet('https://www.webfx.com/tools/emoji-cheat-sheet/')
    youtube_dict = get_emoji_from_youtube(
        'https://www.gstatic.com/youtube/img/emojis/emojis-png-7.json'
    )

    logging.info('  Combining...\n')

    used_github_aliases: Set[str] = set()

    escapedToUnicodeMap = {
        escaped: escaped.encode().decode('unicode-escape') for escaped in emojis
    }  # maps: "\\U0001F4A4" to "\U0001F4A4"

    all_existing_aliases_and_en = set(
        item
        for emj_data in emoji_pkg.EMOJI_DATA.values()
        for item in emj_data.get('alias', [])
    )
    all_existing_aliases_and_en.update(
        emj_data['en'] for emj_data in emoji_pkg.EMOJI_DATA.values()
    )

    f = 0
    c = 0
    new_aliases: List[str] = []
    logging.info(f'  Writing to {out_file}...\n')
    fp = open(out_file, mode='wt', encoding='utf-8', newline='\n')
    fp.write('{\n')
    total_items = len(emojis)
    for i, (code, v) in enumerate(
        sorted(emojis.items(), key=lambda item: item[1]['en'])
    ):
        emj = escapedToUnicodeMap[code]

        alternative = re.sub(r'\\U0000FE0[EF]$', '', code)
        emj_no_variant = escapedToUnicodeMap[alternative]

        # Add existing alias from EMOJI_DATA
        aliases: Set[str] = set()
        if emj in emoji_pkg.EMOJI_DATA and 'alias' in emoji_pkg.EMOJI_DATA[emj]:
            aliases.update(a[1:-1] for a in emoji_pkg.EMOJI_DATA[emj]['alias'])
        old_aliases = set(aliases)

        if (
            emj_no_variant in emoji_pkg.EMOJI_DATA
            and 'alias' in emoji_pkg.EMOJI_DATA[emj_no_variant]
        ):
            aliases.update(
                a[1:-1] for a in emoji_pkg.EMOJI_DATA[emj_no_variant]['alias']
            )

        # Add alias from GitHub API
        github_aliases = find_github_aliases(emj, github_alias_dict, v, emj_no_variant)
        aliases.update(
            shortcut
            for shortcut in github_aliases
            if shortcut not in all_existing_aliases_and_en
        )
        used_github_aliases.update(github_aliases)

        # Add alias from cheat sheet
        if (
            emj in cheat_sheet_dict
            and cheat_sheet_dict[emj] not in all_existing_aliases_and_en
        ):
            aliases.add(cheat_sheet_dict[emj][1:-1])
        if (
            emj_no_variant in cheat_sheet_dict
            and cheat_sheet_dict[emj_no_variant] not in all_existing_aliases_and_en
        ):
            aliases.add(cheat_sheet_dict[emj_no_variant][1:-1])

        # Add alias from youtube
        if emj in youtube_dict:
            aliases.update(
                shortcut[1:-1]
                for shortcut in youtube_dict[emj]
                if shortcut not in all_existing_aliases_and_en
            )
        if emj_no_variant in youtube_dict:
            aliases.update(
                shortcut[1:-1]
                for shortcut in youtube_dict[emj_no_variant]
                if shortcut not in all_existing_aliases_and_en
            )

        # Remove if alias is same as 'en'-name
        if v['en'] in aliases:
            aliases.remove(v['en'])

        # Store new aliases to print them at the end after the JSON
        if emj in emoji_pkg.EMOJI_DATA:
            if 'alias' in emoji_pkg.EMOJI_DATA[emj]:
                diff = aliases.difference(
                    a[1:-1] for a in emoji_pkg.EMOJI_DATA[emj]['alias']
                )
            else:
                diff = aliases
            for a in diff:
                new_aliases.append(f'# alias NEW {a} FOR {emj} CODE {code}')

        aliases_list = list(aliases)

        # Keep the order of existing aliases intact
        if emj in emoji_pkg.EMOJI_DATA and 'alias' in emoji_pkg.EMOJI_DATA[emj]:
            aliases_list = [a[1:-1] for a in emoji_pkg.EMOJI_DATA[emj]['alias']] + [
                a for a in aliases_list if f':{a}:' not in emoji_pkg.EMOJI_DATA[emj]['alias']
            ]

        if any('flag_for_' in a for a in aliases_list):
            # Put the :flag_for_COUNTRY: alias as the first entry so that it gets picked by demojize()
            # This ensures compatibility because in the past there was only the :flag_for_COUNTRY: alias
            aliases_list = [a for a in aliases_list if 'flag_for_' in a] + [
                a for a in aliases_list if 'flag_for_' not in a
            ]

        # Format the emoji code for the JSON
        # Only escape unicode points \ufe0f and \u200d so that similarly displayed emoji can be visually differentiated
        pretty_code = emj.replace('\ufe0f', '\\ufe0f').replace('\u200d', '\\u200d')

        # Write/Print the data as JSON
        alias = ''
        if len(aliases_list) > 0:
            alias_list_str = ', '.join([f'":{a}:"' for a in aliases_list])
            alias = ',\n  "alias": [%s]' % (alias_list_str,)
        variant = ',\n  "variant": true' if 'variant' in v else ''
        entry = f""""{pretty_code}": {{
  "en": ":{v["en"]}:",
  "status": {emoji_pkg.STATUS[v['status']]},
  "E": {v['version']:g}{alias}{variant}
}}"""
        # print(entry, end=',\n',)
        if i == total_items - 1:
            fp.write(f'{entry}\n}}\n')
        else:
            fp.write(f'{entry},\n')
        if v['status'] == 'fully_qualified':
            f += 1
        elif v['status'] == 'component':
            c += 1

    logging.debug(f' # Total count of emojis: {len(emojis)}')
    logging.debug(f' # fully_qualified: {f}')
    logging.debug(f' # component: {c}\n')
    logging.debug('\n'.join(new_aliases))

    # Check if all aliases from GitHub API were used
    for github_alias in github_alias_dict:
        if github_alias not in used_github_aliases:
            logging.debug(
                f'# Unused Github alias: {github_alias} {github_alias_dict[github_alias]} {to_ascii(github_alias_dict[github_alias])}'
            )

    logging.info('\n\n  Done.')

    fp.close()

    logging.info('\n\n  Checking json file. Any errors should appear below:\n')
    with open(out_file, 'rt', encoding='utf-8') as fp:
        json.load(fp)
    with open(out_file, 'rb') as fp:
        json.load(fp)

--- END OF utils/generate_emoji.py ---


--- START OF utils/generate_emoji_translations.py ---
"""
Update the translation of the emoji names in the emoji.json file.
The translation is based on the Unicode CLDR annotations and the emojiterra.com website.
The output files are emoji_{xy}.json where {xy} is the letter language code
"""

import sys
import os
from pathlib import Path
from typing import Dict, Optional, Set
import re
import io
import xml.etree.ElementTree as ET
import logging
import json

import bs4

from generateutils import get_text_from_url, adapt_emoji_name, to_ascii

logging.basicConfig(stream=sys.stderr, level=logging.DEBUG)

include = os.path.relpath(os.path.join(os.path.dirname(__file__), '..'))
sys.path.insert(0, include)
import emoji as emoji_pkg  # noqa: E402

emoji_pkg.config.load_language()  # Make all languages available in EMOJI_DATA


def get_emojiterra_from_url(url: str) -> Dict[str, str]:
    html = get_text_from_url(url)

    soup = bs4.BeautifulSoup(html, 'html.parser')
    emojis: Dict[str, str] = {}

    lis = soup.find_all('li')

    data = [
        li
        for li in lis
        if 'class' in li.attrs
        and 'href' not in li.attrs
        and 'e-' in str(li['class'])
        and li['title'].strip()
        and li.text.strip()
    ]

    for i in data:
        code = i.text.strip()
        emojis[code] = i['title'].strip()

    assert len(data) > 100, f'emojiterra data from {url} has only {len(data)} entries'

    return emojis


def get_UNICODE_EMOJI(lang: str) -> Dict[str, str]:
    return {
        emj: emoji_pkg.EMOJI_DATA[emj][lang]
        for emj in emoji_pkg.EMOJI_DATA
        if lang in emoji_pkg.EMOJI_DATA[emj]
    }


def add_unicode_annotations(data: Dict[str, str], lang: str, url: str):
    xml = get_text_from_url(url)

    tree = ET.fromstring(xml)
    annotations = tree.find('annotations')
    assert annotations is not None, f'No annotations found in {url}'
    for annotation in annotations:
        if annotation.get('type') == 'tts':
            emj = annotation.get('cp')
            assert annotation.text is not None, 'Empty annotation text'
            text = annotation.text.strip()
            assert emj is not None, f'No code point found in {url} for {annotation}'
            assert text is not None, f'No text found in {url} for {annotation}'

            emoji_name = adapt_emoji_name(text, lang, emj)

            if emj in data and data[emj] != emoji_name:
                print(
                    f'# {lang}: {emj} CHANGED {data[emj]} TO {emoji_name} \t\t(Source: {text})'
                )

            data[emj] = emoji_name


def extract_names(
    github_tag: str,
    github_lang: str,
    lang: str,
    emoji_terra: Optional[Dict[str, str]] = None,
) -> Dict[str, str]:
    """Copies emoji.EMOJI_DATA[emj][lang] and adds the names from the Unicode CLDR xml

    Find latest tag at https://cldr.unicode.org/index/downloads or
    https://github.com/unicode-org/cldr/tree/main/common/annotations
    """

    emoji_terra = {} if emoji_terra is None else emoji_terra

    data = get_UNICODE_EMOJI(lang)
    add_unicode_annotations(
        data,
        lang,
        f'https://github.com/unicode-org/cldr/raw/{github_tag}/common/annotations/{github_lang}.xml',
    )
    add_unicode_annotations(
        data,
        lang,
        f'https://github.com/unicode-org/cldr/raw/{github_tag}/common/annotationsDerived/{github_lang}.xml',
    )

    # Add names from emojiterra if there is no unicode annotation
    for emj, name in emoji_terra.items():
        if emj in emoji_pkg.EMOJI_DATA and emj not in data:
            emoji_name = adapt_emoji_name(name, lang, emj)
            data[emj] = emoji_name

    # There are some emoji with two code sequences for the same emoji, one that ends with \uFE0F and one that does not.
    # The one that ends with \uFE0F is the "new" emoji, that is RGI.
    # The Unicode translation data sometimes only has one of the two code sequences and is missing the other one.
    # In that case we want to use the existing translation for both code sequences.
    missing_translation: Dict[str, str] = {}
    for emj in data:
        if (
            emj.endswith('\ufe0f')
            and emj[0:-1] not in data
            and emj[0:-1] in emoji_pkg.EMOJI_DATA
        ):
            # the emoji NOT ending in \uFE0F exists in EMOJI_DATA but is has no translation
            # e.g. ':pirate_flag:' -> '\U0001F3F4\u200D\u2620\uFE0F' or '\U0001F3F4\u200D\u2620'
            missing_translation[emj[0:-1]] = data[emj]

        with_emoji_type = f'{emj}\ufe0f'
        if (
            not emj.endswith('\ufe0f')
            and with_emoji_type not in data
            and with_emoji_type in emoji_pkg.EMOJI_DATA
        ):
            # the emoji ending in \uFE0F exists in EMOJI_DATA but is has no translation
            # e.g. ':face_in_clouds:' -> '\U0001F636\u200D\U0001F32B\uFE0F' or '\U0001F636\u200D\U0001F32B'
            missing_translation[with_emoji_type] = data[emj]

    # Find emoji that contain \uFE0F inside the sequence (not just as a suffix)
    # e.g. ':eye_in_speech_bubble:' -> '\U0001F441\uFE0F\u200D\U0001F5E8\uFE0F'
    for emj in emoji_pkg.EMOJI_DATA:
        if emj in data:
            continue
        emj_no_variant = emj.replace('\ufe0f', '')
        if emj_no_variant != emj and emj_no_variant in data:
            # the emoji with \uFE0F has no translation, but the emoji without all \uFE0F has a translation
            data[emj] = data[emj_no_variant]

    data.update(missing_translation)

    return data


if __name__ == '__main__':
    logging.warning(
        'Please run generate_emoji.py before this script to update the list of emojis (emoji.json file).'
    )

    logging.info('  Downloading...\n')

    emojis = emoji_pkg.EMOJI_DATA

    # Find latest release tag at https://cldr.unicode.org/index/downloads
    # or  https://github.com/unicode-org/cldr/releases
    github_tag = 'release-46-1'
    languages = {
        # Update names in other languages:
        'de': extract_names(github_tag, 'de', 'de', get_emojiterra_from_url('https://emojiterra.com/de/tastatur/')),
        'es': extract_names(github_tag, 'es', 'es', get_emojiterra_from_url('https://emojiterra.com/es/teclado/')),
        'fr': extract_names(github_tag, 'fr', 'fr', get_emojiterra_from_url('https://emojiterra.com/fr/clavier/')),
        'ja': extract_names(github_tag, 'ja', 'ja', get_emojiterra_from_url('https://emojiterra.com/keyboard/ja/')),
        'ko': extract_names(github_tag, 'ko', 'ko', get_emojiterra_from_url('https://emojiterra.com/keyboard/ko/')),
        'pt': extract_names(github_tag, 'pt', 'pt', get_emojiterra_from_url('https://emojiterra.com/pt/copiar/')),
        'it': extract_names(github_tag, 'it', 'it', get_emojiterra_from_url('https://emojiterra.com/it/tastiera/')),
        'fa': extract_names(github_tag, 'fa', 'fa', get_emojiterra_from_url('https://emojiterra.com/keyboard/fa/')),
        'id': extract_names(github_tag, 'id', 'id', get_emojiterra_from_url('https://emojiterra.com/keyboard/id/')),
        'zh': extract_names(github_tag, 'zh', 'zh', get_emojiterra_from_url('https://emojiterra.com/keyboard/zh/')),
        'ru': extract_names(github_tag, 'ru', 'ru', get_emojiterra_from_url('https://emojiterra.com/keyboard/ru/')),
        'tr': extract_names(github_tag, 'tr', 'tr', get_emojiterra_from_url('https://emojiterra.com/keyboard/tr/')),
        'ar': extract_names(github_tag, 'ar', 'ar', get_emojiterra_from_url('https://emojiterra.com/keyboard/ar/')),

        # Do not update names in other languages:
        # 'de': get_UNICODE_EMOJI('de'),
        # 'es': get_UNICODE_EMOJI('es'),
        # 'fr': get_UNICODE_EMOJI('fr'),
        # 'ja': get_UNICODE_EMOJI('ja'),
        # 'ko': get_UNICODE_EMOJI('ko'),
        # 'pt': get_UNICODE_EMOJI('pt'),
        # 'it': get_UNICODE_EMOJI('it'),
        # 'fa': get_UNICODE_EMOJI('fa'),
        # 'id': get_UNICODE_EMOJI('id'),
        # 'zh': get_UNICODE_EMOJI('zh'),
        # 'ru': get_UNICODE_EMOJI('ru'),
        # 'tr': get_UNICODE_EMOJI('tr'),
        # 'ar': get_UNICODE_EMOJI('ar'),
    }

    logging.info('  Combining...\n')

    used_github_aliases: Set[str] = set()

    all_existing_aliases_and_en = set(
        item
        for emj_data in emoji_pkg.EMOJI_DATA.values()
        for item in emj_data.get('alias', [])
    )
    all_existing_aliases_and_en.update(
        emj_data['en'] for emj_data in emoji_pkg.EMOJI_DATA.values()
    )

    f = 0
    c = 0
    new_aliases = []
    logging.info('  Writing into files:\n')

    fps: Dict[str, io.BufferedWriter] = {}
    for lang in languages:
        out_file = (
            Path(emoji_pkg.__file__)
            .parent.joinpath(f'unicode_codes/emoji_{lang}.json')
            .resolve()
        )
        logging.info(f'   *  {out_file}')
        fps[lang] = open(out_file, mode='wb')
        fps[lang].write('{\n'.encode('utf-8'))

    for emj, v in sorted(emojis.items(), key=lambda item: item[1]['en']):
        code = to_ascii(emj)
        alternative = re.sub(r'\\U0000FE0[EF]$', '', code)
        emj_no_variant = alternative.encode().decode('unicode-escape')

        translation = None
        for lang in languages:
            if emj in languages[lang]:
                translation = languages[lang][emj]
            elif 'variant' in v:
                # the language annotation uses the normal emoji (no variant), while the emoji-test.txt uses the emoji or text variant
                if emj_no_variant in languages[lang]:
                    translation = languages[lang][emj_no_variant]

            if not translation:
                continue

            # Format the emoji code for the JSON
            # Only escape unicode points \ufe0f and \u200d so that similarly displayed emoji can be visually differentiated
            pretty_code = emj.replace('\ufe0f', '\\ufe0f').replace('\u200d', '\\u200d')

            # Print the data as JSON
            entry = f'"{pretty_code}": "{translation}",'
            # print(entry, end='\n',)
            fps[lang].write(f'{entry}\n'.encode('utf-8'))

    for lang in languages:
        fps[lang].seek(-2, os.SEEK_CUR)
        fps[lang].write('\n}\n'.encode('utf-8'))
        fps[lang].close()

    logging.info('\n\n  Checking json files. Any errors should appear below:\n')
    for lang in languages:
        out_file = (
            Path(emoji_pkg.__file__)
            .parent.joinpath(f'unicode_codes/emoji_{lang}.json')
            .resolve()
        )
        logging.info(f'   *  {out_file}')

        with open(out_file, 'rt', encoding='utf-8') as fp:
            json.load(fp)
        with open(out_file, 'rb') as fp:
            json.load(fp)

--- END OF utils/generate_emoji_translations.py ---


--- START OF utils/requirements.txt ---
requests>=2.32.3
beautifulsoup4>=4.12.3
cloudscraper>=1.2.71

--- END OF utils/requirements.txt ---


--- START OF utils/testutils.py ---
from typing import Generator, Dict, Any, Tuple, Iterable
import sys
import unicodedata

import pytest
if sys.version_info < (3, 9):
    from typing_extensions import Literal  # type: ignore
else:
    from typing import Literal

import emoji.unicode_codes

_NormalizationForm = Literal['NFC', 'NFD', 'NFKC', 'NFKD']


@pytest.fixture
def load_all_languages():
    """Load all keys from JSON files into EMOJI_DATA and
    build all language packs (i.e. fill the cache)"""
    emoji.emojize('', language='alias')
    for lang_code in emoji.LANGUAGES:
        emoji.emojize('', language=lang_code)
    yield


def ascii(s: str) -> str:
    """return escaped Code points for non-ascii chars like \U000ab123"""
    return s.encode('unicode-escape').decode()


def normalize(form: _NormalizationForm, s: str) -> str:
    return unicodedata.normalize(form, s)


def is_normalized(form: _NormalizationForm, s: str) -> bool:
    if sys.version_info >= (3, 8):
        return unicodedata.is_normalized(form, s)
    else:
        return normalize(form, s) == s


_EMOJI_UNICODE: Dict[str, Any] = {
    lang: None for lang in emoji.LANGUAGES
}  # Cache for the language dicts
_ALIASES_UNICODE: Dict[str, str] = {}  # Cache for the aliases dict


def get_emoji_unicode_dict(lang: str) -> Dict[str, Any]:
    """Generate dict containing all fully-qualified and component emoji name for a language
    The dict is only generated once per language and then cached in _EMOJI_UNICODE[lang]"""

    emoji.config.load_language(lang)
    if not _EMOJI_UNICODE[lang]:
        _EMOJI_UNICODE[lang] = {
            data[lang]: emj
            for emj, data in emoji.EMOJI_DATA.items()
            if lang in data and data['status'] <= emoji.STATUS['fully_qualified']
        }

    return _EMOJI_UNICODE[lang]


def get_aliases_unicode_dict() -> Dict[str, str]:
    """Generate dict containing all fully-qualified and component aliases
    The dict is only generated once and then cached in _ALIASES_UNICODE"""

    if not _ALIASES_UNICODE:
        _ALIASES_UNICODE.update(get_emoji_unicode_dict('en'))
        for emj, data in emoji.EMOJI_DATA.items():
            if 'alias' in data and data['status'] <= emoji.STATUS['fully_qualified']:
                for alias in data['alias']:
                    _ALIASES_UNICODE[alias] = emj

    return _ALIASES_UNICODE


def all_language_packs() -> Generator[Tuple[str, Dict[str, Any]], None, None]:
    for lang_code in emoji.LANGUAGES:
        yield (lang_code, get_emoji_unicode_dict(lang_code))


def all_language_and_alias_packs() -> Generator[Tuple[str, Dict[str, Any]], None, None]:
    yield ('alias', get_aliases_unicode_dict())
    yield from all_language_packs()


def get_language_packs(
    *langs: Iterable[str],
) -> Generator[Tuple[str, Dict[str, Any]], None, None]:
    for lang_code, lang_pack in all_language_and_alias_packs():
        if lang_code in langs:
            yield (lang_code, lang_pack)

--- END OF utils/testutils.py ---


--- START OF utils/README.md ---
# Adding a new language

## Unicode repository

Find out if the language exists in the Unicode repository:
https://github.com/unicode-org/cldr/tree/main/common/annotations

If the language exists, open the `{language-code}.xml` file and check if there are actually translations for emoji.
We use the entries that have the attribute `type="tts"` because they only contain one translation, so we don't have
to decide which translation to use.
For example for Spanish, we can look at [`es.xml`](https://github.com/unicode-org/cldr/blob/main/common/annotations/es.xml).
Let's look at the entries for 😼:

```xml
<annotation cp="😼">cara | gato | gato haciendo una mueca | irónico | sonrisa</annotation>
<annotation cp="😼" type="tts">gato haciendo una mueca</annotation>
```

We use the second one with the `type="tts"`. This would result in the emoji name `:gato_haciendo_una_mueca:`


## Emojiterra

The data on https://emojiterra.com/ is also sourced from the unicode repository and very similar. Most notably the
countries/flags are included on emojiterra but no in the Unicode repository (they are located in a different file
on the Unicode respository).

We use the URL of the "Copy and Paste"-section to extract the data. Go to https://emojiterra.com/keyboard/ and
then select the language from the dropdown menu.
Note that the URL is sometimes localized. For example the Spanish url is `https://emojiterra.com/es/teclado/` but
the Turkish url is `https://emojiterra.com/keyboard/tr/`


## Generate JSON files

To generate all the emoji sequences, English names and aliases automatically from all the data, we use
[`utils/generate_emoji.py`](generate_emoji.py)

To update to a newer Unicode version, change the parameters of these lines:

```python
   emoji_source = get_emoji_from_url(16.0)
    emoji_sequences_source = get_emoji_variation_sequence_from_url('16.0.0')
```

The translations are generated with the script [`utils/generate_emoji_translations.py`](generate_emoji_translations.py)

Open the script and add the two-letter code of the language to the dict `languages = {`. For example, we can add `es`:

```python
languages = {
    'es': extract_names(get_language_data_from_url(github_tag, 'es'), 'es', get_emojiterra_from_url('https://emojiterra.com/es/copiar/')),
}
```

If you run the script, the JSON files in the directory `emoji/unicode_codes/` are replaced with the new files.

```sh
python -m pip install -r requirements.txt
python utils/generate_emoji.py
python utils/generate_emoji_translations.py
```

If you have added a new language you need to add the language to the `LANGUAGES` variable in [`emoji/unicode_codes/data_dict.py`](../emoji/unicode_codes/data_dict.py).

You can also add the new langauge to the `languages` dict in [`utils/gh-pages/generatePages.py`](gh-pages/generatePages.py#L26-L35).

## Test the new data

The final step is to run the tests to check that everything works as it should:

```sh
pytest

```

If the tests fail, the first step can be to run the test `test_emojize_name_only` alone to see if the regular expression
`emoji.core._EMOJI_NAME_PATTERN` contains all the necessary characters:

```sh
pytest -k test_emojize_name_only

```

If this test fails, it will print the character that is missing e.g.

```text
Regular expression is missing a character:
'،' ('\u0327') is not in the regular expression
```

It means that one of the emoji names contains the character `\u0327` but that character is not matched by `emoji.core._EMOJI_NAME_PATTERN`.
Instead of the character itself, it could also be another possible unicode form of the same letter.
Some letters (usually the ones with a diacritic) can be described in different forms in Unicode. There are at most four possible forms.
For example the `ç` in `:Curaçao:` has two different Unicode forms that we need to be able to find with our regular expression pattern:

```python
name = ':Curaçao:'
unicodedata.normalize('NFKC', name)  # ':Cura\\xe7ao:'
unicodedata.normalize('NFC', name)   # ':Cura\\xe7ao:'
unicodedata.normalize('NFKD', name)  # ':Curac\\u0327ao:'
unicodedata.normalize('NFD', name)   # ':Curac\\u0327ao:'
```

To solve this, you can strip/replace the offending character from the emoji name by changing the `adapt_emoji_name()` in `generateutils.py`.
There are already special cases for some languages.

You could also change the entries in the JSON file by hand if it is only a few special cases.

If you think the character should be kept in the name, then you have to add the character (and possibly the other Unicode forms of it)
to the regular expression `emoji.core._EMOJI_NAME_PATTERN`.

--- END OF utils/README.md ---


--- START OF utils/gh-pages/generatePages.py ---
"""Generate the files index.html and all.html that will contain a table of all supported emoji
Run with -minify to minify HTML for production"""

import sys
import os
import codecs
import django.conf
import django.template
from htmlmin.minify import html_minify

try:
    import emoji
except ImportError:
    include = os.path.relpath(os.path.join(os.path.dirname(__file__), '../..'))
    sys.path.insert(0, include)
    import emoji

    print('Imported emoji from %s' % os.path.abspath(os.path.join(include, 'emoji')))

# Configuration
OUT_DIR = os.path.abspath(os.path.dirname(__file__))
TEMPLATE_DIR = os.path.abspath(os.path.dirname(__file__))
TEMPLATE_FILE = os.path.join(TEMPLATE_DIR, 'template.html')
data = {'defaultLang': 'en'}

languages = {
    'en': emoji.emojize('en :United_Kingdom:'),
    'alias': emoji.emojize('alias :United_Kingdom:'),
    'es': emoji.emojize('es :Spain:'),
    'ja': emoji.emojize('ja :Japan:'),
    'ko': emoji.emojize('ko :South_Korea:'),
    'pt': emoji.emojize('pt :Portugal:'),
    'it': emoji.emojize('it :Italy:'),
    'fr': emoji.emojize('fr :France:'),
    'de': emoji.emojize('de :Germany:'),
    'fa': emoji.emojize('fa :Iran:'),
    'id': emoji.emojize('id :Indonesia:'),
    'zh': emoji.emojize('zh :China:'),
    'ru': emoji.emojize('ru :Russia:'),
    'ar': emoji.emojize('ar :Saudi_Arabia:'),
    'tr': emoji.emojize('tr :Turkey:', language='alias'),
}
language_args = {}


minify_enabled = sys.argv[-1] == '-minify'
if not minify_enabled:
    print('Run with -minify to minify HTML')


print('Collecting emoji data...')

data['lists'] = lists = []
for language in languages:
    emoji.config.load_language(language)
    if language in language_args:
        language_arg = language_args[language]
    elif language == data['defaultLang']:
        language_arg = ''
    else:
        language_arg = f'language="{language}"'

    emoji_list = []
    for code, emoji_data in emoji.EMOJI_DATA.items():
        if language not in emoji_data:
            continue
        names = (
            [emoji_data[language]]
            if isinstance(emoji_data[language], str)
            else emoji_data[language]
        )
        for name in names:
            emoji_list.append(
                {
                    'code': code,
                    'name': name,
                    'unicode': code.encode('ascii', 'backslashreplace').decode('ascii'),
                    'charname': code.encode('ascii', 'namereplace').decode('ascii'),
                    'xml': code.encode('ascii', 'xmlcharrefreplace').decode('ascii'),
                }
            )

    listentry = {
        'name': language,
        'pretty': languages[language],
        'languageArg': language_arg,
        'emojis': emoji_list,
    }
    lists.append(listentry)


# Render with django
TEMPLATES = [
    {
        'BACKEND': 'django.template.backends.django.DjangoTemplates',
        'DIRS': [TEMPLATE_DIR],
    }
]

django.conf.settings.configure(TEMPLATES=TEMPLATES)
django.setup()
template = django.template.loader.get_template(TEMPLATE_FILE)

print("Render 'all.html' ...")
with codecs.open(os.path.join(OUT_DIR, 'all.html'), 'w', encoding='utf-8') as f:
    html = template.render(data)
    if minify_enabled:
        print("Minify 'all.html' ...")
        html = html_minify(html)
    f.write(html)
    print(f"Wrote to {os.path.join(OUT_DIR, 'all.html')}")

print("Render 'index.html' ...")
# Remove emoji except for default list
for listentry in lists:
    if listentry['name'] != data['defaultLang']:
        listentry['emojis'] = []

with codecs.open(os.path.join(OUT_DIR, 'index.html'), 'w', encoding='utf-8') as f:
    html = template.render(data)
    if minify_enabled:
        print("Minify 'index.html' ...")
        html = html_minify(html)
    f.write(html)
    print(f"Wrote to {os.path.join(OUT_DIR, 'index.html')}")

print('Done.')

--- END OF utils/gh-pages/generatePages.py ---


--- START OF utils/gh-pages/requirements.txt ---
django>=4.1.1
django-htmlmin>=0.11.0

--- END OF utils/gh-pages/requirements.txt ---


--- START OF utils/gh-pages/main.css ---
:root {
  --main-color: #111;
  --main-bg: #f0f0ff;
  --model-bg: #99f;
  --modal-emoji-bg: white;
  --table-font-family: monospace;
  --table-header-bg: #ccf;
  --table-listheader-bg: #ddf;
  --table-even-bg: #ddf;
  --table-odd-bg: #f0f0ff;
  --font-family: "Segoe UI", "Nimbus Sans L", "Liberation Sans", "Open Sans", FreeSans, Arial, sans-serif;
}

body {
  font-size: larger;
  font-family: var(--font-family);
  background-color: var(--main-bg);
  color: var(--main-color);
  position:relative;
  min-height: 90vh;
}

h1 {
  text-align: center;
  font-size: x-large;
}

.footer {
  position: absolute;
  bottom: -3em;
  padding: 1em;
}

.controls {
  text-align: center;
}

.search {
  display: inline-block;
  box-sizing: border-box;
  border-radius: 4px;
  height: 2.1em;
  background-color: #fff;
  border: 1px solid rgba(0, 0, 0, 0.15);
  box-shadow: 0 2px 3px rgba(0, 0, 0, 0.06);
  padding-left: .5em;
  padding-right: .5em;
}

#search_full {
  appearance: none;
  font-size: 1em;
  background: none;
  outline: none;
  border: none;
  padding: 0;
  height: 2.1em;
  width: 17em;
}

.search_icon {
  border-radius: 0 4px 4px 0;
  color: #999;
  font-size: 1.25em;
  padding: 0 0.5em 0 0;
  margin-top: -1px;
  margin-bottom: -1px;
  margin-right: -3px;
  line-height: 1.5;
  cursor: default;
}

.copiable {
  user-select: all;
  cursor: copy;
}

.copiable.copied::after {
  display: block;
  height: 28px;
  opacity: 1.0;
  background-color: #EEE;
  color: black;
  border-radius: 10px;
  padding: 3px;
  margin: 0px;
  line-height: normal;
  font-size: 15px;
  font-weight: normal;
  font-family: var(--font-family);
  content: "Copied!";
  position: absolute;
  box-shadow: 0px 0px 10px #999 inset;
  transition: opacity 2s
}

.copiable.copiedfadeout::after {
  opacity: 0.0 !important;
}

.spinnerholder {
  display: inline-block;
  text-align: center;
  margin: auto;
  line-height: 2em;
  vertical-align: middle;
  width: 2em;
}

.roundspinner {
  position: relative;
  height: 30px;
  width: 30px;
  margin: 0px auto;
  display: inline-block;
  animation: spinnerrotation 3s infinite linear;
  cursor: wait;
  border: 3px solid #3e899fab;
  border-bottom-color: transparent;
  border-radius: 50%
}

@keyframes spinnerrotation {
  from {
    transform: rotate(0deg)
  }

  to {
    transform: rotate(359deg)
  }
}

.modal {
  box-sizing: content-box;
  background-color: transparent;
  position: fixed;
  left: 50%;
  top: 50%;
  transform: translate(-50%, -50%);
  z-index: 10;
  max-height: 300px;
  min-width: 280px;
  max-width: 300px;
}

@media (min-width: 600px) and (min-height: 480px) {
  .modal {
    max-height: 460px;
    max-width: 400px;
  }
}

@media (min-width: 600px) and (min-height: 680px) {
  .modal {
    max-height: 660px;
    max-width: 400px;
  }
}

@media (min-width: 800px) and (min-height: 780px) {
  .modal {
    max-height: 760px;
    max-width: 500px;
  }
}

@media (min-width: 900px) and (min-height: 780px) {
  .modal {
    max-height: 760px;
    max-width: 700px;
  }
}

.modal .content {
  background-color: var(--model-bg);
  overflow-y: auto;
  overflow-x: hidden;
  padding: 15px;
  max-width: 783px;
  height: 100%;
  max-height: 90vh;
  width: 100%;
  box-shadow: 5px 5px 10px black;
}

.modal samp {
  display: block;
  background-color: #fffd;
  padding: 2px;
  border-radius: 4px;
}

.modal samp.emoji {
  display: block;
  font-size: 100px;
  background-color: var(--modal-emoji-bg);
  text-align: center;
  line-height: 1.2;
  border: 2px solid #333;
  box-shadow: 0px 0px 5px #999 inset;
  padding: 25px 10px 10px 10px;
  margin: 0px auto;
}

@media (min-width: 600px) and (min-height: 480px) {
  .modal samp.emoji {
    font-size: 126px;
    line-height: 180px;
    border: 4px solid #333;
    box-shadow: 0px 0px 10px #999 inset;
  }
}

.modal code {
  display: block;
  background-color: #fffd;
  padding: 2px;
  border-radius: 4px;
  margin: 4px 0px;
}

.modal .name {
  text-align: center;
  font-size: larger;
  font-weight: bolder;
  margin-top: 0.3em;
}

table {
  margin: auto;
}

td {
  font-family: monospace;
  word-wrap: anywhere;
}

td:first-child {
  text-align: center
}

tr:nth-child(2n+1) {
  background-color: var(--table-odd-bg)
}

tr:nth-child(2n) {
  background-color: var(--table-even-bg)
}

tr.empty {
  display: none
}

tr>th:nth-child(3),
tr>td:nth-child(3),
tr>th:nth-child(4),
tr>td:nth-child(4),
tr>th:nth-child(5),
tr>td:nth-child(5) {
  display: none
}

.allcolumns tr>th:nth-child(3),
.allcolumns tr>td:nth-child(3),
.allcolumns tr>th:nth-child(4),
.allcolumns tr>td:nth-child(4),
.allcolumns tr>th:nth-child(5),
.allcolumns tr>td:nth-child(5) {
  display: table-cell
}

tr.listheader>* {
  background-color: var(--table-listheader-bg);
  position: -webkit-sticky;
  position: sticky;
  top: 0;
}

tr.header>* {
  background-color: var(--table-header-bg);
  position: -webkit-sticky;
  position: sticky;
  top: 28px;
}

tr.listheader.UNICODE_EMOJI_ENGLISH>th:first-child {
  background-color: #012169;
  background-image: radial-gradient(white 15%, #012169 60%);
  color: #c8102e
}

tr.listheader.UNICODE_EMOJI_ALIAS_ENGLISH>th:first-child {
  background-image: radial-gradient(#c8102e80 5%, #ffffff80 15%, #01216980 60%);
  color: black
}

tr.listheader.UNICODE_EMOJI_SPANISH>th:first-child {
  background-color: #ffc400;
  background-image: linear-gradient(#c60b1e, #ffc400, #ffc400, #c60b1e);
  color: black
}

tr.listheader.UNICODE_EMOJI_PORTUGUESE>th:first-child {
  background-color: red;
  background-image: linear-gradient(to right, #060, red, red, red);
  color: white
}

tr.listheader.UNICODE_EMOJI_ITALIAN>th:first-child {
  background-color: #6cb06c;
  background-image: linear-gradient(to right, #6cb06c, white, #f72a2a);
  color: black
}

--- END OF utils/gh-pages/main.css ---


--- START OF utils/gh-pages/main.js ---
'use strict'

window.addEventListener('DOMContentLoaded', onLoad)

function onLoad () {
  // Show loading spinner immediately because the search cache will be building for some time
  createSpinner()

  // Add ui events
  document.getElementById('search_full').addEventListener('keyup', searchFullHandler)

  document.querySelectorAll('input[id^=enable_list_]').forEach(function (e) {
    if (document.location.pathname.indexOf('all.html') === -1 && e.classList.contains('notloaded')) {
      e.addEventListener('change', openAll)
    } else {
      e.addEventListener('change', searchFullHandler)
    }
  })

  document.getElementById('enable_more_columns').addEventListener('change', toggleMoreColums)
  document.querySelectorAll('#emoji_table tr').forEach(tr => tr.addEventListener('click', trClick))
  document.addEventListener('selectionchange', onSelectionChange)
  document.documentElement.addEventListener('click', closeModalOutsideClick)

  // Fix table header height, otherwise the two table headers (position:sticky) may overlap
  const rowHeight = document.querySelector('#emoji_table .listheader').clientHeight + 'px'
  document.querySelectorAll('#emoji_table .header>*').forEach(e => (e.style.height = rowHeight))

  // Parse url
  if (document.location.search.indexOf('enableList=enable_list_') !== -1) {
    const m = document.location.search.match(/enableList=(\w+)/)
    if (m) {
      document.getElementById(m[1]).checked = true
    }
  }
  if (document.location.search.indexOf('query=') !== -1) {
    const m = document.location.search.match(/query=([^=#&]+)/)
    if (m) {
      document.getElementById('search_full').value = decodeURIComponent(m[1])
    }
  }

  // Update table (and build search cache)
  toggleMoreColums()
  searchFullHandler().then(hideSpinner)
}

function openAll () {
  // Open all.html with parameters
  this.checked = false
  let params = `enableList=${this.id}`
  if (document.getElementById('search_full').value) {
    params += `&query=${encodeURIComponent(document.getElementById('search_full').value)}`
  }
  document.location.href = `all.html?${params}`
}

function onSelectionChange (e) {
  // If the selected text is in a .copiable element, copy the whole textContent to the clipboard
  const selection = document.getSelection()
  if (selection.toString().length === 0) {
    return
  }
  if (selection.anchorNode != null) {
    let node = null
    if ('classList' in selection.anchorNode && selection.anchorNode.classList.contains('copiable')) {
      node = selection.anchorNode
    } else if (selection.anchorNode.parentNode && 'classList' in selection.anchorNode.parentNode && selection.anchorNode.parentNode.classList.contains('copiable')) {
      node = selection.anchorNode.parentNode
    }
    if (node) {
      selection.removeAllRanges()
      const range = document.createRange()
      range.selectNode(node)
      selection.addRange(range)
      navigator.clipboard.writeText(node.textContent)
      node.classList.add('copied')
      window.setTimeout(() => node.classList.add('copiedfadeout'), 100)
      window.setTimeout(() => { node.classList.remove('copied'); node.classList.remove('copiedfadeout') }, 2000)
    }
  }
}

function closeModalOutsideClick (ev) {
  if (document.querySelector('.modal').style.display === 'none') {
    return
  }
  let node = ev.target
  while (node && node !== document.body) {
    if ('classList' in node && node.classList.contains('modal')) {
      return
    }
    node = node.parentNode
  }
  closeModal()
}

function closeModal () {
  document.querySelector('.modal').style.display = 'none'
}

function examplePythonCode (fName, stringArg, argN) {
  const s = `emoji.<span style="color:#6f42c1">${fName}</span>(<span style="color:#032f62">${JSON.stringify(stringArg)}</span>`
  if (argN) {
    return `${s}, ${argN.replace(/=(\w*)/g, '<span style="color:#005cc5">=$1</span>').replace(/("\w+")/g, '<span style="color:#032f62">$1</span>')})`
  }
  return `${s})`
}

function trClick () {
  const tr = this
  if (tr.className.indexOf('listheader') !== -1) {
    // list header click

  } else if (tr.className.indexOf('header') !== -1) {
    // top header click

  } else {
    // emoji row click
    const selection = document.getSelection()
    if (selection && !selection.isCollapsed) {
      // User is selecting text in the row -> don't open the modal
      return
    }
    loadMoreColumns()
    const tds = tr.querySelectorAll('td')
    const emoji = tds[0].textContent
    const name = tds[1].textContent
    const unicode = tds[2].textContent
    const charName = tds[3].textContent
    const xml = tds[4].textContent
    // find language code
    let listheader = tr.previousElementSibling
    while (listheader && listheader.className.indexOf('listheader') === -1) {
      listheader = listheader.previousElementSibling
    }
    const modal = document.querySelector('.modal')

    modal.querySelector('.emoji').textContent = emoji
    modal.querySelector('.name').textContent = name
    modal.querySelector('.unicode').textContent = unicode
    modal.querySelector('.charname').textContent = charName
    modal.querySelector('.xml').textContent = xml
    modal.querySelector('.example .emojize').innerHTML = examplePythonCode('emojize', name, listheader.dataset.languageArg)
    modal.querySelector('.example .demojize').innerHTML = examplePythonCode('demojize', emoji, listheader.dataset.languageArg)

    window.setTimeout(function () {
      modal.style.display = 'block'
    }, 100)
  }
}

let moreColumnsLoaded = false
function loadMoreColumns () {
  if (!moreColumnsLoaded) {
    // Fill missing columns in table
    document.querySelectorAll('#emoji_table tr>td:nth-child(3)').forEach(function (td) {
      const tdU32 = td.parentNode.appendChild(document.createElement('td'))
      tdU32.textContent = xmlFromPython32(td.textContent)
    })
    moreColumnsLoaded = true
  }
}

function xmlFromPython32 (s) {
  return s.trim().split('\\').slice(1).map(c => `&#${parseInt(c.substring(1), 16)};`).join('')
}

function toggleMoreColums () {
  if (document.getElementById('enable_more_columns').checked) {
    loadMoreColumns()
    document.getElementById('emoji_table').classList.add('allcolumns')
  } else {
    document.getElementById('emoji_table').classList.remove('allcolumns')
  }
}

function wordsInText (words, text) {
  let matches = 0
  for (const word of words) {
    matches += (text.indexOf(word) !== -1)
  }
  return matches === words.length
}

let searchTimeOut = null
let lastSearchParameters = null
let enabledLists = {}
function searchFullHandler () {
  return new Promise(function downloadCrossSiteImage (resolve) {
    window.clearTimeout(searchTimeOut)
    const query = document.getElementById('search_full').value
    searchTimeOut = window.setTimeout(() => searchFull(query, resolve), 500)
  })
}

let searchCache = null
function buildSearchCache () {
  searchCache = []
  document.querySelectorAll('#emoji_table tr').forEach(function (tr, i) {
    if (tr.className.indexOf('header') === -1) {
      searchCache.push({
        tr: tr,
        text: tr.textContent.toLowerCase(),
        list: tr.className
      })
    }
  })
}

function createSpinner () {
  if (document.querySelector('.spinnerholder .roundspinner')) {
    document.querySelector('.spinnerholder').style.display = 'inline-block'
    return
  }

  const spinnerHolder = document.createElement('div')
  spinnerHolder.classList.add('spinnerholder')
  const spinner = spinnerHolder.appendChild(document.createElement('div'))
  spinner.classList.add('roundspinner')

  const oldSpinnerHolder = document.querySelector('.spinnerholder')
  oldSpinnerHolder.parentNode.replaceChild(spinnerHolder, oldSpinnerHolder)
}

function hideSpinner () {
  if (document.querySelector('.spinnerholder')) {
    document.querySelector('.spinnerholder').style.display = 'none'
  }
}

function searchFull (query, onDoneCallback) {
  // Full text search in the table
  searchTimeOut = null

  createSpinner()

  if (searchCache == null) {
    buildSearchCache()
  }
  const searchWords = query.toLowerCase().split(/\s+/)

  enabledLists = {}

  const table = document.getElementById('emoji_table')

  document.querySelectorAll('input[id^=enable_list_]').forEach(function (e) {
    if (e.checked) {
      enabledLists[e.dataset.name] = true
      const tr = table.querySelector(`tr.listheader.${e.dataset.name}`)
      if (tr) {
        tr.style.display = ''
      }
    } else {
      const tr = table.querySelector(`tr.listheader.${e.dataset.name}`)
      if (tr) {
        tr.style.display = 'none'
      }
    }
  })

  if (lastSearchParameters === query + '#' + Object.keys(enabledLists).join(',')) {
    hideSpinner()
    if (onDoneCallback) {
      onDoneCallback()
    }
    return
  }

  const tableHolder = document.getElementById('emoji_table_holder')
  const fragment = document.createDocumentFragment()
  fragment.appendChild(table)

  table.querySelectorAll('tr.empty').forEach(e => e.remove())

  const onDone = function () {
    if (tableHolder.firstElementChild) {
      tableHolder.replaceChild(fragment, tableHolder.firstElementChild)
    } else {
      tableHolder.appendChild(fragment)
    }
    lastSearchParameters = query + '#' + Object.keys(enabledLists).join(',')
    hideSpinner()
    if (onDoneCallback) {
      onDoneCallback()
    }
  }

  window.setTimeout(() => searchFullWorker(searchWords, 0, 0, 4000, onDone))
}

function searchFullWorker (searchWords, startIndex, hiddenNodesCounter, batchSize, cb) {
  const endIndex = Math.min(startIndex + batchSize, searchCache.length)
  const emptyTr = document.createElement('tr')
  emptyTr.classList.add('empty')
  for (let i = startIndex; i < endIndex; i++) {
    const entry = searchCache[i]
    if (!(entry.list in enabledLists)) {
      entry.tr.style.display = 'none'
    } else if (!searchWords.length || wordsInText(searchWords, entry.text)) {
      entry.tr.style.display = ''
      if (hiddenNodesCounter > 0 && hiddenNodesCounter % 2 === 1) {
        // Insert an empty node to correct the odd/even css behaviour
        entry.tr.parentNode.insertBefore(emptyTr.cloneNode(false), entry.tr)
        hiddenNodesCounter = 0
      }
    } else {
      entry.tr.style.display = 'none'
      hiddenNodesCounter++
    }
  }

  if (endIndex < searchCache.length - 1) {
    window.setTimeout(() => searchFullWorker(searchWords, endIndex, hiddenNodesCounter, batchSize, cb))
  } else if (cb) {
    cb()
  }
}

--- END OF utils/gh-pages/main.js ---


--- START OF utils/gh-pages/.gitignore ---
index.html
all.html

--- END OF utils/gh-pages/.gitignore ---


--- START OF utils/gh-pages/template.html ---
<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>emoji overview</title>
  <meta name="description" content="Overview of all emoji made availabe by the carpedm20/emoji python package. Search through all emoji and copy their Unicode, HTML entities or python code">
  <meta property="og:image" content="https://raw.githubusercontent.com/carpedm20/emoji/master/example/example.png">

  <link rel="stylesheet" href="main.css">
  <script src="main.js"></script>
</head>

<body>

<h1>List of all emojis in the <a href="https://github.com/carpedm20/emoji">emoji</a> python package</h1>

<div class="controls">
  <div class="spinnerholder"></div>
  <div class="search"><span class="search_icon">🔍</span><input type="text" id="search_full" placeholder="Search" /></div>
  <br>
  {% for entry in lists %}
    <input type="checkbox" id="enable_list_{{ entry.name }}" data-name="{{ entry.name }}" {% if entry.name == defaultLang %} checked {% endif %} {% if not entry.emojis %} class="notloaded" {% endif %} title="{{ entry.name }}">
    <label for="enable_list_{{ entry.name }}" title="{{ entry.name }}">{{ entry.pretty }}</label>
  {% endfor %}
  <br>
  <input type="checkbox" id="enable_more_columns"><label for="enable_more_columns">Show more columns</label>

</div>

<div id="emoji_table_holder">
<table id="emoji_table">
  <tr class="header">
    <th>emoji</th>
    <th>name</th>
    <th>Unicode</th>
    <th>char name</th>
    <th>xml/html</th>
  </tr>
  {% for entry in lists %}
  {% if entry.emojis %}
    <tr class="{{ entry.name }} listheader" data-language-arg="{{ entry.languageArg }}">
      <th>{{ entry.pretty }}</th>
      <th colspan="5">{{ entry.name }}</th>
    </tr>
    {% for emoji in entry.emojis %}
      <tr class="{{ entry.name }}">
        <td>{{ emoji.code }}</td>
        <td>{{ emoji.name }}</td>
        <td>{{ emoji.unicode }}</td>
        <td>{{ emoji.charname }}</td>
      </tr>
    {% endfor %}
  {% else %}
    <!-- Omitted {{ entry.name }} because no emojis were found -->
  {% endif %}
  {% endfor %}

  <tr class="headerend">
    <th colspan="6">The end. No more results.</th>
  </tr>
</table>
</div>

<div class="modal" style="display:none">
  <div class="content">
    <samp class="emoji copiable"></samp>
    <samp class="name copiable"></samp>
    Python Unicode: <samp class="unicode copiable"></samp>
    Python Unicode name: <samp class="charname copiable"></samp>
    XML/HTML: <samp class="xml copiable"></samp>
    Python example: <div class="example"><code class="code emojize copiable"></code><code class="demojize copiable"></code></div>
  </div>
</div>

<div class="footer">
  <a href="https://github.com/carpedm20/emoji">GitHub</a> / <a href="https://pypi.org/project/emoji/">PyPI</a> / <a href="https://carpedm20.github.io/emoji/docs/">documentation</a>
</div>

</body>
</html>

--- END OF utils/gh-pages/template.html ---


--- START OF utils/gh-pages/README.rst ---
Emoji overview on GitHub Pages
==============================

Generate a HTML website that contains all emoji and names that are currently supported.

GitHub Pages
------------

https://carpedm20.github.io/emoji/

On every release the content on the GitHub Pages is updated by a GitHub Action:
`updateGithubPages.yml <../../.github/workflows/updateGithubPages.yml>`__.

You can view the generated source in the `gh-pages <https://github.com/carpedm20/emoji/tree/gh-pages>`__ branch.


Build pages locally
-------------------

.. code-block:: sh

    python -m pip install -r utils/gh-pages/requirements.txt
    python utils/gh-pages/generatePages.py

--- END OF utils/gh-pages/README.rst ---


--- START OF .github/workflows/updateGithubPages.yml ---
name: Update GithubPages documentation

on:
  workflow_dispatch:
  release:
    types: [published]

jobs:
  generateGHPages:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.12'
    - name: Install package
      run: |
        python -m pip install --upgrade pip setuptools
        python -m pip install .
    - name: Retain directories
      run: |
        cp -R utils/gh-pages ..
        cp -R docs ..
        cp -R emoji ../emoji_module
    - name: Switch to branch gh-pages
      run: |
        git stash
        git config --global user.name github-actions
        git config --global user.email 41898282+github-actions[bot]@users.noreply.github.com
        git fetch origin
        if ! git checkout -b gh-pages origin/gh-pages; then
            echo Create new orphan branch gh-pages;
            git checkout --orphan gh-pages;
            git rm -rf .;
        fi;
    - name: Install requirements
      run: |
        python -m pip install -r ../gh-pages/requirements.txt
        python -m pip install -r ../docs/requirements.txt
    - name: Generate HTML
      run: |
        python ../gh-pages/generatePages.py -minify
    - name: Move emoji module in correct path for sphinx links
      run: |
        mkdir -p ../emoji/
        mv ../emoji_module/* ../emoji/
    - name: Generate sphinx
      run: |
        make --directory ../docs html
    - name: Move files into repository
      run: |
        mv ../gh-pages/index.html .
        mv ../gh-pages/all.html .
        mv ../gh-pages/main.css .
        mv ../gh-pages/main.js .
        rm -R docs || true
        mv ../docs/_build/html docs
        touch .nojekyll
    - name: git commit & push
      run: |
        git add index.html all.html main.css main.js docs .nojekyll
        # Use "|| true" or "--allow-empty"  otherwise the action fails for empty commits
        git commit -m "Updated gh-pages" || true
        git push -u origin gh-pages

--- END OF .github/workflows/updateGithubPages.yml ---


--- START OF .github/workflows/pypipublish.yml ---
name: Upload Python Package to PyPi.org

on:
  release:
    types: [published]

jobs:
  build-package:
    name: Build & verify package
    runs-on: ubuntu-latest
    permissions:
      id-token: write
      attestations: write
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
      - uses: hynek/build-and-inspect-python-package@v2
        with:
          attest-build-provenance-github: 'true'

  deploy:
    name: Publish to pypi.org
    environment:
      name: pypi
      url: https://pypi.org/project/emoji/
    runs-on: ubuntu-latest
    needs: build-package
    permissions:
      id-token: write
      attestations: write
    steps:
      - name: Download package built by build-and-inspect-python-package
        uses: actions/download-artifact@v4
        with:
          name: Packages
          path: dist
      - name: Upload package to PyPI
        uses: pypa/gh-action-pypi-publish@v1.10.1

--- END OF .github/workflows/pypipublish.yml ---


--- START OF .github/workflows/pythonTests.yml ---
name: Test python package
on:
  workflow_dispatch:
  push:
    branches-ignore:
      - 'gh-pages'
  pull_request:
    branches-ignore:
      - 'gh-pages'
jobs:
  pytest:
    runs-on: ubuntu-22.04
    strategy:
      max-parallel: 8
      matrix:
        python-version:
          - "3.7"
          - "3.8"
          - "3.9"
          - "3.10"
          - "pypy-3.10"
          - "3.11"
          - "3.12"
          - "3.13-dev"
    steps:
    - uses: actions/checkout@v4
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v5
      with:
        python-version: ${{ matrix.python-version }}
    - name: Install dev dependencies
      run: |
        python -m pip install .[dev]
    - name: Test with pytest
      run: |
        pytest
    - name: Test with pytest (random test order)
      run: |
        pytest --shuffle

  lint:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ["3.13-dev"]

    steps:
      - uses: actions/checkout@v4
      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Install Dependencies
        run: |
          python -m pip install .[dev]

      - name: Pyright
        uses: jakebailey/pyright-action@v2

--- END OF .github/workflows/pythonTests.yml ---


--- START OF .github/workflows/build.yml ---
name: Build & test whl

on: [push]

jobs:

  build-package:
    name: Build & verify package
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - uses: hynek/build-and-inspect-python-package@v2
        id: baipp

    outputs:
      python-versions: ${{ steps.baipp.outputs.supported_python_classifiers_json_array }}

  testwheel:
    name: Test whl
    runs-on: ubuntu-latest
    needs: build-package
    strategy:
      max-parallel: 4
      matrix:
        python-version:
            - "3.10"
            - "3.11"
            - "3.12"
            - "3.13-dev"
    steps:

    - name: Download pre-built packages
      uses: actions/download-artifact@v4
      with:
        name: Packages
        path: dist
    - name: Extract source tarball
      run: tar xf dist/*.tar.gz --strip-components=1
    - name: Remove source code
      run: rm -R emoji
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v5
      with:
        python-version: ${{ matrix.python-version }}
    - name: Install tox
      run: python -Im pip install tox
    - name: Run tox on wheel
      run: python -Im tox run --installpkg dist/*.whl

--- END OF .github/workflows/build.yml ---


--- START OF .git/config ---
[core]
	repositoryformatversion = 0
	filemode = true
	bare = false
	logallrefupdates = true
	ignorecase = true
	precomposeunicode = true
[remote "origin"]
	url = https://github.com/carpedm20/emoji.git
	fetch = +refs/heads/*:refs/remotes/origin/*
[branch "master"]
	remote = origin
	merge = refs/heads/master

--- END OF .git/config ---


--- START OF .git/HEAD ---
ref: refs/heads/master

--- END OF .git/HEAD ---


--- START OF .git/description ---
Unnamed repository; edit this file 'description' to name the repository.

--- END OF .git/description ---


--- START OF .git/packed-refs ---
# pack-refs with: peeled fully-peeled sorted 
b84a519c75ad282e2d00767b656a2f68e23035fa refs/remotes/origin/gh-pages
08c5cc4789d924ad4215e2fb2ee8f0b19a0d421f refs/remotes/origin/master
b3b70368b86e269f1e53079862a708e1e377cfbb refs/tags/1.0.0
6333b5a0b6ac1b80fe1e6915f1310d3018a0ab98 refs/tags/v.1.0.1
ea334f0206259729ff134135e2557960aa14816b refs/tags/v.1.1.0
9365b6a74b137593497880a5c001e1bc3827c607 refs/tags/v.1.1.1
b6f9c95f15ed3f99df87fec81a61a5a83cf3c3c7 refs/tags/v.1.2.0
70e7ba12dfaf3449a5d445b1e7de4ae2c6245d19 refs/tags/v.1.2.1
8e13deae6f11e3751543a78077362fafed73d247 refs/tags/v.1.3.0
b3aea088093232684e82ff18c44a3da09a026d6c refs/tags/v.1.4.0
1a6a3cbcafcbafaed7771e2f86d9cd09509071b7 refs/tags/v.1.4.1
0a3809facbbaf3b5327e2c0b18bc36e097a80f4e refs/tags/v.1.4.2
e97cef2f9851103ff3cb1a6abc57b16b806adb15 refs/tags/v0.3.4
170bb25ba35392ac8c218c7345f24f2d97999bc9 refs/tags/v1.5.0
89197c1c275bd493011ba36cb503df6096be00aa refs/tags/v1.5.1
57f010aa5776672c390796443a24cdc1e6d33726 refs/tags/v1.5.2
36e2419f4e13f572d825b27a53d796614b9a0a43 refs/tags/v1.6.0
7b3555a6469d60c2c2df1c25021b706b8fdb8c60 refs/tags/v1.6.1
e35fc45168376b273d8d04630dbb7f46c4544989 refs/tags/v1.6.2
17e7a1e60b7042a9cd02461bacf983226bb6823a refs/tags/v1.6.3
d8bbfe455c6fcd12b96ed1dce6e0978fe7a47431 refs/tags/v1.7.0
cf923b238136ec82b2060416a2de2c023189c684 refs/tags/v2.0.0
83cec961f4049ff5b13c69486c2c97498eff84f2 refs/tags/v2.1.0
ec64b72e8c98897c6b9c0e0d2aa72b5d439a20ee refs/tags/v2.10.0
645331c9474aaad7362ccb1d81279724514050fa refs/tags/v2.10.1
ceddc11675be53eb1a8907dc6cb2fc0fd214f548 refs/tags/v2.11.0
2be59bc0a302eacad0bbc91a0a24d9984d236c5e refs/tags/v2.11.1
099e3ade0e865c32cf971d945d3e76248fe825d2 refs/tags/v2.12.0
e83cf4acf6de5e5918b9a34f079214cde2aab87c refs/tags/v2.12.1
d34e4bf42ab7fc7284d9a686bb3b97afca3eeba1 refs/tags/v2.13.0
824fed5ebaa189426bd026b575322516d6e7671d refs/tags/v2.13.1
fb042640416232513a37b62a0abefb718721e088 refs/tags/v2.13.2
3209717f8547a587355648f28f1048f15a7bc795 refs/tags/v2.14.0
08c5cc4789d924ad4215e2fb2ee8f0b19a0d421f refs/tags/v2.14.1
f09583fdea35412416995fb073c8117588704742 refs/tags/v2.2.0
1a95133de1ad89d63ee5b09f93bbe67b12c14147 refs/tags/v2.3.0
839fd34c08d23c61d2b689263570b9ec7bde16d3 refs/tags/v2.4.0
6d8a4126f85e5a90d7e4b65a375bdf002dd77c36 refs/tags/v2.5.0
fde2fa78b74fdc4a85999fa2ba47c3858c79cb5d refs/tags/v2.5.1
63d73af34ae20cb4411a353a9eeb942a8ffba408 refs/tags/v2.6.0
9efbf8cc78d510d49a94e6988900508fe895ad6a refs/tags/v2.7.0
d97e3d431a0fffcfaba56c37d84dfcddac5e25a4 refs/tags/v2.8.0
184648397b8be8bfb5be62424f302a8cd4f88f39 refs/tags/v2.9.0

--- END OF .git/packed-refs ---


--- START OF .git/info/exclude ---
# git ls-files --others --exclude-from=.git/info/exclude
# Lines that start with '#' are comments.
# For a project mostly in C, the following would be a good set of
# exclude patterns (uncomment them if you want to use them):
# *.[oa]
# *~

--- END OF .git/info/exclude ---


--- START OF .git/logs/HEAD ---
0000000000000000000000000000000000000000 08c5cc4789d924ad4215e2fb2ee8f0b19a0d421f Hathibelagal <42626106+hathibelagal-dev@users.noreply.github.com> 1739918514 +0530	clone: from https://github.com/carpedm20/emoji.git

--- END OF .git/logs/HEAD ---


--- START OF .git/logs/refs/heads/master ---
0000000000000000000000000000000000000000 08c5cc4789d924ad4215e2fb2ee8f0b19a0d421f Hathibelagal <42626106+hathibelagal-dev@users.noreply.github.com> 1739918514 +0530	clone: from https://github.com/carpedm20/emoji.git

--- END OF .git/logs/refs/heads/master ---


--- START OF .git/logs/refs/remotes/origin/HEAD ---
0000000000000000000000000000000000000000 08c5cc4789d924ad4215e2fb2ee8f0b19a0d421f Hathibelagal <42626106+hathibelagal-dev@users.noreply.github.com> 1739918514 +0530	clone: from https://github.com/carpedm20/emoji.git

--- END OF .git/logs/refs/remotes/origin/HEAD ---


--- START OF .git/hooks/commit-msg.sample ---
#!/bin/sh
#
# An example hook script to check the commit log message.
# Called by "git commit" with one argument, the name of the file
# that has the commit message.  The hook should exit with non-zero
# status after issuing an appropriate message if it wants to stop the
# commit.  The hook is allowed to edit the commit message file.
#
# To enable this hook, rename this file to "commit-msg".

# Uncomment the below to add a Signed-off-by line to the message.
# Doing this in a hook is a bad idea in general, but the prepare-commit-msg
# hook is more suited to it.
#
# SOB=$(git var GIT_AUTHOR_IDENT | sed -n 's/^\(.*>\).*$/Signed-off-by: \1/p')
# grep -qs "^$SOB" "$1" || echo "$SOB" >> "$1"

# This example catches duplicate Signed-off-by lines.

test "" = "$(grep '^Signed-off-by: ' "$1" |
	 sort | uniq -c | sed -e '/^[ 	]*1[ 	]/d')" || {
	echo >&2 Duplicate Signed-off-by lines.
	exit 1
}

--- END OF .git/hooks/commit-msg.sample ---


--- START OF .git/hooks/pre-rebase.sample ---
#!/bin/sh
#
# Copyright (c) 2006, 2008 Junio C Hamano
#
# The "pre-rebase" hook is run just before "git rebase" starts doing
# its job, and can prevent the command from running by exiting with
# non-zero status.
#
# The hook is called with the following parameters:
#
# $1 -- the upstream the series was forked from.
# $2 -- the branch being rebased (or empty when rebasing the current branch).
#
# This sample shows how to prevent topic branches that are already
# merged to 'next' branch from getting rebased, because allowing it
# would result in rebasing already published history.

publish=next
basebranch="$1"
if test "$#" = 2
then
	topic="refs/heads/$2"
else
	topic=`git symbolic-ref HEAD` ||
	exit 0 ;# we do not interrupt rebasing detached HEAD
fi

case "$topic" in
refs/heads/??/*)
	;;
*)
	exit 0 ;# we do not interrupt others.
	;;
esac

# Now we are dealing with a topic branch being rebased
# on top of master.  Is it OK to rebase it?

# Does the topic really exist?
git show-ref -q "$topic" || {
	echo >&2 "No such branch $topic"
	exit 1
}

# Is topic fully merged to master?
not_in_master=`git rev-list --pretty=oneline ^master "$topic"`
if test -z "$not_in_master"
then
	echo >&2 "$topic is fully merged to master; better remove it."
	exit 1 ;# we could allow it, but there is no point.
fi

# Is topic ever merged to next?  If so you should not be rebasing it.
only_next_1=`git rev-list ^master "^$topic" ${publish} | sort`
only_next_2=`git rev-list ^master           ${publish} | sort`
if test "$only_next_1" = "$only_next_2"
then
	not_in_topic=`git rev-list "^$topic" master`
	if test -z "$not_in_topic"
	then
		echo >&2 "$topic is already up to date with master"
		exit 1 ;# we could allow it, but there is no point.
	else
		exit 0
	fi
else
	not_in_next=`git rev-list --pretty=oneline ^${publish} "$topic"`
	/usr/bin/perl -e '
		my $topic = $ARGV[0];
		my $msg = "* $topic has commits already merged to public branch:\n";
		my (%not_in_next) = map {
			/^([0-9a-f]+) /;
			($1 => 1);
		} split(/\n/, $ARGV[1]);
		for my $elem (map {
				/^([0-9a-f]+) (.*)$/;
				[$1 => $2];
			} split(/\n/, $ARGV[2])) {
			if (!exists $not_in_next{$elem->[0]}) {
				if ($msg) {
					print STDERR $msg;
					undef $msg;
				}
				print STDERR " $elem->[1]\n";
			}
		}
	' "$topic" "$not_in_next" "$not_in_master"
	exit 1
fi

<<\DOC_END

This sample hook safeguards topic branches that have been
published from being rewound.

The workflow assumed here is:

 * Once a topic branch forks from "master", "master" is never
   merged into it again (either directly or indirectly).

 * Once a topic branch is fully cooked and merged into "master",
   it is deleted.  If you need to build on top of it to correct
   earlier mistakes, a new topic branch is created by forking at
   the tip of the "master".  This is not strictly necessary, but
   it makes it easier to keep your history simple.

 * Whenever you need to test or publish your changes to topic
   branches, merge them into "next" branch.

The script, being an example, hardcodes the publish branch name
to be "next", but it is trivial to make it configurable via
$GIT_DIR/config mechanism.

With this workflow, you would want to know:

(1) ... if a topic branch has ever been merged to "next".  Young
    topic branches can have stupid mistakes you would rather
    clean up before publishing, and things that have not been
    merged into other branches can be easily rebased without
    affecting other people.  But once it is published, you would
    not want to rewind it.

(2) ... if a topic branch has been fully merged to "master".
    Then you can delete it.  More importantly, you should not
    build on top of it -- other people may already want to
    change things related to the topic as patches against your
    "master", so if you need further changes, it is better to
    fork the topic (perhaps with the same name) afresh from the
    tip of "master".

Let's look at this example:

		   o---o---o---o---o---o---o---o---o---o "next"
		  /       /           /           /
		 /   a---a---b A     /           /
		/   /               /           /
	       /   /   c---c---c---c B         /
	      /   /   /             \         /
	     /   /   /   b---b C     \       /
	    /   /   /   /             \     /
    ---o---o---o---o---o---o---o---o---o---o---o "master"


A, B and C are topic branches.

 * A has one fix since it was merged up to "next".

 * B has finished.  It has been fully merged up to "master" and "next",
   and is ready to be deleted.

 * C has not merged to "next" at all.

We would want to allow C to be rebased, refuse A, and encourage
B to be deleted.

To compute (1):

	git rev-list ^master ^topic next
	git rev-list ^master        next

	if these match, topic has not merged in next at all.

To compute (2):

	git rev-list master..topic

	if this is empty, it is fully merged to "master".

DOC_END

--- END OF .git/hooks/pre-rebase.sample ---


--- START OF .git/hooks/pre-commit.sample ---
#!/bin/sh
#
# An example hook script to verify what is about to be committed.
# Called by "git commit" with no arguments.  The hook should
# exit with non-zero status after issuing an appropriate message if
# it wants to stop the commit.
#
# To enable this hook, rename this file to "pre-commit".

if git rev-parse --verify HEAD >/dev/null 2>&1
then
	against=HEAD
else
	# Initial commit: diff against an empty tree object
	against=$(git hash-object -t tree /dev/null)
fi

# If you want to allow non-ASCII filenames set this variable to true.
allownonascii=$(git config --type=bool hooks.allownonascii)

# Redirect output to stderr.
exec 1>&2

# Cross platform projects tend to avoid non-ASCII filenames; prevent
# them from being added to the repository. We exploit the fact that the
# printable range starts at the space character and ends with tilde.
if [ "$allownonascii" != "true" ] &&
	# Note that the use of brackets around a tr range is ok here, (it's
	# even required, for portability to Solaris 10's /usr/bin/tr), since
	# the square bracket bytes happen to fall in the designated range.
	test $(git diff --cached --name-only --diff-filter=A -z $against |
	  LC_ALL=C tr -d '[ -~]\0' | wc -c) != 0
then
	cat <<\EOF
Error: Attempt to add a non-ASCII file name.

This can cause problems if you want to work with people on other platforms.

To be portable it is advisable to rename the file.

If you know what you are doing you can disable this check using:

  git config hooks.allownonascii true
EOF
	exit 1
fi

# If there are whitespace errors, print the offending file names and fail.
exec git diff-index --check --cached $against --

--- END OF .git/hooks/pre-commit.sample ---


--- START OF .git/hooks/applypatch-msg.sample ---
#!/bin/sh
#
# An example hook script to check the commit log message taken by
# applypatch from an e-mail message.
#
# The hook should exit with non-zero status after issuing an
# appropriate message if it wants to stop the commit.  The hook is
# allowed to edit the commit message file.
#
# To enable this hook, rename this file to "applypatch-msg".

. git-sh-setup
commitmsg="$(git rev-parse --git-path hooks/commit-msg)"
test -x "$commitmsg" && exec "$commitmsg" ${1+"$@"}
:

--- END OF .git/hooks/applypatch-msg.sample ---


--- START OF .git/hooks/fsmonitor-watchman.sample ---
#!/usr/bin/perl

use strict;
use warnings;
use IPC::Open2;

# An example hook script to integrate Watchman
# (https://facebook.github.io/watchman/) with git to speed up detecting
# new and modified files.
#
# The hook is passed a version (currently 2) and last update token
# formatted as a string and outputs to stdout a new update token and
# all files that have been modified since the update token. Paths must
# be relative to the root of the working tree and separated by a single NUL.
#
# To enable this hook, rename this file to "query-watchman" and set
# 'git config core.fsmonitor .git/hooks/query-watchman'
#
my ($version, $last_update_token) = @ARGV;

# Uncomment for debugging
# print STDERR "$0 $version $last_update_token\n";

# Check the hook interface version
if ($version ne 2) {
	die "Unsupported query-fsmonitor hook version '$version'.\n" .
	    "Falling back to scanning...\n";
}

my $git_work_tree = get_working_dir();

my $retry = 1;

my $json_pkg;
eval {
	require JSON::XS;
	$json_pkg = "JSON::XS";
	1;
} or do {
	require JSON::PP;
	$json_pkg = "JSON::PP";
};

launch_watchman();

sub launch_watchman {
	my $o = watchman_query();
	if (is_work_tree_watched($o)) {
		output_result($o->{clock}, @{$o->{files}});
	}
}

sub output_result {
	my ($clockid, @files) = @_;

	# Uncomment for debugging watchman output
	# open (my $fh, ">", ".git/watchman-output.out");
	# binmode $fh, ":utf8";
	# print $fh "$clockid\n@files\n";
	# close $fh;

	binmode STDOUT, ":utf8";
	print $clockid;
	print "\0";
	local $, = "\0";
	print @files;
}

sub watchman_clock {
	my $response = qx/watchman clock "$git_work_tree"/;
	die "Failed to get clock id on '$git_work_tree'.\n" .
		"Falling back to scanning...\n" if $? != 0;

	return $json_pkg->new->utf8->decode($response);
}

sub watchman_query {
	my $pid = open2(\*CHLD_OUT, \*CHLD_IN, 'watchman -j --no-pretty')
	or die "open2() failed: $!\n" .
	"Falling back to scanning...\n";

	# In the query expression below we're asking for names of files that
	# changed since $last_update_token but not from the .git folder.
	#
	# To accomplish this, we're using the "since" generator to use the
	# recency index to select candidate nodes and "fields" to limit the
	# output to file names only. Then we're using the "expression" term to
	# further constrain the results.
	my $last_update_line = "";
	if (substr($last_update_token, 0, 1) eq "c") {
		$last_update_token = "\"$last_update_token\"";
		$last_update_line = qq[\n"since": $last_update_token,];
	}
	my $query = <<"	END";
		["query", "$git_work_tree", {$last_update_line
			"fields": ["name"],
			"expression": ["not", ["dirname", ".git"]]
		}]
	END

	# Uncomment for debugging the watchman query
	# open (my $fh, ">", ".git/watchman-query.json");
	# print $fh $query;
	# close $fh;

	print CHLD_IN $query;
	close CHLD_IN;
	my $response = do {local $/; <CHLD_OUT>};

	# Uncomment for debugging the watch response
	# open ($fh, ">", ".git/watchman-response.json");
	# print $fh $response;
	# close $fh;

	die "Watchman: command returned no output.\n" .
	"Falling back to scanning...\n" if $response eq "";
	die "Watchman: command returned invalid output: $response\n" .
	"Falling back to scanning...\n" unless $response =~ /^\{/;

	return $json_pkg->new->utf8->decode($response);
}

sub is_work_tree_watched {
	my ($output) = @_;
	my $error = $output->{error};
	if ($retry > 0 and $error and $error =~ m/unable to resolve root .* directory (.*) is not watched/) {
		$retry--;
		my $response = qx/watchman watch "$git_work_tree"/;
		die "Failed to make watchman watch '$git_work_tree'.\n" .
		    "Falling back to scanning...\n" if $? != 0;
		$output = $json_pkg->new->utf8->decode($response);
		$error = $output->{error};
		die "Watchman: $error.\n" .
		"Falling back to scanning...\n" if $error;

		# Uncomment for debugging watchman output
		# open (my $fh, ">", ".git/watchman-output.out");
		# close $fh;

		# Watchman will always return all files on the first query so
		# return the fast "everything is dirty" flag to git and do the
		# Watchman query just to get it over with now so we won't pay
		# the cost in git to look up each individual file.
		my $o = watchman_clock();
		$error = $output->{error};

		die "Watchman: $error.\n" .
		"Falling back to scanning...\n" if $error;

		output_result($o->{clock}, ("/"));
		$last_update_token = $o->{clock};

		eval { launch_watchman() };
		return 0;
	}

	die "Watchman: $error.\n" .
	"Falling back to scanning...\n" if $error;

	return 1;
}

sub get_working_dir {
	my $working_dir;
	if ($^O =~ 'msys' || $^O =~ 'cygwin') {
		$working_dir = Win32::GetCwd();
		$working_dir =~ tr/\\/\//;
	} else {
		require Cwd;
		$working_dir = Cwd::cwd();
	}

	return $working_dir;
}

--- END OF .git/hooks/fsmonitor-watchman.sample ---


--- START OF .git/hooks/pre-receive.sample ---
#!/bin/sh
#
# An example hook script to make use of push options.
# The example simply echoes all push options that start with 'echoback='
# and rejects all pushes when the "reject" push option is used.
#
# To enable this hook, rename this file to "pre-receive".

if test -n "$GIT_PUSH_OPTION_COUNT"
then
	i=0
	while test "$i" -lt "$GIT_PUSH_OPTION_COUNT"
	do
		eval "value=\$GIT_PUSH_OPTION_$i"
		case "$value" in
		echoback=*)
			echo "echo from the pre-receive-hook: ${value#*=}" >&2
			;;
		reject)
			exit 1
		esac
		i=$((i + 1))
	done
fi

--- END OF .git/hooks/pre-receive.sample ---


--- START OF .git/hooks/prepare-commit-msg.sample ---
#!/bin/sh
#
# An example hook script to prepare the commit log message.
# Called by "git commit" with the name of the file that has the
# commit message, followed by the description of the commit
# message's source.  The hook's purpose is to edit the commit
# message file.  If the hook fails with a non-zero status,
# the commit is aborted.
#
# To enable this hook, rename this file to "prepare-commit-msg".

# This hook includes three examples. The first one removes the
# "# Please enter the commit message..." help message.
#
# The second includes the output of "git diff --name-status -r"
# into the message, just before the "git status" output.  It is
# commented because it doesn't cope with --amend or with squashed
# commits.
#
# The third example adds a Signed-off-by line to the message, that can
# still be edited.  This is rarely a good idea.

COMMIT_MSG_FILE=$1
COMMIT_SOURCE=$2
SHA1=$3

/usr/bin/perl -i.bak -ne 'print unless(m/^. Please enter the commit message/..m/^#$/)' "$COMMIT_MSG_FILE"

# case "$COMMIT_SOURCE,$SHA1" in
#  ,|template,)
#    /usr/bin/perl -i.bak -pe '
#       print "\n" . `git diff --cached --name-status -r`
# 	 if /^#/ && $first++ == 0' "$COMMIT_MSG_FILE" ;;
#  *) ;;
# esac

# SOB=$(git var GIT_COMMITTER_IDENT | sed -n 's/^\(.*>\).*$/Signed-off-by: \1/p')
# git interpret-trailers --in-place --trailer "$SOB" "$COMMIT_MSG_FILE"
# if test -z "$COMMIT_SOURCE"
# then
#   /usr/bin/perl -i.bak -pe 'print "\n" if !$first_line++' "$COMMIT_MSG_FILE"
# fi

--- END OF .git/hooks/prepare-commit-msg.sample ---


--- START OF .git/hooks/post-update.sample ---
#!/bin/sh
#
# An example hook script to prepare a packed repository for use over
# dumb transports.
#
# To enable this hook, rename this file to "post-update".

exec git update-server-info

--- END OF .git/hooks/post-update.sample ---


--- START OF .git/hooks/pre-merge-commit.sample ---
#!/bin/sh
#
# An example hook script to verify what is about to be committed.
# Called by "git merge" with no arguments.  The hook should
# exit with non-zero status after issuing an appropriate message to
# stderr if it wants to stop the merge commit.
#
# To enable this hook, rename this file to "pre-merge-commit".

. git-sh-setup
test -x "$GIT_DIR/hooks/pre-commit" &&
        exec "$GIT_DIR/hooks/pre-commit"
:

--- END OF .git/hooks/pre-merge-commit.sample ---


--- START OF .git/hooks/pre-applypatch.sample ---
#!/bin/sh
#
# An example hook script to verify what is about to be committed
# by applypatch from an e-mail message.
#
# The hook should exit with non-zero status after issuing an
# appropriate message if it wants to stop the commit.
#
# To enable this hook, rename this file to "pre-applypatch".

. git-sh-setup
precommit="$(git rev-parse --git-path hooks/pre-commit)"
test -x "$precommit" && exec "$precommit" ${1+"$@"}
:

--- END OF .git/hooks/pre-applypatch.sample ---


--- START OF .git/hooks/pre-push.sample ---
#!/bin/sh

# An example hook script to verify what is about to be pushed.  Called by "git
# push" after it has checked the remote status, but before anything has been
# pushed.  If this script exits with a non-zero status nothing will be pushed.
#
# This hook is called with the following parameters:
#
# $1 -- Name of the remote to which the push is being done
# $2 -- URL to which the push is being done
#
# If pushing without using a named remote those arguments will be equal.
#
# Information about the commits which are being pushed is supplied as lines to
# the standard input in the form:
#
#   <local ref> <local oid> <remote ref> <remote oid>
#
# This sample shows how to prevent push of commits where the log message starts
# with "WIP" (work in progress).

remote="$1"
url="$2"

zero=$(git hash-object --stdin </dev/null | tr '[0-9a-f]' '0')

while read local_ref local_oid remote_ref remote_oid
do
	if test "$local_oid" = "$zero"
	then
		# Handle delete
		:
	else
		if test "$remote_oid" = "$zero"
		then
			# New branch, examine all commits
			range="$local_oid"
		else
			# Update to existing branch, examine new commits
			range="$remote_oid..$local_oid"
		fi

		# Check for WIP commit
		commit=$(git rev-list -n 1 --grep '^WIP' "$range")
		if test -n "$commit"
		then
			echo >&2 "Found WIP commit in $local_ref, not pushing"
			exit 1
		fi
	fi
done

exit 0

--- END OF .git/hooks/pre-push.sample ---


--- START OF .git/hooks/update.sample ---
#!/bin/sh
#
# An example hook script to block unannotated tags from entering.
# Called by "git receive-pack" with arguments: refname sha1-old sha1-new
#
# To enable this hook, rename this file to "update".
#
# Config
# ------
# hooks.allowunannotated
#   This boolean sets whether unannotated tags will be allowed into the
#   repository.  By default they won't be.
# hooks.allowdeletetag
#   This boolean sets whether deleting tags will be allowed in the
#   repository.  By default they won't be.
# hooks.allowmodifytag
#   This boolean sets whether a tag may be modified after creation. By default
#   it won't be.
# hooks.allowdeletebranch
#   This boolean sets whether deleting branches will be allowed in the
#   repository.  By default they won't be.
# hooks.denycreatebranch
#   This boolean sets whether remotely creating branches will be denied
#   in the repository.  By default this is allowed.
#

# --- Command line
refname="$1"
oldrev="$2"
newrev="$3"

# --- Safety check
if [ -z "$GIT_DIR" ]; then
	echo "Don't run this script from the command line." >&2
	echo " (if you want, you could supply GIT_DIR then run" >&2
	echo "  $0 <ref> <oldrev> <newrev>)" >&2
	exit 1
fi

if [ -z "$refname" -o -z "$oldrev" -o -z "$newrev" ]; then
	echo "usage: $0 <ref> <oldrev> <newrev>" >&2
	exit 1
fi

# --- Config
allowunannotated=$(git config --type=bool hooks.allowunannotated)
allowdeletebranch=$(git config --type=bool hooks.allowdeletebranch)
denycreatebranch=$(git config --type=bool hooks.denycreatebranch)
allowdeletetag=$(git config --type=bool hooks.allowdeletetag)
allowmodifytag=$(git config --type=bool hooks.allowmodifytag)

# check for no description
projectdesc=$(sed -e '1q' "$GIT_DIR/description")
case "$projectdesc" in
"Unnamed repository"* | "")
	echo "*** Project description file hasn't been set" >&2
	exit 1
	;;
esac

# --- Check types
# if $newrev is 0000...0000, it's a commit to delete a ref.
zero=$(git hash-object --stdin </dev/null | tr '[0-9a-f]' '0')
if [ "$newrev" = "$zero" ]; then
	newrev_type=delete
else
	newrev_type=$(git cat-file -t $newrev)
fi

case "$refname","$newrev_type" in
	refs/tags/*,commit)
		# un-annotated tag
		short_refname=${refname##refs/tags/}
		if [ "$allowunannotated" != "true" ]; then
			echo "*** The un-annotated tag, $short_refname, is not allowed in this repository" >&2
			echo "*** Use 'git tag [ -a | -s ]' for tags you want to propagate." >&2
			exit 1
		fi
		;;
	refs/tags/*,delete)
		# delete tag
		if [ "$allowdeletetag" != "true" ]; then
			echo "*** Deleting a tag is not allowed in this repository" >&2
			exit 1
		fi
		;;
	refs/tags/*,tag)
		# annotated tag
		if [ "$allowmodifytag" != "true" ] && git rev-parse $refname > /dev/null 2>&1
		then
			echo "*** Tag '$refname' already exists." >&2
			echo "*** Modifying a tag is not allowed in this repository." >&2
			exit 1
		fi
		;;
	refs/heads/*,commit)
		# branch
		if [ "$oldrev" = "$zero" -a "$denycreatebranch" = "true" ]; then
			echo "*** Creating a branch is not allowed in this repository" >&2
			exit 1
		fi
		;;
	refs/heads/*,delete)
		# delete branch
		if [ "$allowdeletebranch" != "true" ]; then
			echo "*** Deleting a branch is not allowed in this repository" >&2
			exit 1
		fi
		;;
	refs/remotes/*,commit)
		# tracking branch
		;;
	refs/remotes/*,delete)
		# delete tracking branch
		if [ "$allowdeletebranch" != "true" ]; then
			echo "*** Deleting a tracking branch is not allowed in this repository" >&2
			exit 1
		fi
		;;
	*)
		# Anything else (is there anything else?)
		echo "*** Update hook: unknown type of update to ref $refname of type $newrev_type" >&2
		exit 1
		;;
esac

# --- Finished
exit 0

--- END OF .git/hooks/update.sample ---


--- START OF .git/hooks/push-to-checkout.sample ---
#!/bin/sh

# An example hook script to update a checked-out tree on a git push.
#
# This hook is invoked by git-receive-pack(1) when it reacts to git
# push and updates reference(s) in its repository, and when the push
# tries to update the branch that is currently checked out and the
# receive.denyCurrentBranch configuration variable is set to
# updateInstead.
#
# By default, such a push is refused if the working tree and the index
# of the remote repository has any difference from the currently
# checked out commit; when both the working tree and the index match
# the current commit, they are updated to match the newly pushed tip
# of the branch. This hook is to be used to override the default
# behaviour; however the code below reimplements the default behaviour
# as a starting point for convenient modification.
#
# The hook receives the commit with which the tip of the current
# branch is going to be updated:
commit=$1

# It can exit with a non-zero status to refuse the push (when it does
# so, it must not modify the index or the working tree).
die () {
	echo >&2 "$*"
	exit 1
}

# Or it can make any necessary changes to the working tree and to the
# index to bring them to the desired state when the tip of the current
# branch is updated to the new commit, and exit with a zero status.
#
# For example, the hook can simply run git read-tree -u -m HEAD "$1"
# in order to emulate git fetch that is run in the reverse direction
# with git push, as the two-tree form of git read-tree -u -m is
# essentially the same as git switch or git checkout that switches
# branches while keeping the local changes in the working tree that do
# not interfere with the difference between the branches.

# The below is a more-or-less exact translation to shell of the C code
# for the default behaviour for git's push-to-checkout hook defined in
# the push_to_deploy() function in builtin/receive-pack.c.
#
# Note that the hook will be executed from the repository directory,
# not from the working tree, so if you want to perform operations on
# the working tree, you will have to adapt your code accordingly, e.g.
# by adding "cd .." or using relative paths.

if ! git update-index -q --ignore-submodules --refresh
then
	die "Up-to-date check failed"
fi

if ! git diff-files --quiet --ignore-submodules --
then
	die "Working directory has unstaged changes"
fi

# This is a rough translation of:
#
#   head_has_history() ? "HEAD" : EMPTY_TREE_SHA1_HEX
if git cat-file -e HEAD 2>/dev/null
then
	head=HEAD
else
	head=$(git hash-object -t tree --stdin </dev/null)
fi

if ! git diff-index --quiet --cached --ignore-submodules $head --
then
	die "Working directory has staged changes"
fi

if ! git read-tree -u -m "$commit"
then
	die "Could not update working tree to new HEAD"
fi

--- END OF .git/hooks/push-to-checkout.sample ---


--- START OF .git/refs/heads/master ---
08c5cc4789d924ad4215e2fb2ee8f0b19a0d421f

--- END OF .git/refs/heads/master ---


--- START OF .git/refs/remotes/origin/HEAD ---
ref: refs/remotes/origin/master

--- END OF .git/refs/remotes/origin/HEAD ---



--- END OF q/repo-to-prompt/src/llm_prompt.txt ---


